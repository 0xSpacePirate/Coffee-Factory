VERS 00000001 5
HEAD 00001306 <?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="/resources/transform.xslt"?><header><componentName>correlator</componentName><version>10.5.0.0.357639</version><build>rel/10.5.0.x@357639</build><buildPlatform>amd64-win</buildPlatform><platform>Windows 10 Enterprise</platform><cputype>GenuineIntel family 6 model 14 stepping 3 Intel(R) Core(TM) i7-6600U CPU @ 2.60GHz</cputype><cpus name="cpus">4.00</cpus><javaEnabled>true</javaEnabled><replayLogMode>inputLog</replayLogMode><args><arg>C:\dev\apama_win_full_latest\Apama\bin\correlator.exe</arg><arg>--config</arg><arg>C:\Users\y508970\workspace105\Coffee Factory\config\CorrelatorConfig.yaml</arg><arg>--port</arg><arg>15903</arg><arg>--loglevel</arg><arg>INFO</arg><arg>--name</arg><arg>Apama Designer Correlator for Coffee Factory(Coffee Factory:defaultCorrelator)</arg><arg>-j</arg><arg>--inputLog</arg><arg>logs/defaultCorrelator_${START_TIME}_${ID}.input.log</arg></args><environment><variable>ALLUSERSPROFILE=C:\ProgramData</variable><variable>APAMA_HOME=C:\dev\apama_win_full_latest\Apama</variable><variable>APAMA_WORK=C:\Users\Public\SoftwareAG\ApamaWork_10.5</variable><variable>APPDATA=C:\Users\y508970\AppData\Roaming</variable><variable>COMMONPROGRAMFILES=C:\Program Files\Common Files</variable><variable>COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files</variable><variable>COMMONPROGRAMW6432=C:\Program Files\Common Files</variable><variable>COMPUTERNAME=SAG-98V9PF2</variable><variable>COMSPEC=C:\Windows\system32\cmd.exe</variable><variable>DEFLOGDIR=C:\ProgramData\McAfee\Endpoint Security\Logs</variable><variable>DRIVERDATA=C:\Windows\System32\Drivers\DriverData</variable><variable>EMPIRUMSERVER=cukuni02.eur.ad.sag</variable><variable>EMPIRUMSERVICEPARTITION=0</variable><variable>EMPSRVLONG=cukuni02.eur.ad.sag</variable><variable>HOMEDRIVE=C:</variable><variable>HOMEPATH=\Users\y508970</variable><variable>LOCALAPPDATA=C:\Users\y508970\AppData\Local</variable><variable>LOGONSERVER=\\CUKDC85</variable><variable>NUMBER_OF_PROCESSORS=4</variable><variable>ONEDRIVE=C:\Users\y508970\OneDrive - Software AG</variable><variable>ONEDRIVECOMMERCIAL=C:\Users\y508970\OneDrive - Software AG</variable><variable>OS=Windows_NT</variable><variable>PATH=C:\dev\apama_win_full_latest\Apama\..\jvm\jvm\jre\bin\server;C:\dev\apama_win_full_latest\Apama\..\jvm\jvm\jre\bin;C:\dev\apama_win_full_latest\Apama\bin;C:\dev\apama_win_full_latest\Apama\..\common\security\openssl\bin;C:\Users\Public\SoftwareAG\ApamaWork_10.5\lib;C:\dev\apama_win_full_latest\Apama\..\jvm\jvm\jre\bin;C:\dev\apama_win_full_latest\Apama\..\jvm\jvm\jre\bin\server;C:\dev\apama_win_full_latest\Apama\..\UniversalMessaging\cplus\lib\x86_64;C:\dev\apama_win_full_latest\Apama\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\PuTTY\;C:\Program Files\SlikSvn\bin;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\TortoiseGit\bin;C:\Users\y508970\AppData\Local\Microsoft\WindowsApps;C:\Users\y508970\AppData\Local\Programs\Git\cmd;C:\Users\y508970\AppData\Local\GitHubDesktop\bin</variable><variable>PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC</variable><variable>PROCESSOR_ARCHITECTURE=AMD64</variable><variable>PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 78 Stepping 3, GenuineIntel</variable><variable>PROCESSOR_LEVEL=6</variable><variable>PROCESSOR_REVISION=4e03</variable><variable>PROGRAMDATA=C:\ProgramData</variable><variable>PROGRAMFILES=C:\Program Files</variable><variable>PROGRAMFILES(X86)=C:\Program Files (x86)</variable><variable>PROGRAMW6432=C:\Program Files</variable><variable>PROMPT=$P$G</variable><variable>PSMODULEPATH=C:\Program Files\WindowsPowerShell\Modules;C:\Windows\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files\Barracuda\Network Access Client\Modules</variable><variable>PUBLIC=C:\Users\Public</variable><variable>SESSIONNAME=Console</variable><variable>SSL_CERT_FILE=C:\dev\apama_win_full_latest\Apama\..\common\security\openssl\cert.pem</variable><variable>SYSTEMDRIVE=C:</variable><variable>SYSTEMROOT=C:\Windows</variable><variable>TEMP=C:\Users\y508970\AppData\Local\Temp</variable><variable>TMP=C:\Users\y508970\AppData\Local\Temp</variable><variable>USERDNSDOMAIN=EUR.AD.SAG</variable><variable>USERDOMAIN=EUR</variable><variable>USERDOMAIN_ROAMINGPROFILE=EUR</variable><variable>USERNAME=y508970</variable><variable>USERPROFILE=C:\Users\y508970</variable><variable>WINDIR=C:\Windows</variable></environment><version>10.5.0.0.357639</version></header>
YAML 000005a4 ###############################################################################
# $Copyright (c) 2016 Software AG, Darmstadt, Germany and/or Software AG USA Inc., Reston, VA, USA, and/or its subsidiaries and/or its affiliates and/or their licensors.$
# Use, reproduction, transfer, publication or disclosure is prohibited except as specifically provided for in your License Agreement with Software AG
###############################################################################

#To set the default log file and level for an EPL package, monitor, or event, specify
# logging details in the eplLogging section of the YAML configuration file.
#For example:
#eplLogging:
#  com.myCompany.Client:
#    file: apama/Client.log
#    level: DEBUG
#  com.myCompany.Internal: { level: ERROR }

engineConnect:
    - sourceHost: localhost
      sourcePort: 15903

      channels:
        - roastChannel
        - extractorChannel
        - freezeChannel
        - freezeDryerChannel

      #mode: parallel
      #disconnectIfSlow: false

#See the information on setting log files and log levels in a YAML configuration file in the documentation for more
# information about the supported options.
#To enable use of this file when you launch this project from Designer, edit the project's run/launch configuration,
#open the correlator, and tick the "Configuration" checkbox next to the textbox that names this .yaml file.
 00000049 C:\Users\y508970\workspace105\Coffee Factory\config\CorrelatorConfig.yaml
RAND 00000009 719690802
TIME 00000010 1568382755.877,1
CONN 0000003c 6736152632449878368:6735871166063102304 from 127.0.0.1:58877
TIME 0000000c 1568382756,1
CONN 0000003c 6736152632449878368:6736715595288201568 from 127.0.0.1:15903
CONN 0000003c 3022726252155043840:3091057390917648384 from 127.0.0.1:58870
TIME 0000000e 1568382756.5,1
MONF 00000b40 /**
 * $Copyright (c) 2016-2017 Software AG, Darmstadt, Germany and/or Software AG USA Inc., Reston, VA, USA, and/or its subsidiaries and/or its affiliates and/or their licensors.$
 * Use, reproduction, transfer, publication or disclosure is prohibited except as specifically provided for in your License Agreement with Software AG
 */

package com.softwareag.connectivity.control;

/**
 * Used for com.softwareag.connectivity.Chain#ackUpTo() and
 * com.softwareag.connectivity.control.AckRequired#ackUpTo() , sent to the
 * control channel of the chain.
 * @private
 */
event AckUpTo {
	string messageId;
}

/**
 * Request from a connectivity chain to the application, asking it to reliably
 * acknowledge all events that came from the chain immediately prior to this
 * AckRequired.
 *
 * This event will be sent to the default channel of that chain. That is, your
 * EPL will not normally need to subscribe to any extra channels to receive
 * these requests, if it is already receiving regular events from that chain.
 *
 * A reliable-messaging-aware transport will issue these requests with as large
 * an interval as it can get away with, based on the constraints of the
 * external messaging system. So if your application has a "commit" mechanism
 * that has a large fixed cost (for example, a filesystem sync, a database
 * commit or an expensive computation) then doing a commit and acknowledgment
 * on and only on AckRequired requests makes sense.
 *
 * Do not rely on these requests being high frequency or timely; the functional
 * behaviour of your application should not depend on them, especially if
 * latency is important. Only the operations required for safely preserving the
 * effect of incoming events should be tied to AckRequired requests.
 *
 * @see com.softwareag.connectivity.Chain#ackUpTo() Otherwise, you can use this
 * action to perform per-event acknowledgments if the message id of each
 * incoming event is available.
 */
event AckRequired {
	/** The message id of the regular event received immediately before this AckRequired. */
	string messageId;

	/** Id of the connectivity chain that this request has come from. */
	string chainId;

	/**
	 * Acknowledge all previously received events from the connectivity chain
	 * as having been reliably processed by your application.
	 */
	action ackUpTo() {
		send AckUpTo(messageId) to "com.softwareag.connectivity.chaincontrol." + chainId;
	}
}

/**
 * Used by com.softwareag.connectivity.Chain#flush(). This event gets sent to
 * the control channel of the chain.
 * @private
 */
event Flush {
	integer requestId;
	context replyTo;
}

/**
 * Response to a flush request.
 *
 * @see com.softwareag.connectivity.Chain#flush()
 */
event FlushAck {
	/** Identifies the corresponding flush request. */
	integer requestId;
}
 0000004a C:\dev\apama_win_full_latest\Apama\monitors\ConnectivityPluginsControl.mon
MONF 000021ea /**
 * $Copyright (c) 2015-2018 Software AG, Darmstadt, Germany and/or Software AG USA Inc., Reston, VA, USA, and/or its subsidiaries and/or its affiliates and/or their licensors.$
 * Use, reproduction, transfer, publication or disclosure is prohibited except as specifically provided for in your License Agreement with Software AG
 */

package com.softwareag.connectivity;

/**
 * Represents a chain instance and provides methods to perform various operations on it.
 */
event Chain
{
	/** @private */
	import "ConnectivityPlugin" as _plugin;
	/** 
	 * Destroy this chain instance. Chains that are managed by a dynamic chain
	 * manager cannot be destroyed this way.
	 * This should be called only once.
	 */
	action destroy()
	{
		_plugin.destroyChain(chain);
	}
	
	/**
	 * Return the unique id of the chain instance.
	 *
	 * @return The id of the chain instance
	 */
	action getId() returns string
	{
		return _plugin.getChainId(chain);
	}

	/**
	 * Acknowledge that a specific event and all previous events received from
	 * this connectivity chain have been reliably processed by your
	 * application.
	 *
	 * If you are going to make use of this action, then the message id of the
	 * incoming events will need to be available somehow. For example, as a
	 * field on the event.
	 *
	 * This action will only have an effect on chains with a
	 * reliable-messaging-aware transport, and should not be used otherwise.
	 *
	 * @see com.softwareag.connectivity.control.AckRequired  In some situations
	 * it may make more sense to do acknowledgments on AckRequired requests,
	 * rather than against events of the application's choice.
	 *
	 * @param messageId The message id of the specific event
	 */
	action ackUpTo(string messageId) {
		send control.AckUpTo(messageId) to "com.softwareag.connectivity.chaincontrol." + getId();
	}

	/**
	 * Ask the chain to acknowledge all events previously sent to it by the
	 * application. A FlushAck reply will be sent to the current context once
	 * these events have been reliably processed by the external system.
	 *
	 * This action will only have an effect on chains with a
	 * reliable-messaging-aware transport, and should not be used otherwise.
	 *
	 * A transport will still handle events that are sent to it, whether or not
	 * flushing is used. A flush request is purely a signalling mechanism.
	 *
	 * @see com.softwareag.connectivity.control.FlushAck
	 * @return The requestId of the expected FlushAck
	 */
	action flush() returns integer {
		integer rID := integer.incrementCounter("apama.ConnectivityFlushRequest");
		send control.Flush(rID, context.current()) to "com.softwareag.connectivity.chaincontrol." + getId();
		return rID;
	}
	
	/** @private */
	chunk chain;
}

/**
 * Utility event to provide string literals for direction.
 */
event Direction {
	/**
	 * The direction of messages flowing towards the transport (from the host).
	 */
	constant string TOWARDS_TRANSPORT := "TOWARDS_TRANSPORT";
	
	/**
	 * The direction of messages flowing towards the host (from the transport).
	 */
	constant string TOWARDS_HOST := "TOWARDS_HOST";
}

/**
 * Utilities for interacting with connectivity plug-ins.
 */
event ConnectivityPlugins
{
	/** @private */
	import "ConnectivityPlugin" as _plugin;

	/** Should be called by EPL applications after all EPL has been injected
	 * and initialized, to indicate that the application is ready to receive
	 * events from connectivity plug-ins.
	 *
	 * This will also enable reception of JMS events if correlator-integrated
	 * JMS is enabled (That is, it implicitly calls
	 * JMSPlugin.onApplicationInitialized)
	 *
	 * Invoking this action more than once is an error and will throw an
	 * exception.
	 *
	 */
	static action onApplicationInitialized()
	{
		_plugin.onApplicationInitialized();
	}
	/** 
	 * Create and start a chain instance from the given chain definition listed in dynamicChains in the configuration file.
	 *
	 * This action returns a Chain that has already been created and started. It is immediately able to receive events.
	 *
	 * @deprecated [This action has been deprecated. Please use createDynamicChain instead.]
	 *
	 * @param chainInstanceId The unique identifier to use for the new chain instance. This identifier is used for logging, and for looking up existing Chain objects by id.
	 * Caution: A small amount of memory is allocated for each unique chain instance identifier. This memory is not freed when the chain is destroyed. Therefore, if you are creating many chains, consider reusing old chain instance identifiers. If you create more than 1000 unique identifiers, a warning is written to the correlator log file to notify you of this. You cannot have two active chains with the same chain instance identifier, so only reuse identifiers which are no longer in use.
	 * @param channels The list of channels this chain should subscribe to
	 * @param chainDefnName The name of a chain definition listed under dynamicChains in the configuration file
	 * @param substitutions Dictionary providing values for <code>@{...}</code> dynamic substitution variables in the chain definition
	 * @return A Chain object which can be used to destroy this chain later
	 */
	static action createChain(string chainInstanceId, sequence<string> channels, string chainDefnName, dictionary<string, string> substitutions) returns Chain 
	{
		return Chain(_plugin.createChain(chainInstanceId, channels, chainDefnName, substitutions));
	}
	
	/** 
	 * Create and start a chain instance from the given chain definition listed in dynamicChains in the configuration file.
	 *
	 * This action returns a Chain that has already been created and started. It is immediately able to receive events.
	 *
	 * @param chainInstanceId The unique identifier to use for the new chain instance. This identifier is used for logging, and for looking up existing Chain objects by id.
	 * @param channels The list of channels this chain should subscribe to
	 * @param chainDefnName The name of a chain definition listed under dynamicChains in the configuration file
	 * @param substitutions Dictionary providing values for <code>@{...}</code> dynamic substitution variables in the chain definition
	 * @param defaultChannelTowardsHost Default channel to use for sending a message towards the host if no channel is specified on the message. 
	 * Use an empty string for no default channel. It is an error to specify non-empty defaultChannelTowardsHost value if defaultChannel is also
	 * specified for the host plug-in.
	 * @return A Chain object which can be used to destroy this chain later
	 */
	static action createDynamicChain(string chainInstanceId, sequence<string> channels, string chainDefnName, dictionary<string, string> substitutions, string defaultChannelTowardsHost) returns Chain 
	{
		return Chain(_plugin.createDynamicChain(chainInstanceId, channels, chainDefnName, substitutions, defaultChannelTowardsHost));
	}
	
	/**
	 * Look up a chain instance by its identifier. This can retrieve
	 * dynamically created chains, as well as statically created chains from
	 * 'startChains' in the correlator configuration.
	 *
	 * An exception is thrown if no chain exists with this identifier.
	 *
	 * @param chainInstanceId The unique identifier of the chain instance
	 * @return The chain instance
	 */
	static action getChainById(string chainInstanceId) returns Chain {
		return Chain(_plugin.getChainById(chainInstanceId));
	}
	
	/**
	 * Look up a chain instance by a channel it is subscribed to or sending to.
	 *
	 * There must be exactly one chain matching the requested combination of
	 * channel and direction, else an exception is thrown.
	 * 
	 * The direction of the channel specifies how the channel is used by the chain instance. 
	 * The TOWARDS_TRANSPORT direction means that the channel is one of the channels that 
	 * the chain instance is subscribed to to receive events from the host. The TOWARDS_HOST 
	 * direction means that the channel is used by the chain instance as the default channel 
	 * to deliver events from the transport to the host.
	 * 
	 * @param channel The channel to use for lookup. 
	 * @param direction Specifies the direction in which the channel is used by the chain instance. 
	 * Use the constants defined in the Direction event for string literals.
	 * @see com.softwareag.connectivity.Direction
	 */
	static action getChainByChannel(string channel, string direction) returns Chain {
		return Chain(_plugin.getChainByChannel(channel, direction));
	}
}

 00000043 C:\dev\apama_win_full_latest\Apama\monitors\ConnectivityPlugins.mon
MONF 00000593 /*
 * $Copyright (c) 2016-2018 Software AG, Darmstadt, Germany and/or Software AG USA Inc., Reston, VA, USA, and/or its subsidiaries and/or its affiliates and/or their licensors.$
 * Use, reproduction, transfer, publication or disclosure is prohibited except as specifically provided for in your License Agreement with Software AG
 * $Revision: 294001 $ $Date: 2016-10-28 18:45:56 +0100 (Fri, 28 Oct 2016) $
 */

//*****************************************************************************
// Title:         Connectivity starter
// Description:   Starts connectivity plug-ins.  Remove this bundle for more fine-grained control over when connectivity starts.
// Dependencies:  None
// Author:        CREE
//
//*****************************************************************************

package com.apama.connectivity;

/** Notify that the application has been started.
 *
 * This event should be sent in to the correlator after all EPL files have been injected, and will result in
 * ConnectivityPlugins.onApplicationInitialized() being called, allowing the incoming messages to be received from
 * connectivity plug-ins and JMS.
 */
event ApplicationInitialized {
}

/** Monitor to start connectivity */
monitor ApplicationInitializedTransports {
	action onload() {
		on ApplicationInitialized() {
			com.softwareag.connectivity.ConnectivityPlugins.onApplicationInitialized();
		}
	}
}

 00000051 C:\dev\apama_win_full_latest\Apama\monitors\AutomaticOnApplicationInitialized.mon
MONF 0000c797 /*
 * $Copyright (c) 2012 Progress Software Corporation and/or its subsidiaries and affiliates. All rights reserved.$ 
 * $Copyright (c) 2013-2014, 2016-2018 Software AG, Darmstadt, Germany and/or Software AG USA Inc., Reston, VA, USA, and/or its subsidiaries and/or its affiliates and/or their licensors.$ 
 * Use, reproduction, transfer, publication or disclosure is prohibited except as specifically provided for in your License Agreement with Software AG 
 *
 * Event definitions for the Correlator-integrated Apama JMS adapter. 
 *
 * $Revision: 328106 $
 *
 */
package com.apama.correlator.jms;


// *****************************************************************************
// 
// Private event definitions - for internal use only. 
//

/** @private*/ event __AddSender
{
	string connectionId;
	string senderId;
	string senderReliability;
	dictionary<string,string> extraAddParams;
}

/** @private*/ event __RemoveSender
{
	string senderId;
}

/** @private*/ event __AddReceiver
{
	string connectionId;
	string receiverId;
	string destination;
	string receiverReliability;
	string durableTopicSubscriptionName;
	string messageSelector;
	boolean noLocal;
	dictionary<string,string> extraAddParams;
}

/** @private*/ event __RemoveReceiver
{
	string receiverId;
}

/** @private*/ event __JMSReceiverFlowControlWindowUpdate
{
	string receiverId;
	integer __processInstanceToken;
	integer __flowControlMarker;
	integer __flowControlWindow;
}

/** @private*/ event __ReceiverAcknowledgeAndResume
{
	string receiverId;
}

/** @private*/ event __JMSSenderFlush
{
	integer requestId;
	string channelName;
}

// *****************************************************************************
// 
// Public event API for dynamically adding/removing JMS senders and receivers
//
// To be notified about the successful addition or removal of senders and 
// receivers, applications should listen for the separate Sender/ReceiverStatus 
// events, looking for the OK or REMOVED status. 
//

/** An enumeration containing constants for the currently supported sender 
	reliability values.
*/
event JMSSenderReliability
{
	/** Best effort non-reliable messaging; events may be lost or duplicated 
		if a component fails. */
	constant string BEST_EFFORT := "BEST_EFFORT";
	/** Reliable messaging without duplicate detection. 
	
		Events may be  duplicated or reordered if a component fails, but will 
		not be lost. */
	constant string AT_LEAST_ONCE := "AT_LEAST_ONCE";
	/** Reliable messaging with duplicate detection identifiers. 
	
		Events may be reordered if a component fails, but will not be lost, 
		and will not be duplicated if the unique message ids are mapped into 
		the message and the receiving JMS client uses an appropriate duplicate 
		detection window. */
	constant string EXACTLY_ONCE := "EXACTLY_ONCE";
}

/** An enumeration containing constants for the message delivery modes for sender.
*/
event JMSMessageDeliveryMode
{
	/** Use PERSISTENT message delivery mode for sending messages to the broker.
	
		Reliable senders always use PERSISTENT message delivery mode.
	*/
	constant string PERSISTENT := "PERSISTENT";
	
	/** Use NON_PERSISTENT message delivery mode for sending messages to the broker.
	
		This is the default for BEST_EFFORT senders.
	*/
	constant string NON_PERSISTENT := "NON_PERSISTENT";
}

/** An event object representing an existing JMS sender. 
 *
 * A JMS sender has an associated channel to which Apama events can be "sent", 
 * which will then be mapped to JMS messages using the requested message 
 * reliability setting and delivered to a destination on the JMS message bus. 
 */
event JMSSender
{
	// Public
	
	/** Returns the unique identifier of this sender. */
	action getSenderId() returns string { return __senderId; }
	
	/** Returns the Correlator channel to use for events that should 
	 * be delivered to JMS using this sender. 
	 *
	 * Note that if this senderId does not exist or has been removed then 
	 * events sent to this channel will be lost without a warning. 
	 */
	action getChannel() returns string { return __channel; }
	
	/** Requests removal of this JMS sender. The removal will be performed 
	 * asynchronously, and completes after all events already sent by this 
	 * context have been passed to JMS, and the associated JMS producer and 
	 * session have been closed. 
	 *
	 * EPL applications may listen for the REMOVED JMSSenderStatus event to 
	 * detect when the removal has completed. 
	 *
	 * If the connection is currently down there could be an unbounded delay 
	 * in completing the removal of the sender. The application should not 
	 * send any more events to the sender channel once this action has been 
	 * called. 
	 *
	 * It is an error to attempt to remove a JMS sender that does not exist, or 
	 * to attempt to remove a static JMS sender. Such errors will result in 
	 * the termination of the current EPL monitor instance. 
	 * 
	 * @see JMSSenderStatus#REMOVED
	 */
	action remove()
	{
		__plugin.processControlEvent(__RemoveSender(__senderId).toString());
	}

	/** Returns the number of events that have been send to this sender's 
	 * channel from the application, but are still queued waiting to be sent to 
	 * JMS.
	 *
	 * This allows an EPL application to throttle or reduce the rate at which 
	 * it sends events based on the size of the backlog building up in the 
	 * Correlator's queues, to ensure that the Correlator does not run out of 
	 * memory due to a temporary peak in throughput rate or loss of the JMS 
	 * connection. 
	 *
	 * Calling this action is a slightly expensive operation, so it is best to 
	 * get the number of outstanding events once, then loop sending a batch of 
	 * events. Therefore do not call getOutstandingEvents inside a loop that is 
	 * continually sending events to JMS. 
	 *
	 * You must not call this method after calling remove().
	 */
	action getOutstandingEvents() returns integer
	{
		return __plugin.getOutstandingMessages(__senderId);
	}
	
	/** Requests a notification event after flushing all messages 
	 * already sent to the sender's channel by the current context. 
	 *
	 * A JMSSenderFlushed event will be sent to this context when all the 
	 * messages already sent to the sender channel have been processed 
	 * and passed to the JMS broker (or dropped, in the case of 
	 * non-recoverable mapping errors). 
	 *
	 * This feature is only applicable to BEST_EFFORT senders, as for 
	 * AT_LEAST_ONCE/EXACTLY_ONCE senders reliability is already taken care of 
	 * by the integration with Correlator state persistence. It is an error 
	 * to call this action from a persistent monitor. 
	 * 
	 * Applications may have multiple flush requests in flight at any one time. 
	 * Performance will be improved by sending multiple messages (e.g. 1000) 
	 * between each flush request.
	 *
	 * @returns The unique request id for flush request, which will be included 
	 * in the resulting JMSSenderFlushed event.
	 *
	 * @see JMSSenderFlushed Notification event sent in response to 
	 */
	action requestFlush() returns integer
	{
		__plugin.checkNonPersistentMonitor("requestFlush");
		integer requestId := integer.incrementCounter("apama.JMSSenderFlushRequest");
		string privateChannel := "com.apama.jms.backchannel." + context.current().getId().toString();
		monitor.subscribe(privateChannel);
		send __JMSSenderFlush(requestId, privateChannel) to self.getChannel();
		return requestId;
	}
	
	// Private
	
	/** @private*/ string __senderId;
	/** @private*/ string __channel;
	/** @private*/ import "JMSPlugin" as __plugin;

}

/** An event object representing the configuration of a new JMS sender, for 
 * dynamically adding JMS senders at runtime. 
 *
 * Call JMSConnection.createSenderConfiguration() to create an instance, and 
 * then use the setter actions to specify each required configuration option. 
 * Each setter method returns this configuration instance to make it possible 
 * to chain calls and specify all required options in a single statement. 
 *
 * @see JMSConnection#createSenderConfiguration() Creates a new 
 *	JMSSenderConfiguration event object. 
 * @see JMSConnection#addSenderWithConfiguration() Uses a JMSSenderConfiguration 
 *	to add a new JMS sender. 
 */
event JMSSenderConfiguration
{
	/** The unique identifier of this sender. */
	action getSenderId() returns string
	{ return __senderId; }

	/** The identifier of the connection this sender belongs to. */
	action getConnectionId() returns string
	{ return __connectionId; }
	
	/** Specifies the reliability mode to use for messages from this sender. 
	 * @param value Must be one of the enumeration constants from the 
	 * JMSSenderReliability event, or "" to indicate that the connection's 
	 * defaultSenderReliability should be used. 
	 * @see JMSSenderReliability
	 */
	action setSenderReliability(string value) returns JMSSenderConfiguration
	{ __senderReliability := value; return self; }
	/** Specifies the reliability mode to use for messages from this sender. */
	action getSenderReliability() returns string
	{ return __senderReliability; }
	
	/** Specifies the message delivery mode to use for messages from this sender.
	 *
	 * This can be used only for non-reliable BEST_EFFORT senders.
	 * It is ignored for reliable senders which always use PERSISTENT message 
	 * delivery mode.
	 *
	 * @param value Must be one of the enumeration constants from the 
	 * JMSMessageDeliveryMode event, or "" to indicate that the default mode will be used
	 * @see JMSMessageDeliveryMode
	 */
	action setMessageDeliveryMode(string value) returns JMSSenderConfiguration
	{ __messageDeliveryMode := value; return self; }
	/** Specifies the message delivery mode to use for messages from this sender. */
	action getMessageDeliveryMode() returns string
	{ return __messageDeliveryMode; }
	
	// Private fields
	
	/** @private*/ string __connectionId;
	/** @private*/ string __senderId;
	/** @private*/ string __senderReliability;
	/** @private*/ string __messageDeliveryMode;
	
	/** Initializes this object with required parameters 
	 * @private*/ 
	action __init(string connectionId, string senderId) 
	{
		self.__connectionId := connectionId;
		self.__senderId := senderId;
	}
	
	/** @private*/ 
	action __getAddSender() returns __AddSender
	{
		return __AddSender(
			getConnectionId(), 
			getSenderId(), 
			getSenderReliability(),
			{"MessageDeliveryMode":getMessageDeliveryMode()}
			);
	}
}

/** A notification event sent to an EPL application in response to a sender 
 * flush request.
 * 
 * The application context will receive this event after all the messages 
 * already sent by the application at the time of the flush request have been 
 * processed and passed to the JMS broker (or dropped, in the case of 
 * non-recoverable mapping errors). 
 *
 * This event will be sent to the context that requested message flushing.
 *
 * @see JMSSender#requestFlush()
 */
event JMSSenderFlushed
{
	/** The unique request id returned by the flush request.*/
	integer requestId;
	/** The identifier of sender. */
	string senderId;
}

/** An enumeration containing constants for the currently supported receiver 
	reliability values.
*/
event JMSReceiverReliability
{
	/** Best effort non-reliable messaging; events may be lost or duplicated 
		if a component fails. */
	constant string BEST_EFFORT := "BEST_EFFORT";
	/** Reliable messaging without duplicate detection; events may be 
		duplicated or reordered if a component fails, but will not be lost. */
	constant string AT_LEAST_ONCE := "AT_LEAST_ONCE";
	/** Reliable messaging with duplicate detection; events may be 
		reordered if a component fails, but will not be lost, and will not be 
		duplicated provided the unique message ids and duplicate detection 
		window are configured correctly. */
	constant string EXACTLY_ONCE := "EXACTLY_ONCE";
	/** Reliable messaging with acknowledgements controlled by the application.
	*/
	constant string APP_CONTROLLED := "APP_CONTROLLED";
}

/** An event object representing an existing JMS receiver. 
 *
 * A receiver listeners for messages on a specific JMS queue or topic, maps 
 * them to Apama events and sends them to the Correlator's public contexts. 
 */
event JMSReceiver
{
	// Public
	
	/** Returns the unique identifier of this receiver. */
	action getReceiverId() returns string { return __receiverId; }
	
	
	/** Requests removal of this JMS receiver. 
	 *
	 * The removal will be performed asynchronously, and completes after all 
	 * events already received from this JMS destination have been enqueued to 
	 * the Correlator, any persisted uniqueMessageIds no longer required for 
	 * duplicate detection have been deleted, any durable topic subscription 
	 * has been removed from the JMS broker, and the associated JMS consumer 
	 * and session have been closed. 
	 *
	 * EPL applications may listen for the REMOVED JMSReceiverStatus event to 
	 * detect when the removal has completed. 
	 *
	 * If the connection is currently down there could be an unbounded delay 
	 * in completing the removal of the receiver. 
	 *
	 * It is an error to attempt to remove a JMS receiver that does not exist, 
	 * or to attempt to remove a static JMS receiver. Such errors will result 
	 * in the termination of the current EPL monitor instance. 
	 * 
	 * @see JMSReceiverStatus#REMOVED
	 */
	action remove()
	{
		__plugin.processControlEvent(__RemoveReceiver(__receiverId).toString());
	}
	
	
	/** Signals that the application is ready for messages received 
	 * since the last appControlledAcknowledgeAndResume() call to be 
	 * acknowledged to JMS, and that message receiving can then resume. 
	 *
	 * This is used only by receivers which are running in APP_CONTROLLED 
	 * reliability mode. APP_CONTROLLED receivers should listen for the 
	 * JMSAppControlledReceivingSuspended event enqueued at the end of each 
	 * batch of incoming messages and respond by calling 
	 * appControlledAcknowledgeAndResume() once the messages or the output 
	 * events/state changes resulting from processing them have been reliably 
	 * stored in another system (e.g. sent and flushed to a downstream JMS 
	 * destination, or committed to a database or distributed MemoryStore). 
	 *
	 * To avoid race conditions, it is important to call this method only from 
	 * the context that is handling both the JMS messages from this receiver 
	 * and the JMSAppControlledReceivingSuspended event. 
	 * 
	 * Never call this method except in response to a 
	 * JMSAppControlledReceivingSuspended event, and do not call it from 
	 * a persistent monitor - both will result in an exception.
	 *
	 * @see JMSAppControlledReceivingSuspended
	 */
	action appControlledAcknowledgeAndResume() {
		__plugin.processControlEvent(__ReceiverAcknowledgeAndResume(__receiverId).toString());
	}
	
	// Private
	
	/** @private*/ string __receiverId;
	/** @private*/ import "JMSPlugin" as __plugin;

}

/** A notification event sent to an EPL application every time an APP_CONTROLLED 
 * receiver suspends, at the end of each message batch. 
 *
 * The application should respond by taking whatever action is required to 
 * ensure that the messages received since the last suspend 
 * or the output events/state changes resulting from processing them 
 * have been reliably stored in another system (e.g. sent and flushed to 
 * a downstream JMS destination, or committed to a database or distributed MemoryStore). 
 *
 * Once these operations have completed the application should call 
 * JMSReceiver.appControlledAcknowledgeAndResume() to signal that the message 
 * batch can be acknowledged to JMS (i.e. no longer needs to be retained for 
 * possible resending in the event of crash) and that receiving can resume. 
 *
 * This event will be sent to the same context(s) that are handling the 
 * messages from this receiver. 
 * The event will be sent at the end of every message 'batch' 
 * (see "maxBatchSize" in the documentation for more details). 
 * @see JMSReceiver#appControlledAcknowledgeAndResume()
 */
event JMSAppControlledReceivingSuspended
{
	/** The unique identifier of the suspended receiver. */
	string receiverId;
}


/** An event object representing the configuration of a new JMS receiver, for 
 * dynamically adding JMS receivers at runtime. 
 *
 * Call JMSConnection.createReceiverConfiguration() to create an instance, and 
 * then use the setter actions to specify each required configuration option. 
 * Each setter method returns this configuration instance to make it possible 
 * to chain calls and specify all required options in a single statement. 
 *
 * @see JMSConnection#createReceiverConfiguration() Creates a new 
 *	JMSReceiverConfiguration event object. 
 * @see JMSConnection#addReceiverWithConfiguration() Uses a 
 *	JMSReceiverConfiguration to add a new JMS receiver. 
 */
event JMSReceiverConfiguration
{
	/** The unique identifier of this receiver. */
	action getReceiverId() returns string
	{ return __receiverId; }

	/** The identifier of the connection this receiver belongs to. */
	action getConnectionId() returns string
	{ return __connectionId; }
	
	/** The queue or topic this receiver will listen to. */
	action getDestination() returns string
	{ return __destination; }
	
	/** Specifies the reliability mode to use for receiving messages. 
	 * @param value Must be one of the enumeration constants from the 
	 *	JMSReceiverReliability event, or "" to indicate that the connection's 
	 *	defaultReceiverReliability should be used. 
	 * @see JMSReceiverReliability
	 */
	action setReceiverReliability(string value) returns JMSReceiverConfiguration
	{ __receiverReliability := value; return self; }
	/** Specifies the reliability mode to use for receiving messages. */
	action getReceiverReliability() returns string
	{ return __receiverReliability; }
	
	/** Specifies the unique identifier for the subscription if a durable topic 
	 * subscription is to be created.
	 * @param value A unique JMS subscription name if a durable topic 
	 *	subscription should be created, or "" if a non-durable topic 
	 *	subscription should be made. Only valid for topics, and only if the 
	 *	reliability is not BEST_EFFORT.
	 */
	action setDurableTopicSubscriptionName(string value) returns JMSReceiverConfiguration
	{ __durableTopicSubscriptionName := value; return self; }
	/** Specifies the unique identifier for the subscription if a durable topic 
	 * subscription is to be created. */
	action getDurableTopicSubscriptionName() returns string
	{ return __durableTopicSubscriptionName; }

	/** Specifies the JMS message selector query string to select a subset of 
	 * queue/topic messages to be processed by this receiver. 
	 * @param value A message selector string, or "" to receive all messages. 
	 * See the JMS documentation for the javax.jms.Message interface for more 
	 * details. 
	 */
	action setMessageSelector(string value) returns JMSReceiverConfiguration
	{ __messageSelector := value; return self; }
	/** Specifies the JMS message selector query string to select a subset of 
	 * queue/topic messages to be processed by this receiver. */
	action getMessageSelector() returns string
	{ return __messageSelector; }

	/** Specifies an application-defined identifier to override how receivers 
	 * are grouped together for duplicate-detection purposes when using 
	 * EXACTLY_ONCE reliability. 
	 * @param value An arbitrary (but preferably short) string defined by the 
	 *	EPL application. All EXACTLY_ONCE receivers with this string will be 
	 *	grouped together to form a single duplicate detection domain. 
	 *
	 *	This is an advanced feature - by default, receivers are grouped into 
	 *	a duplicate detection domain together with other receivers in the 
	 *	same connectionId listening to the same destination, which is the 
	 *	correct setting in the majority of cases. 
	 */
	action setDupDetectionDomainId(string value) returns JMSReceiverConfiguration
	{ __dupDetectionDomainId := value; return self; }
	/** Specifies an application-defined identifier to override how receivers 
	 * are grouped together for duplicate-detection purposes when using 
	 * EXACTLY_ONCE reliability. */
	action getDupDetectionDomainId() returns string
	{ return __dupDetectionDomainId; }

	/** Specifies that messages sent to this destination by our own connection 
	 * should be ignored by the receiver. 
	 * @param value May be set to true or false for topic destinations. If 
	 *	the destination is a queue, the behaviour of noLocal=true is not 
	 *	specified, and will not work with many providers. The default value of 
	 *	false is usually fine. 
	 */
	action setNoLocal(boolean value) returns JMSReceiverConfiguration
	{ __noLocal := value; return self; }
	/** Specifies that messages sent to this destination by our own connection 
	 * should be ignored by the receiver. */
	action getNoLocal() returns boolean
	{ return __noLocal; }
	
	// Private fields
	
	/** @private*/ string __connectionId;
	/** @private*/ string __receiverId;
	/** @private*/ string __destination;
	/** @private*/ string __receiverReliability;
	/** @private*/ string __durableTopicSubscriptionName;
	/** @private*/ string __messageSelector;
	/** @private*/ string __dupDetectionDomainId;
	/** @private*/ boolean __noLocal;
	
	
	/** Initializes this object with required parameters 
	 * @private*/ 
	action __init(string connectionId, string receiverId, string destination) 
	{
		self.__connectionId := connectionId;
		self.__receiverId := receiverId;
		self.__destination := destination;
	}
	/** Initializes this object with required parameters 
	 * @private*/ 
	action __getAddReceiver() returns __AddReceiver
	{
		__AddReceiver result := new __AddReceiver;
		result.connectionId := getConnectionId();
		result.receiverId := getReceiverId();
		result.destination := getDestination();
		result.receiverReliability := getReceiverReliability();
		result.durableTopicSubscriptionName := getDurableTopicSubscriptionName();
		result.messageSelector := getMessageSelector();
		result.noLocal := getNoLocal();
		if getDupDetectionDomainId() != "" { result.extraAddParams["dupDetectionDomainId"] := getDupDetectionDomainId(); }
		
		return result;
	}
}

/** An event object representing a JMS connection, with actions for 
 * manipulating a connection's existing senders and receivers, and also for 
 * dynamically adding senders and receivers at runtime. 
 *
 * Senders and receivers may be added dynamically either using the 
 * comprehensive JMSConnection.addReceiver/SenderWithConfiguration() actions 
 * which provide access to all configuration parameters, or one of the 
 * other addReceiver/Sender*() actions that simplify creation of 
 * senders/receivers using the more common configuration parameter sets. 
 *
 * @see JMS#getConnection() Use this method to get a JMSConnection
 */
event JMSConnection
{
	// Public
	
	/** The unique identifier of this connection. */
	action getConnectionId() returns string 
	{
		return __connectionId;
	}

	/** Get a JMSReceiver event object representing a receiver that already 
	 * exists, which might have been added dynamically, or defined statically 
	 * in the XML configuration file. 
	 *
	 * It is the caller's responsibility to specify a valid receiverId - the  
	 * specified identifier is not be validated as part of this action call. 
	 * If the identifier does not represent an existing receiver then 
	 * operations on the returned JMSReceiver (such as remove()) will cause an 
	 * error. 
	 */
	static action getReceiver(string receiverId) returns JMSReceiver { return JMSReceiver(receiverId); }
	
	/** Get a JMSSender event object representing a sender that already 
	 * exists, which might have been added dynamically, or defined statically 
	 * in the XML configuration file. 
	 *
	 * It is the caller's responsibility to specify a valid senderId - the  
	 * specified identifier is not be validated as part of this action call. 
	 * If the identifier does not represent an existing sender then 
	 * operations on the returned JMSSender (such as remove()) will cause an 
	 * error. 
	 */
	static action getSender(string senderId) returns JMSSender { return JMSSender(senderId, "jms:"+senderId); }

	/** Get a JMSSender event object representing the default sender for this 
	 * connection (which exists automatically if no other static senders 
	 * were explicitly configured). 
	 */
	action getDefaultSender() returns JMSSender { return getSender(__connectionId+"-default-sender"); }

	
	/** Requests the addition of a new dynamic JMS sender, with the specified 
	 * reliability setting. 
	 *
	 * EPL applications may listen for the JMSSenderStatus event to be notified 
	 * when the new sender has been added, and when it has reached the 
	 * "OK" state. Events can be sent to the sender's channel as soon as 
	 * this action returns. 
	 *
	 * A unique senderId will be generated automatically. 
	 *
	 * The monitor instance will usually be terminated with an ERROR if invalid 
	 * arguments are provided. 
	 *
	 * @param senderReliability An enumeration value from JMSSenderReliability 
	 * indicating the reliability setting to use for sending events. 
	 * Alternatively, specify an empty string "" to use the connection's 
	 * defaultSenderReliability. 
	 *
	 * @return A JMSSender instance which can be used to get the senderId for 
	 * status monitoring, the channel to send events to, and an action for 
	 * removing the sender when it is no longer required. 
	 * @see JMSSenderReliability
	 */
	action addSender(string senderReliability) returns JMSSender
	{
		return addSenderWithConfiguration(createSenderConfiguration(__makeUniqueId("sender", senderReliability))
			.setSenderReliability(senderReliability));
	}
	
	
	/** Requests the addition of a new dynamic JMS sender, with the specified 
	 * sender configuration. 
	 *
	 * EPL applications may listen for the JMSSenderStatus event to be notified 
	 * when the new sender has been added, and when it has reached the 
	 * "OK" state. Note that no events will actually be sent into the 
	 * Correlator until JMS.onApplicationInitialized() has been called. 
 	 *
	 * The monitor instance will usually be terminated with an ERROR if invalid 
	 * arguments are provided. 
	 *
	 * @param config An event representing the configuration of the new sender, 
	 * constructed using JMSConnection.createSenderConfiguration and the 
	 * setter methods on JMSSenderConfiguration.
	 *
	 * @return A JMSSender instance which can be used to get the senderId for 
	 * status monitoring, the channel to send events to, and an action for 
	 * removing the sender when it is no longer required. 
	 *
	 * @see JMSConnection#createSenderConfiguration()
	 */
	action addSenderWithConfiguration(JMSSenderConfiguration config) returns JMSSender
	{
		__plugin.processControlEvent(config.__getAddSender().toString());
		return getSender(config.getSenderId());
	}
	
	/** Create a JMSSenderConfiguration for this connection that can be 
	 * used to add a new sender with the specified settings. 
	 *
	 * @param senderId An application-defined unique identifier for this 
	 * sender, used to track status and removal. The senderId must not be an 
	 * empty string or contain the colon ":" character - if it does, the 
	 * monitor will terminate with an error when trying to create the sender.
	 *
	 * Applications are encouraged to use <tt>integer.incrementCounter("apama.JMSSessionId").toString()</tt> 
	 * or a similar generator of unique numbers for all or part of the senderId. 
	 *
	 * @see JMSConnection#addSenderWithConfiguration()
	 */
	action createSenderConfiguration(string senderId) returns JMSSenderConfiguration
	{
		JMSSenderConfiguration result := new JMSSenderConfiguration;
		result.__init(__connectionId, senderId);
		return result;
	}

	/** Requests the addition of a new dynamic JMS receiver, with the specified 
	 * queue/topic name and reliability setting. 
	 *
	 * EPL applications may listen for the JMSReceiverStatus event to be 
	 * notified when the new receiver has been added, and when it has reached 
	 * the "OK" state. 
	 *
	 * A unique receiverId will be generated automatically. 
	 *
	 * The monitor instance will usually be terminated with an ERROR if invalid 
	 * arguments are provided. 
	 *
	 * @param destination A JMS queue name, JMS topic name, or JNDI name, 
	 *	prefixed by <tt>"queue:"</tt>, <tt>"topic:"</tt> or <tt>"jndi:"</tt>.
	 
	 * @param receiverReliability An enumeration value from 
	 *	JMSReceiverReliability indicating the reliability setting to use. 
	 *	Alternatively, specify an empty string "" to use the connection's 
	 *	defaultReceiverReliability. 
	 *
	 * @return A JMSReceiver instance which can be used to get the receiverId 
	 *	for status monitoring, and an action for removing the receiver when it 
	 *	is no longer required. 
	 * @see JMSReceiverReliability
	 */
	action addReceiver(string destination, string receiverReliability) returns JMSReceiver
	{
		return addReceiverWithConfiguration(
			createReceiverConfiguration(__makeUniqueId("receiver", destination), destination)
			.setReceiverReliability(receiverReliability));
	}

	/** Requests the addition of a new dynamic JMS durable topic subscription. 
	 *
	 * EPL applications may listen for the JMSReceiverStatus event to be 
	 * notified when the new receiver has been added, and when it has reached 
	 * the "OK" state. 
	 *
	 * This durable topic subscription will remain on the JMS broker until this 
	 * dynamic receiver is removed using JMSReceiver.remove(). 
	 *
	 * A unique receiverId will be generated automatically. 
	 *
	 * The monitor instance will usually be terminated with an ERROR if invalid 
	 * arguments are provided. 
	 *
	 * @param destination A JMS topic name, or JNDI name, 
	 *	prefixed by <tt>"topic:"</tt> or <tt>"jndi:"</tt>.
	 *
	 * @param receiverReliability An enumeration value from 
	 *	JMSReceiverReliability indicating the reliability setting to use.
	 
	 *	For a durable topic subscription, this must not be BEST_EFFORT.  
	 *	Specify an empty string "" to use the connection's 
	 *	defaultReceiverReliability. 
	 *
	 * @param durableTopicSubscriptionName The unique identifier used by the 
	 *	JMS broker for for this durable topic subscription. 
	 *
	 *	Must not be "", and must not match any other subscription name with the 
	 *	same connection clientID. 
	 *
	 * @param messageSelector An optional JMS message selector query string to 
	 *	select a subset of topic messages to be processed by this receiver, or 
	 *	"" to receive all messages. 
	 *
	 *	See the JMS documentation for the javax.jms.Message interface for more 
	 *	details. 

	 * @return A JMSReceiver instance which can be used to get the receiverId 
	 *	for status monitoring, and an action for removing the receiver when it 
	 *	is no longer required. 
	 * @see JMSReceiverReliability
	 * @see JMSReceiver#remove()
	 */
	action addReceiverWithDurableTopicSubscription(string destination, string receiverReliability, 
		string durableTopicSubscriptionName, string messageSelector) returns JMSReceiver
	{
		return addReceiverWithConfiguration(
			createReceiverConfiguration(__makeUniqueId("durable-subscriber", durableTopicSubscriptionName), destination)
			.setReceiverReliability(receiverReliability)
			.setMessageSelector(messageSelector)
			.setDurableTopicSubscriptionName(durableTopicSubscriptionName)
			);
	}

	/** Requests the addition of a new dynamic JMS receiver, with the specified 
	 * receiver configuration. 
	 *
	 * EPL applications may listen for the JMSReceiverStatus event to be 
	 * notified when the new receiver has been added, and when it has reached 
	 * the "OK" state. 
	 *
	 * The monitor instance will usually be terminated with an ERROR if invalid 
	 * arguments are provided. 
	 *
	 * @param config An event representing the configuration of the new 
	 * receiver, constructed using JMSConnection.createReceiverConfiguration 
	 * and the setter methods on JMSReceiverConfiguration.
	 *
	 * @return A JMSReceiver instance which can be used to get the receiverId 
	 * for status monitoring, and an action for removing the receiver when it 
	 * is no longer required. 
	 *
	 * @see JMSConnection#createReceiverConfiguration()
	 */
	action addReceiverWithConfiguration(JMSReceiverConfiguration config) returns JMSReceiver
	{
		__plugin.processControlEvent(config.__getAddReceiver().toString());
		return getReceiver(config.getReceiverId());
	}
	
	/** Create a JMSReceiverConfiguration for this connection that can be 
	 * used to add a new receiver with the specified settings. 
	 *
	 * @param receiverId An application-defined unique identifier for this 
	 * receiver, used to track status and removal. The receiverId must not be an 
	 * empty string or contain the colon ":" character - if it does, the 
	 * monitor will terminate with an error when trying to create the receiver.
	 *
	 * Applications are encouraged to use <tt>integer.incrementCounter("apama.JMSSessionId").toString()</tt> 
	 * or a similar generator of unique numbers for all or part of the receiverId. 
	 *
	 * @param destination A JMS queue name, JMS topic name, or JNDI name, 
	 * prefixed by <tt>"queue:"</tt>, <tt>"topic:"</tt> or <tt>"jndi:"</tt>.
	 *
	 * @see JMSConnection#addReceiverWithConfiguration()
	 */
	action createReceiverConfiguration(string receiverId, string destination) returns JMSReceiverConfiguration
	{
		JMSReceiverConfiguration result := new JMSReceiverConfiguration;
		result.__init(__connectionId, receiverId, destination);
		return result;
	}
	
	// Private
	
	/** @private*/ string __connectionId;
	/** @private*/ import "JMSPlugin" as __plugin;
	
	/** @private*/ 
	action __makeUniqueId(string requiredSuffix, string optionalSuffix) returns string {
		string result := __connectionId+"-"+requiredSuffix;
		if optionalSuffix != "" {
			result := result+"-"+optionalSuffix;
		}
		result := result.replaceAll(":","-"); // ensure it's a valid identifier
		return result + "-" + integer.incrementCounter("apama.JMSSessionId").toString();
	}
	
}

/** The top-level event object representing the Correlator-integrated JMS 
 * runtime.
 */
event JMS
{
	// Public
	
	/** Should be called by EPL applications after all EPL has been injected 
	 * and initialized, to indicate that the application is ready to receive 
	 * events from the JMS runtime, such as received JMS messages and 
	 * status notification events. 
	 *
	 * Invoking this action more than once will have no effect. 
	 *
	 */
	static action onApplicationInitialized() 
	{
		__plugin.onApplicationInitialized();
	}
	
	/** Get a JMSConnection event object representing a connection defined  
	 * in the XML configuration file. 
	 */
	static action getConnection(string connectionId) returns JMSConnection
	{
		return JMSConnection(connectionId);
	}
	
	/** Get a JMSReceiver event object representing a receiver that already 
	 * exists, which might have been added dynamically, or defined statically 
	 * in the XML configuration file. 
	 *
	 * It is the caller's responsibility to specify a valid receiverId - the  
	 * specified identifier is not be validated as part of this action call. 
	 * If the identifier does not represent an existing receiver then 
	 * operations on the returned JMSReceiver (such as remove()) will cause an 
	 * error. 
	 */
	static action getReceiver(string receiverId) returns JMSReceiver { return JMSConnection.getReceiver(receiverId); }
	
	/** Get a JMSSender event object representing a sender that already 
	 * exists, which might have been added dynamically, or defined statically 
	 * in the XML configuration file. 
	 *
	 * It is the caller's responsibility to specify a valid senderId - the  
	 * specified identifier is not be validated as part of this action call. 
	 * If the identifier does not represent an existing sender then 
	 * operations on the returned JMSSender (such as remove()) will cause an 
	 * error. 
	 */
	static action getSender(string senderId) returns JMSSender { return JMSConnection.getSender(senderId); }
	
	// Private
	
	/** @private*/ import "JMSPlugin" as __plugin;
}


//*****************************************************************************
//
// Status events
//

/** 
 * A notification event sent to an EPL application when a configured JMS 
 * connection encounters an error or changes state. 
 *
 * This event includes string constants for each supported status. 
 *
 * Note that all notification events will be held back until 
 * JMS.onApplicationInitialized() has been called. 
 */
event JMSConnectionStatus
{
	/** The unique identifier of the JMS connection. 
	*/
	string connectionId;

	/** An enumeration value specifying the status of the connection. The 
	 * values in the enumeration are provided as constants in this event. 
	 *
	 * If the status is OK then the connection is up. 
	 */
	string status;
	
	/** A user-readable string specifying the cause of the error. This should 
		always be a non-empty string when the status is "ERROR". */
	string errorMessage;
	
	/** Additional status information items. None are currently supported. */
	dictionary<string,string> extraStatusInfo;
	
	// enumeration constants for status field value:
	
	/** The status value indicating that the Correlator-JMS runtime is fully 
		connected to the JMS broker with a valid JMS Connection object. */
	constant string OK := "OK";
	
	/** The status value indicating that the Correlator-JMS runtime is trying
		to establish an initial connection.  */
	constant string CONNECTING := "CONNECTING";

	/** The status value indicating that the connection is not available due to 
		some non-fatal error condition; the Correlator-JMS runtime will keep 
		retrying in the background. */
	constant string ERROR := "ERROR";
}

/** 
 * A notification event sent to an EPL application when a configured JMS 
 * sender has been created successfully, encounters an error, or is removed. 
 *
 * This event includes string constants for each supported status, and 
 * fields specifying information about the configuration of this sender
 * (as specified when it was created). 
 *
 * Note that all notification events will be held back until 
 * JMS.onApplicationInitialized() has been called. 
 *
 * JMSSenderStatus events are sent for both static senders in the 
 * configuration file (or the implicitly defined default sender), and 
 * dynamic senders created with JMSConnection.addSender.
 */
event JMSSenderStatus
{
	/** The unique identifier of the JMS connection. 
	*/
	string connectionId;

	/** The unique identifier of this sender. 
	*/
	string senderId;

	/** An enumeration value specifying the status of the sender. The values
	 * in the enumeration are provided as constants in this event. 
	 *
	 * If the status is OK then the sender is functioning correctly; if it 
	 * is REMOVED then removal of the sender has completed.  
	 */
	string status;
	
	/** A user-readable string specifying the cause of the error. This is 
	 * guaranteed not empty if status="ERROR" or "FATAL_ERROR". */
	string errorMessage;
	
	/** Additional status information items. None are currently supported. */
	dictionary<string,string> extraStatusInfo;
	
	// enumeration constants for status field value:
	
	/** The status value indicating that the sender is fully connected to the 
		JMS broker with a valid JMS Producer object, and is available to send 
		messages. */
	constant string OK := "OK";
	
	/** The status value indicating that the sender is waiting for the 
		JMS connection or sender session to be established. */
	constant string CONNECTING := "CONNECTING";
	/** The status value indicating that the sender is not available due to 
		some non-fatal error condition; the Correlator-JMS runtime will keep 
		retrying in the background. */
	constant string ERROR := "ERROR";
	
	/** The status value indicating that the sender is not available due to 
		a fatal error condition. 
		
		Senders in this state are no longer useful and should be removed by the 
		EPL application (if dynamic) or the system administrator (if statically 
		defined in the XML config file). Note that the removal of such failed 
		senders does not happen automatically. */
	constant string FATAL_ERROR := "FATAL_ERROR";
	/** The status value indicating that the removal of a dynamic sender has 
		been completed, which will be sent some time after a sender removal 
		request, once all the associated state on the broker and the 
		Correlator's database has been removed. 
		
		In rare cases it's possible that a status event for a sender may be 
		sent after the REMOVED status; any such event should be ignored.  */
	constant string REMOVED := "REMOVED";
	
	// fields specifying the sender's configuration:

	/** Sender quality of service, specifying the reliability mode of the 
		messages from this sender. 
		
		One of the enumeration constants from the JMSSenderReliability event. */
	string senderReliability;

	/** Additional sender configuration parameters specified when it was added. 
	*/
	dictionary<string,string> extraAddParams;

}

/** 
 * A notification event sent to an EPL application when a configured JMS 
 * receiver has been created successfully, encounters an error, or is removed. 
 *
 * This event includes string constants for each supported status, and 
 * fields specifying information about the configuration of this receiver
 * (as specified when it was created). 
 *
 * Note that the ordering of JMSReceiverStatus events relative to received 
 * messages is not defined. Also note that notification events will be held 
 * back until JMS.onApplicationInitialized() has been called. 
 *
 * JMSReceiverStatus events are sent for both static receivers in the 
 * configuration file, and dynamic receivers created with 
 * JMSConnection.addReceiver.
 */
event JMSReceiverStatus
{
	/** The unique identifier of the JMS connection.  */
	string connectionId;
	
	/** The unique identifier of this receiver. */
	string receiverId;

	/** An enumeration value specifying the status of the receiver. The values
	 * in the enumeration are provided as constants in this event. 
	 *
	 * If the status is OK then the receiver is functioning correctly; if it 
	 * is REMOVED then removal of the receiver has completed.  
	 */
	string status;
	
	/** A user-readable string specifying the cause of the error. This is 
	 * guaranteed not empty if status="ERROR" or "FATAL_ERROR". */
	string errorMessage;

	// enumeration constants for status field value:
	
	/** The status value indicating that the receiver is fully connected to the 
		JMS broker with a valid JMS Consumer object, and is available to receive 
		messages. */
	constant string OK := "OK";
	
	/** The status value indicating that the receiver is waiting for the 
		JMS connection or receiver session to be established. */
	constant string CONNECTING := "CONNECTING";
	/** The status value indicating that the receiver is not available due to 
		some non-fatal error condition; the Correlator-JMS runtime will keep 
		retrying in the background. */
	constant string ERROR := "ERROR";

	/** The status value indicating the  receiver could not be found because of 
		a problem accessing the specified destination (i.e. a JMS or JNDI 
		error). */
	constant string DESTINATION_NOT_FOUND := "DESTINATION_NOT_FOUND"; 	

	/** The status value indicating that the receiver is not available due to 
		a fatal error condition. 
		
		Receivers in this state are no longer useful and should be removed by 
		the EPL application (if dynamic) or the system administrator (if 
		statically defined in the XML config file). The removal of such failed 
		receivers does not happen automatically. 
	*/
	constant string FATAL_ERROR := "FATAL_ERROR";

	/** The status value indicating that the removal of a dynamic receiver has 
		been completed, which will be sent some time after a receiver removal 
		request, once all the associated state on the broker and the 
		Correlator's database has been removed. 
		
		In rare cases it's possible that a status event for a receiver may be 
		sent after the REMOVED status; any such event should be ignored.  */
	constant string REMOVED := "REMOVED";
	
	/** Additional status information items. None are currently supported. */
	dictionary<string,string> extraStatusInfo;

	// fields specifying the receiver's configuration:
	
	/** A JMS queue name, JMS topic name, or JNDI name, prefixed by 
		<tt>"queue:"</tt>, <tt>"topic:"</tt> or <tt>"jndi:"</tt>. */
	string destination;
	/** Receiver quality of service, specifying the reliability mode used 
		for receiving messages. 
		
		One of the enumeration constants from the JMSReceiverReliability event*/
	string receiverReliability;
	/** A unique JMS subscription name if a durable topic subscription should 
		be created, or "" if a non-durable topic subscription should be made. */
	string durableTopicSubscriptionName;
	/** JMS message selector string, to specify a subset of messages from the 
		destination to be processed by this receiver. 
	*/
	string messageSelector;
	/** Specifies that messages sent to this destination by our own connection 
		should be ignored by the receiver. */
	boolean noLocal;
	/** Additional receiver configuration parameters. None currently supported. */
	dictionary<string,string> extraAddParams;
}

//*****************************************************************************
//
// Advanced control events
//


/** A control event periodically sent to an EPL application for each receiver 
 * with receiverFlowControl enabled, which the application uses to update 
 * the flow control window.
 *
 * This event is used as a baseline from which the EPL application specifies 
 * the size of the window of new events it is currently ready to receive, 
 * specified relative to the last event received before this marker. 
 *
 * The event is sent:
 * i) when a receiver with receiverFlowControl=true is first added 
 * (once onApplicationInitialized has been called), 
 * ii) during recovery (in a persistent correlator), and 
 * iii) also periodically as JMS messages are received and 
 * enqueued to the correlator (typically these events are sent as often as 
 * the configured maxBatchSize, e.g. at least once every 1000 events). 
 *
 * To correctly implement the receiver flow control protocol, applications must 
 * respond to this event by calling updateFlowControlWindow (see below) 
 * to indicate the maximum number of additional events that the JMS runtime 
 * should take from this receiver, using the point in the event stream at 
 * which this marker was received as the baseline. 
 *
 * Applications that wish to  use flow control to throttle message receiving 
 * based on the number of outstanding asynchronous operations from 
 * already-received messages (to put a finite bound on memory usage) should 
 * also cache the most recent JMSReceiverFlowControlMarker for each 
 * active JMSReceiver so that the flow control window can be updated 
 * (e.g. extended) as pending operations complete, since there is no guarantee 
 * another JMSReceiverFlowControlMarker event will be sent until the window 
 * is extended enough for more events to be received. 
 *
 * Note that the fields of this event (apart from receiverId) are intended as 
 * 'opaque' data for internal use only and should be ignored by customer code.
 *
 * @see JMSReceiverFlowControlMarker#updateFlowControlWindow() Set the flow 
 * control window for this receiver, relative to this marker. 
 */ 
event JMSReceiverFlowControlMarker
{
	/** The unique identifier of this receiver. */
	string receiverId;
	
	/** For internal use only, treat as opaque data. */ 
	integer __processInstanceToken;
	
	/** For internal use only, treat as opaque data. */ 
	integer __flowControlMarker;
	
	/**
	* Sets the current flow control window size for a given receiver, which 
	* indicates the number of extra Apama events that should be taken from JMS 
	* and passed to the application before blocking, relative to the last data 
	* event received before this marker. 
	*
	* @param windowSizeEvents The maximum number of new events that should be 
	* received from this JMS receiver and enqueued to the correlator, relative 
	* to the position in the event flow indicated by this marker. 
	* The window size may be a constant number (e.g. 10,000 events) for 
	* applications that immediately process received events to completion,
	* or it may have a number of 'pending' events subtracted from it to create 
	* a bound on on the number of events that may be received from the JMS 
	* broker but are not yet been fully processed by the application (e.g. if 
	* an asynchronous database operation must complete before the memory, data 
	* structures or event listeners associated with the event may be deleted).
	*
	* It is valid to supply a zero or negative number for this value, in which 
	* case the JMS runtime will attempt to pause receiving, and take no more 
	* messages from the JMS queue/topic until this action is called again 
	* with a positive window (though it is not possible to guarantee that the 
	* flow of events will stop immediately, since some events could already be 
	* queued up). To allow an unbounded number of events to be received, 
	* specify integer.MAX for windowSizeEvents.
	* 
	* It is important that the overall long-term maximum window size 
	* (i.e. the chosen constant upper bound, ignoring any currently pending 
	* operations) is greater than than the receiver's maxBatchSize 
	* (typically 1000). 
	*/
	action updateFlowControlWindow(integer windowSizeEvents)
	{
		// use 'UnlessDisabled' as this should be a no-op when JMS is disabled, to support replay log
		__plugin.processControlEventUnlessDisabled(__JMSReceiverFlowControlWindowUpdate(
			receiverId, __processInstanceToken, __flowControlMarker, windowSizeEvents).toString()
		);
	}
	
	/** @private*/ import "JMSPlugin" as __plugin;
}
 00000043 C:\dev\apama_win_full_latest\Apama\monitors\CorrelatorJMSEvents.mon
MONF 00002fd8 //*****************************************************************************
// Title:       StatusSupport
// Description: Provides event definitions for generic status reporting from  
//              service monitors.
//
// Revision:    $Revision: 357639 $
//
// $Copyright(c) 2006-2007, 2008-2009, 2011-2012 Progress Software Corporation (PSC). All rights reserved.$
// $Copyright (c) 2013-2015, 2019 Software AG, Darmstadt, Germany and/or Software AG USA Inc., Reston, VA, USA, and/or its subsidiaries and/or its affiliates and/or their licensors.$
// Use, reproduction, transfer, publication or disclosure is prohibited except as specifically provided for in your License Agreement with Software AG
//
//*****************************************************************************

package com.apama.statusreport;

/*
	The events defined in this file act as an API between applications
	and service monitors.  They provide functionality to 
	Subscribe to status messages.
	
	The aim of this API is to provide an abstraction over any adapter
	specific details - for example, some adapters may require an explicit 
	call to subscribe to such data, some may be sent it anyway.
	
	Any adapter specific information that the application needs to supply
	or be supplied can be passed in the extraParams dictionary - these 
	are free-form (though there are conventions on the keys, see below).
	
	The service monitor also needs to handle any session initiation that
	may be required.
	
	A Status event does not denote a change of state, merely what the current
	state is - in particular, one will be sent out after every 
	SubscribeStatus request.

	All operations and responses are keyed on serviceId (if non-blank), 
	object,	connection and subServiceID. Every event starts with these 4 
	fields.
	
*/


/**
 *	Sent to the SubscribeStatus chanenl to subscribe to status.
 *	
 */
event SubscribeStatus {
	constant string CHANNEL := "SubscribeStatus";
	/**
	 *	service ID to subscribe to - blank will target all services.
	 */
	string serviceID;
	
	/**
	 *	object to request status of - this may include:
	 *	"Connection" - whether connected or not
	 *	"Market" - a market may be "Open", "Closed", or other states
	 */
	string object;
	
	/**
	 *	subService ID to subscribe to.
	 *	Some services may expose several services.  The interpretation of
	 *	this string is adapter-specific.
	 */
	string subServiceID;
	
	/**
	 *	connection to subscribe to.
	 *	Some services may expose several services.  The interpretation of
	 *	this string is adapter-specific.
	 */
	string connection;
}

/**
 *	Sent to the service monitor to unsubscribe from status.
 *	
 */
event UnsubscribeStatus {	 
	constant string CHANNEL := "SubscribeStatus";
	/**
	 *	service ID to subscribe to - blank will target all services
	 */
	string serviceID;
	
	/**
	 *	object to request status of - this may include:
	 *	"Connection" - whether connected or not
	 *	"Market" - a market may be "Open", "Closed", or other states
	 */
	string object;
	
	/**
	 *	subService ID to subscribe to.
	 *	Some services may expose several services.  The interpretation of
	 *	this string is adapter-specific.
	 */
	string subServiceID;
	
	/**
	 *	connection to subscribe to.
	 *	Some services may expose several services.  The interpretation of
	 *	this string is adapter-specific.
	 */
	string connection;
}


/**
 *	Sent from the service monitor to the StatusReport channel to notify the application of status for a 
 *	subscribed item.
 *	
 */
event Status {	
	constant string CHANNEL := "StatusReport";
	/**
	 *	service ID to subscribe to - blank will target all services
	 */
	string serviceID;
	
	/**
	 *	object to request status of - this may include:
	 *	"Connection" - whether connected or not
	 *	"MarketState" - a market may be "Open", "Closed", or other states
	 */
	string object;
	
	/**
	 *	subService ID to subscribe to.
	 *	Some services may expose several services.  The interpretation of
	 *	this string is adapter-specific.
	 */
	string subServiceID;
	
	/**
	 *	connection to subscribe to.
	 *	Some services may expose several services.  The interpretation of
	 *	this string is adapter-specific.
	 */
	string connection;

	/**
	 *	status description.
	 *	A free-form text string giving a description of the status.
	 */
	string description;
	
	/**
	 *	A sequence of summary strings specifying information about the 
	 *	status of the specified object.  This will be a well recognized
	 *	sequence of words - for example, a financial market's
	 *	"MarketState" may be "Open", "Closed", "PreOpen", etc.  A Connection 
	 *	may be "Connected", "Disconnected", "Disconnected LoginFailed", 
	 *	"Disconnected TimedOut", etc. 
	 */
	sequence<string> summaries;

	/**
	 *	available.
	 *	True if the object is "available" - the exact meaning is adapter 
	 * 	specific; for example, connected, open for general orders, etc.
	 */
	 boolean available;
	 
	 /** 
	 *	extra parameters that do not map into any of the above.  Convention
	 *	is that keys are in TitleCase.  e.g. "Username", "CloseTime", etc.
	 */
	wildcard dictionary <string, string> extraParams;
}


event StatusError {
	constant string CHANNEL := "StatusReport";
	/**
	 *	service ID to subscribe to - blank will target all services
	 */
	string serviceID;
	
	/**
	 *	object to request status of - this may include:
	 *	"Connection" - whether connected or not
	 *	"MarketState" - a market may be "Open", "Closed", or other states
	 */
	string object;
	
	/**
	 *	subService ID to subscribe to.
	 *	Some services may expose several services.  The interpretation of
	 *	this string is adapter-specific.
	 */
	string subServiceID;
	
	/**
	 *	connection to subscribe to.
	 *	Some services may expose several services.  The interpretation of
	 *	this string is adapter-specific.
	 */
	string connection;

	/**
	 *	status description.
	 *	A free-form text string giving a description of the status.
	 */
	string description;
	
	/**
	 *	Whether the subscription has been terminated.  Any subscribers will 
	 *	need to send a new SubscribeStatus request after this.
	 */
	boolean failed;
}
	
//*****************************************************************************
// Title:         ParallelStatusSupport
// Description:   ParallelStatusSupport description
// Dependencies:  None
// Author:        arrustem
//
//*****************************************************************************

/*
	Event definitions for block subject event wrappers;
	These are provided for backwards compatibility.  Monitors listening to status should instead subscribe to the "StatusReport" channel.
*/
event SubscribeStatusToContext {
	context instanceContext;
	SubscribeStatus subscribe;
}

event UnsubscribeStatusToContext {
	context instanceContext;
	UnsubscribeStatus unsubscribe;
}

monitor ParallelStatusSupport {
	/*	dictionary < [serviceId] , sequence of contexts > eventRouter;
	 - eventRouter will keep track of all contexts that are listening to a particular symbol
	 - The same d.s. will be used for both, Status and StatusError
	   since they are added/removed precisely at the same time. 
	*/
	dictionary < string , sequence<context> > eventRouter;
	
	/*	dictionary < [serviceId], dictionary < [contextId], [key ctr] > > statusToContextCtr;
	 - Keeps count of number of listeners for each symbol on each context
	*/
	dictionary < string, dictionary < integer, integer > > statusToContextCtr;

	/*	dictionary < [serviceId], listener > statusListeners;
	 - keeps track of the local listeners for Status
		dictionary < [serviceId], listener > errorListeners;
	 - keeps track of the local listeners for StatusError
	*/
	dictionary < string, listener > statusListeners;
	dictionary < string, listener > errorListeners;
	
	action onload() {
		monitor.subscribe("StatusReport");
		// set up listeners for the wrapped events coming from subjects
		SubscribeStatusToContext subscribe;
		on all SubscribeStatusToContext():subscribe subscribeEventHandler(subscribe);
		
		UnsubscribeStatusToContext unsubscribe;
		on all UnsubscribeStatusToContext():unsubscribe unsubscribeEventHandler(unsubscribe);
	}
	
	action ondie() {
                // print out an error if statusToContextCtr is not empty
                if (statusToContextCtr.size() != 0) {
                        log "ParallelStatusSupport is terminating but there may still be contexts subscribed to Status events" at ERROR;
                }
                else {
                        log "ParallelStatusSupport is terminating" at INFO;
                }
	}
	
	action onunload() {
		// not doing anything here since it is assumed that only one instance of this monitor is executing 
	}
	
	action subscribeEventHandler(SubscribeStatusToContext evt) {
		
		string key := evt.subscribe.serviceID;
		integer cId := evt.instanceContext.getId();
		
		// manage statusToContextCtr
		if not statusToContextCtr.hasKey(key) {
			dictionary <integer, integer> entry := {cId:0};
			statusToContextCtr.add(key, entry);
		}
		else {
			if not statusToContextCtr[key].hasKey(cId) {
				statusToContextCtr[key].add(cId, 0);
				
			}
		}
		statusToContextCtr[key][cId] := statusToContextCtr[key][cId] + 1;
		
		// manage eventRouter
		if not eventRouter.hasKey(key) {
			sequence < context > entry := [];
			eventRouter.add(key, entry);
			addListener(key);
		}
		// look up context in the symbol
		if (eventRouter[key].indexOf(evt.instanceContext) = -1) {
			eventRouter[key].append(evt.instanceContext);
		}

		route evt.subscribe;
	}

	action unsubscribeEventHandler(UnsubscribeStatusToContext evt) {
		string key := evt.unsubscribe.serviceID;
		
		integer cId := evt.instanceContext.getId();
		
		// manage statusToContextCtr
		if ((not statusToContextCtr.hasKey(key)) or 
			(not statusToContextCtr[key].hasKey(cId))) {
			log "unsubscribeEventHandler: unexpected UnsubscribeStatusToContext received for (key=" + 
				key.toString() + ", contextId=" + cId.toString() + ")" at WARN;
		}
		else {
			statusToContextCtr[key][cId] := statusToContextCtr[key][cId] - 1;
			if (statusToContextCtr[key][cId] = 0) {
				statusToContextCtr[key].remove(cId);
				integer i := eventRouter[key].indexOf(evt.instanceContext);
				if (i != -1) {
					eventRouter[key].remove(i);
				}
			}
			if (statusToContextCtr[key].size() = 0) {
				eventRouter.remove(key);
				removeListener(key);
			}
		}

		route evt.unsubscribe;
	}
	
	action addListener(string serviceID) {
		listener dl, el;
		context c;
		Status d;
		dl := on all Status(serviceID=serviceID):d {
			//send d to eventRouter[serviceID];
			for c in eventRouter[serviceID] {
				if c.getId() != context.current().getId() {
					send d to c;
				}
			}			
		}
		if statusListeners.hasKey(serviceID) {
			log "[action addListener] statusListeners already contains a listener for entry " + serviceID at WARN;
		}
		else {
			statusListeners.add(serviceID, dl);
		}
		
		StatusError e;
		el := on all StatusError(serviceID=serviceID):e {
			//send e to eventRouter[serviceID];
			for c in eventRouter[serviceID] {
				if c.getId() != context.current().getId() {
					send e to c;
				}
			}
		}
		if errorListeners.hasKey(serviceID) {
			log "[action addListener] errorListeners already contains a listener for entry " + serviceID at WARN;
		}
		else {
			errorListeners.add(serviceID, el);
		}
	}
	
	action removeListener(string serviceID) {

		if statusListeners.hasKey(serviceID) {
			statusListeners[serviceID].quit();
			statusListeners.remove(serviceID);
		}
		else {
			log "[action removeListener] statusListeners does not contain a listener for entry " + serviceID at WARN;			
		}
		
		if errorListeners.hasKey(serviceID) {
			errorListeners[serviceID].quit();
			errorListeners.remove(serviceID);
		}
		else {
			log "[action removeListener] errorListeners does not contain a listener for entry " + serviceID at WARN;			
		}
	}
}

 0000003d C:\dev\apama_win_full_latest\Apama\monitors\StatusSupport.mon
TIME 0000000e 1568382756.6,1
MONF 000033e8 /*
 * Apama Correlator-integrated JMS Status Manager service.
 *
 * Implements the StatusSupport event interface to allow an EPL application to 
 * monitor status information about the status of Correlator-Integrated JMS connections, 
 * senders and receivers.
 * 
 * $Copyright (c) 2012 Progress Software Corporation and/or its subsidiaries and affiliates. All rights reserved.$ 
 * $Copyright (c) 2013 Software AG, Darmstadt, Germany and/or Software AG USA Inc., Reston, VA, USA, and/or its subsidiaries and/or its affiliates and/or their licensors.$ 
 * Use, reproduction, transfer, publication or disclosure is prohibited except as specifically provided for in your License Agreement with Software AG 
 *
 */
package com.apama.correlator.jms;

using com.apama.correlator.jms.JMSConnectionStatus;
using com.apama.correlator.jms.JMSSenderStatus;
using com.apama.correlator.jms.JMSReceiverStatus;
using com.apama.statusreport.Status;
using com.apama.statusreport.StatusError;
using com.apama.statusreport.SubscribeStatus;
using com.apama.statusreport.UnsubscribeStatus;


/**
 * Provides a bridge between the JMS-specific status events and the generic 
 * StatusSupport API used by some Apama applications. 
 *
 * @see com.apama.statusreport.SubscribeStatus Generic StatusSupport 
 * status subscription request that an application may send to SubscribeStatus.CHANNEL.
 * @see com.apama.statusreport.Status Generic StatusSupport 
 * status information sent to the Status channel by this monitor for subscribed 
 * objects.
 */
monitor CorrelatorJMSStatusManager 
{
	dictionary<SubscribeStatus, integer> subs;

	dictionary<string, JMSConnectionStatusPublisher> csPubs;
	dictionary<string, JMSSenderStatusPublisher> ssPubs;
	dictionary<string, JMSReceiverStatusPublisher> rsPubs;

	action onload() 
	{
		// Set up listeners for client requests
		listenForSubscribeStatus();
		listenForUnsubscribeStatus();
	
		// Set up listeners for correlator-jms status events
		listenForNewJmsEntities();
	}

	action ondie()
	{
		//Can't distinguish between abnormal termination and shutdown,
		//so just log a message to indicate termination.
		log "CORRELATOR_JMS status manager has terminated." at INFO;
	}

	action listenForSubscribeStatus()
	{
		monitor.subscribe(SubscribeStatus.CHANNEL);
		SubscribeStatus newSub;
		on all SubscribeStatus("CORRELATOR_JMS", *, *, *):newSub
		{
			if isValidSubscription(newSub) 
			{
				log "Received status subscription: " + newSub.toString() at INFO;

				if subs.hasKey(newSub) { subs.add(newSub, subs[newSub] + 1); }
				else { subs.add(newSub, 1); }

				boolean atLeastOneAckSent := false;
				
				JMSConnectionStatusPublisher csPub;
				for csPub in csPubs.values()
				{
					atLeastOneAckSent := csPub.ackMatchingNewSub(newSub) or atLeastOneAckSent;
				}

				JMSSenderStatusPublisher ssPub;
				for ssPub in ssPubs.values()
				{
					atLeastOneAckSent := ssPub.ackMatchingNewSub(newSub) or atLeastOneAckSent;
				}

				JMSReceiverStatusPublisher rsPub;
				for rsPub in rsPubs.values()
				{
					atLeastOneAckSent := rsPub.ackMatchingNewSub(newSub) or atLeastOneAckSent;
				}

				if not atLeastOneAckSent 
				{
					log "No status events received yet from entities matching subscription: " + newSub.toString() at INFO;
					sequence<string> summaries := [ "UNKNOWN" ];
					dictionary<string,string> extraParams := {};	
					Status status := Status("CORRELATOR_JMS", newSub.object, newSub.subServiceID, newSub.connection, "No status events received yet from entities matching subscription", summaries, false, extraParams);
					send status to Status.CHANNEL; 
				}
			}
		}
	}

	action listenForUnsubscribeStatus() 
	{
		UnsubscribeStatus unsub;
		on all UnsubscribeStatus("CORRELATOR_JMS", *, *, *):unsub
		{
			if isValidUnsubscription(unsub)
			{
				log "Received status unsubscription: " + unsub.toString() at INFO;
				SubscribeStatus key := SubscribeStatus(unsub.serviceID, unsub.object, unsub.subServiceID, unsub.connection);
	
				if subs.hasKey(key)
				{
					if subs[key] <= 1
					{
						subs.remove(key);	
					}
					else { subs[key] := subs[key] - 1; }
				}
				else
				{
					log "No subscription exists that matches unsubscription: " + unsub.toString() at DEBUG;
				}
			}
		}
	}

	action listenForNewJmsEntities()
	{
		JMSConnectionStatus cs;
		on all JMSConnectionStatus():cs
		{
			if not csPubs.hasKey(cs.connectionId)
			{
				log "Received connection status from new connection: " + cs.toString() at DEBUG;
				JMSConnectionStatusPublisher csPub := new JMSConnectionStatusPublisher;
				csPub.activate(cs, subs);
				csPubs.add(cs.connectionId, csPub);
			}
		}	

		JMSSenderStatus ss;
		on all JMSSenderStatus():ss
		{
			if not ssPubs.hasKey(ss.connectionId + ":" + ss.senderId)
			{
				log "Received sender status from new sender: " + ss.toString() at DEBUG;
				JMSSenderStatusPublisher ssPub := new JMSSenderStatusPublisher;
				ssPub.activate(ss, subs);
				ssPubs.add(ss.connectionId + ":" + ss.senderId, ssPub);
			}
		}	

		JMSReceiverStatus rs;
		on all JMSReceiverStatus():rs
		{
			if not rsPubs.hasKey(rs.connectionId + ":" + rs.receiverId)
			{
				log "Received receiver status from new receiver: " + rs.toString() at DEBUG;
				JMSReceiverStatusPublisher rsPub := new JMSReceiverStatusPublisher;
				rsPub.activate(rs, subs);
				rsPubs.add(rs.connectionId + ":" + rs.receiverId, rsPub);
			}
		}	
	}

	action isValidSubscription(SubscribeStatus sub) returns boolean 
	{ 
		return isValidSubOrUnsub(sub.serviceID, sub.object, sub.subServiceID, sub.connection, "SubscribeStatus", sub.toString()); 
	}	

	action isValidUnsubscription(UnsubscribeStatus unsub) returns boolean 
	{ 
		return isValidSubOrUnsub(unsub.serviceID, unsub.object, unsub.subServiceID, unsub.connection, "UnsubscribeStatus", unsub.toString()); 
	}	

	action isValidSubOrUnsub(string serviceID, string object, string subServiceID, string connection, string requestType, string asString) returns boolean
	{
		string errMsg;
		if serviceID = "CORRELATOR_JMS"
		{
			if object = ""
			{
				if not subServiceID = ""
				{
					errMsg := "Invalid CORRELATOR_JMS " + requestType + " (subServiceID must be \"\" when object is \"\"): " + asString;	
					send StatusError(serviceID, object, subServiceID, connection, errMsg, true) to StatusError.CHANNEL;
					return false;
				}
			}
			else if object = "CONNECTION"
			{
				if connection = ""
				{
					errMsg := "Invalid CORRELATOR_JMS " + requestType + " (connection may not be \"\" when object is \"CONNECTION\"): " + asString;
					send StatusError(serviceID, object, subServiceID, connection, errMsg, true) to StatusError.CHANNEL;
					return false;
				}

				if not subServiceID = ""
				{
					errMsg := "Invalid CORRELATOR_JMS " + requestType + " (subServiceID must be \"\" when object is \"CONNECTION\"): " + asString;	
					send StatusError(serviceID, object, subServiceID, connection, errMsg, true) to StatusError.CHANNEL;
					return false;
				}
			}
			else if object = "SENDER" or object = "RECEIVER"
			{
				if connection = ""
				{
					errMsg := "Invalid CORRELATOR_JMS " + requestType + " (connection may not be \"\" when object is \"" + object + "\"): " + asString;
					send StatusError(serviceID, object, subServiceID, connection, errMsg, true) to StatusError.CHANNEL;
					return false;
				}

				if subServiceID = ""
				{
					errMsg := "Invalid CORRELATOR_JMS " + requestType + " (subServiceID may not be \"\" when object is \"" + object + "\"): " + asString;	
					send StatusError(serviceID, object, subServiceID, connection, errMsg, true) to StatusError.CHANNEL;
					return false;
				}
			}
			else
			{ 
				errMsg := "Invalid CORRELATOR_JMS " + requestType + " (valid values for object field are \"CONNECTION\", \"SENDER\", \"RECEIVER\" or \"\"): " + asString;
				send StatusError(serviceID, object, subServiceID, connection, errMsg, true) to StatusError.CHANNEL;
				return false; 
			} 
			
			return true;
		}
		else 
		{ 
			errMsg := "Unexpected request to validate non-CORRELATOR_JMS " + requestType + " (serviceID must be CORRELATOR_JMS): " + asString;
			send StatusError(serviceID, object, subServiceID, connection, errMsg, true) to StatusError.CHANNEL;
			return false; 
		}
	}

	event JMSConnectionStatusPublisher
	{
		JMSConnectionStatus current;	
		dictionary<SubscribeStatus, integer> allSubs;
		
		action activate(JMSConnectionStatus cs, dictionary<SubscribeStatus, integer> subs) 
		{
			current := cs;
			allSubs := subs;

			if existsMatchingSub() { sendStatus(); }

			JMSConnectionStatus update;
			on all JMSConnectionStatus(current.connectionId, *, *, *):update
			{
				current := update;	
				if existsMatchingSub() { sendStatus(); }	
			}
		}

		action existsMatchingSub() returns boolean 
		{ 
			SubscribeStatus sub;
			for sub in allSubs.keys()
			{
				if matches(sub) { return true; }
			}
			return false;
		}

		action matches(SubscribeStatus sub) returns boolean
		{
			return (sub.object = "" and (sub.connection = "" or sub.connection = current.connectionId)) or 
	 			(sub.object = "CONNECTION" and sub.connection = current.connectionId);
		}

		action ackMatchingNewSub(SubscribeStatus newSub) returns boolean 
		{ 
			if matches(newSub)
			{
				sendStatus();
				return true;
			} 
			return false;
		}

		action sendStatus() 
		{
			boolean available := false;
			if (current.status = JMSConnectionStatus.OK) { available := true; }

			sequence<string> summaries := [ current.status ];
			dictionary<string,string> extraParams := {};	
			Status status := Status("CORRELATOR_JMS", "CONNECTION", "", current.connectionId, current.errorMessage, summaries, available, extraParams);
			send status to Status.CHANNEL;
		}
	}

	event JMSSenderStatusPublisher
	{
		JMSSenderStatus current;	
		dictionary<SubscribeStatus, integer> allSubs;

		action activate(JMSSenderStatus ss, dictionary<SubscribeStatus, integer> subs) 
		{
			current := ss;
			allSubs := subs;

			if existsMatchingSub() { sendStatus(); }

			JMSSenderStatus update;
			on all JMSSenderStatus(current.connectionId, current.senderId, *, *, *, *, *):update
			{	
				current := update;	
				if existsMatchingSub() { sendStatus(); }	
			}
		}

		action existsMatchingSub() returns boolean 
		{ 
			SubscribeStatus sub;
			for sub in allSubs.keys()
			{
				if matches(sub) { return true; }
			}
			return false;
		}

		action matches(SubscribeStatus sub) returns boolean
		{
			return (sub.object = "" and (sub.connection = "" or sub.connection = current.connectionId)) or 
	 			(sub.object = "SENDER" and sub.connection = current.connectionId and sub.subServiceID = current.senderId);
		}

		action ackMatchingNewSub(SubscribeStatus newSub) returns boolean 
		{
			if matches(newSub)
			{
				sendStatus();
				return true;
			} 
			return false;
		}

		action sendStatus() 
		{
			boolean available := false;
			if (current.status = JMSSenderStatus.OK) { available := true; }

			sequence<string> summaries := [ current.status ];
			dictionary<string,string> extraParams := {};	
			Status status := Status("CORRELATOR_JMS", "SENDER", current.senderId, current.connectionId, current.errorMessage, summaries, available, extraParams);
			send status to Status.CHANNEL; 
		}
	}

	event JMSReceiverStatusPublisher
	{
		JMSReceiverStatus current;	
		dictionary<SubscribeStatus, integer> allSubs;

		action activate(JMSReceiverStatus rs, dictionary<SubscribeStatus, integer> subs) 
		{
			current := rs;
			allSubs := subs;

			if existsMatchingSub() { sendStatus(); }
			
			JMSReceiverStatus update;
			on all JMSReceiverStatus(current.connectionId, current.receiverId, *, *, *, *, *, *, *, *, *):update
			{
				current := update;	
				if existsMatchingSub() { sendStatus(); }	
			}
		}

		action existsMatchingSub() returns boolean 
		{ 
			SubscribeStatus sub;
			for sub in allSubs.keys()
			{
				if matches(sub) { return true; }
			}
			return false;
		}

		action matches(SubscribeStatus sub) returns boolean
		{
			return (sub.object = "" and (sub.connection = "" or sub.connection = current.connectionId)) or 
	 			(sub.object = "RECEIVER" and sub.connection = current.connectionId and sub.subServiceID = current.receiverId);
		}

		action ackMatchingNewSub(SubscribeStatus newSub) returns boolean 
		{
			if matches(newSub)
			{
				sendStatus();
				return true;
			} 
			return false;
		}

		action sendStatus() 
		{
			boolean available := false;
			if (current.status = JMSReceiverStatus.OK) { available := true; }
			log "Sending receiver status report in response to status event: " + current.toString() at DEBUG;

			sequence<string> summaries := [ current.status ];
			dictionary<string,string> extraParams := {};	
			Status status := Status("CORRELATOR_JMS", "RECEIVER", current.receiverId, current.connectionId, current.errorMessage, summaries, available, extraParams);
			send status to Status.CHANNEL;
		}
	}
}
 0000004a C:\dev\apama_win_full_latest\Apama\monitors\CorrelatorJMSStatusManager.mon
MONF 00000e49 //*****************************************************************************
// Title:         DashboardSupport.mon
// Description:   Monitor defining events to be sent when a client connects
//                or disconnects from a dashboard.  The monitor also provides
//                multi-context support for the connect/disconnect events.
// Dependencies:  None
// $Copyright(c) 2010 Progress Software Corporation (PSC). All rights reserved.$
// $Copyright (c) 2013-2015 Software AG, Darmstadt, Germany and/or Software AG USA Inc., Reston, VA, USA, and/or its subsidiaries and/or its affiliates and/or their licensors.$
// Use, reproduction, transfer, publication or disclosure is prohibited except as specifically provided for in your License Agreement with Software AG
//
//*****************************************************************************

package com.apama.dashboard;


event DashboardClientConnected {
	string userName;
	string sessionId;
	dictionary<string,string> extraParams;
}

event DashboardClientDisconnected {
	string userName;
	string sessionId;
	dictionary<string,string> extraParams;
}

// Events to support parallel execution (contexts)

event RegisterContextForDashboardClientConnections {
	context instanceContext;
}

event DeregisterContextForDashboardClientConnections {
	context instanceContext;
}


/**
 * This monitor provides the context forwarders needed to allow
 * the Dashboard connect and disconnect notification events to be sent to
 * the registered contexts.
 * The notifications are always sent to the main context.
 */
monitor DashboardSupport
{
	// Used to persist contexts interested in notifications
	sequence < context > notifyContexts;

	action onload() {
		
		log "Loaded Dashboard Client Connect Notification service" at INFO;
		
		// Forwarders to support parallel execution (contexts)
		setupContextForwarders();
		
	}
	
	action setupContextForwarders()
	{

		DashboardClientConnected connect;
		on all DashboardClientConnected(): connect {
			log "Dashboard Client Connected - User:" + connect.userName +
				"  Session:" + connect.sessionId at DEBUG;
			if notifyContexts.size() > 0 {
				context ctx;
				for ctx in notifyContexts {
					send connect to ctx;
				}
			}
		}

		DashboardClientDisconnected disconnect;
		on all DashboardClientDisconnected(): disconnect {
			log "Dashboard Client Disconnected - User:" + disconnect.userName +
				"  Session:" + disconnect.sessionId at DEBUG;
			if notifyContexts.size() > 0 {
				context ctx;
				for ctx in notifyContexts {
					send disconnect to ctx;
				}
			}
		}
		
		RegisterContextForDashboardClientConnections regCtx;
		on all RegisterContextForDashboardClientConnections():regCtx registerCtx(regCtx.instanceContext);
	
		DeregisterContextForDashboardClientConnections deregCtx;
		on all DeregisterContextForDashboardClientConnections():deregCtx deregisterCtx(deregCtx.instanceContext);
	}
	
	action registerCtx(context ctx)
	{		
		notifyContexts.append(ctx);
	}

	action deregisterCtx(context ctx)
	{
		if notifyContexts.size() > 0 {
			integer ctxId := notifyContexts.indexOf(ctx);
			if ctxId >= 0 {
				notifyContexts.remove(ctxId);
			}
		}
	}

	action ondie() {
		if (notifyContexts.size() != 0) {
			log "ondie: Dashboard Support service is terminating but there may still be contexts subscribed to dashboard connect events" at ERROR;
		}
		else {
			log "ondie: Dashboard Support service is terminating" at INFO;
		}
	}

	action onunload() {
		log "Unloaded Dashboard Support service" at INFO;
	}


}
 00000040 C:\dev\apama_win_full_latest\Apama\monitors\DashboardSupport.mon
TIME 0000000e 1568382756.7,1
MONF 0000d2a6 //
// MemoryStore.mon
//
// Provide shared and (optionally) persistent storage to MonitorScripts
//
// $Copyright(c) 2009,2012-2013 Progress Software Corporation (PSC). All rights reserved.\$
// $Copyright (c) 2013-2019 Software AG, Darmstadt, Germany and/or Software AG USA Inc., Reston, VA, USA, and/or its subsidiaries and/or its affiliates and/or their licensors.\$
// Use, reproduction, transfer, publication or disclosure is prohibited except as specifically provided for in your License Agreement with Software AG

package com.apama.memorystore;

using com.apama.exceptions.Exception;

/** Sent to the application when an asynchronous activity has finished. 
*/
event Finished {
	/** A unique identifier for the operation that has completed, 
		which will have been returned by the action that initiated the 
		operation. */
	integer id;
	/** True if the operation succeeded. */
	boolean success;
	/** An optional status or error message providing more detail 
		about why the operation succeeded or failed. */
	string status;
}

/** Represents the schema for a table in the store, specifying the field 
	names, types, and other behavioural information about the table. 

	The fields and types sequences must be the same length as one another, 
	specifying the names of fields and their corresponding types.
	
	Never construct a Schema using a "Schema(...)" expression. 
	Instead, always create a variable initialized to "new Schema", and then set 
	parameters individually with separate statements. This ensures that your 
	code will continue to work without modification if a subsequent version 
	of the MemoryStore adds more parameters to the Schema event.
	
	@see Store#prepare() The schema for a table is specified when it is 
		prepared. 
*/
event Schema {
	/** A sequence specifying the name of each field in this table. 

		For looking up the index of a specific field name (e.g. while 
		processing RowChanged events), use Table.getFieldIndex() which is 
		more efficient than using indexOf() on the fields sequence.
		
		@see Table#getFieldIndex() for efficiently obtaining the index of 
		a field.
	**/
	wildcard sequence<string> fields;
	
	/** A sequence specifying the type of each field in this table. 
	
		Permitted types are currently: 'integer', 'boolean', 'float', 'string'
		and 'decimal'.
		
		This sequence must have the same length as the fields sequence. 
	*/
	wildcard sequence<string> types;
	
	/** When this field is true, the MemoryStore makes the rows in the 
		in-memory table associated with this schema available to the 
		scenario service, so they can be used by external clients and 
		dashboards. 
		
		That is, the MemoryStore creates DataViews that contain the state of 
		this table that has been committed (but not necessarily persisted) to 
		the shared in-memory representation of the table.
		
		Committing changes to the in-memory row in a table that is exposing 
		its in-memory state causes events to be sent to the main context. 
	 */
	boolean exposeMemoryView;
	/** When this field is true, the MemoryStore makes the rows in the 
		on-disk table associated with this schema available to the 
		scenario service, so they can be used by external clients and 
		dashboards.  
		
		That is, the MemoryStore creates DataViews that contain data from this 
		table that has been persisted to disk. 
		
		You cannot expose a persistent view of a table in a 
		correlator-persistent store.
 	*/
	boolean exposePersistentView;
	
	/** Specifies the display name for an in-memory table. */
	string memoryViewDisplayName;
	/** Describes an in-memory table. */
	string memoryViewDescription;
	/** Specifies the display name for an on-disk table. */
	string persistentViewDisplayName;
	/** Describes an on-disk table. */
	string persistentViewDescription;
	
	/** Convert the supplied types into a valid MemoryStore table Schema.
	 *
	 *  Field types that are not supported by MemoryStore are converted to strings.
	 *
	 *  @param type to turn into a MemoryStore table Schema.
	 *  @returns The MemoryStore table Schema.
	 *  @since 10.1
	 */
	static action schemaFromAny(any prototype) returns Schema {
		Schema schema := new Schema;

		sequence<any> keys := prototype.getKeys();
		schema.types := normalizeTypes(prototype.getFieldTypes());
		
		integer i := 0;
		while (i < schema.types.size()) {
			// Create the field names from the string version of keys
			schema.fields.append(keys[i].valueToString());
			i := i+1;
		}
		
		return schema;
	}
	
	/** Normalize a sequence of types to those accepted by Memory Store.
	 *
	 *  Converts anything other than integer, float, boolean and decimal to string.
	 *
	 *  @param types Type string sequence to normalize
	 *  @returns Sequence of normalized string types
	 *  @since 10.1
	 */
	static action normalizeTypes(sequence<string> types) returns sequence<string> {
		dictionary<string, boolean> validTypes := {"integer":true, "float":true, "boolean":true, "string":true, "decimal":true};
		
		sequence<string> result := types.clone();
		
		integer i := 0;
		while (i < result.size()) {
			// Normalise the type
			if (not validTypes.hasKey(result[i]))
			{	
				result[i] := "string";
			}
			i := i+1;
		}
		
		return result;
	}
}

/** Represents an ordered and typed set of named fields in a table, with a 
	key that uniquely identifies the row within the table. 

	A Row is an atomic snapshot of the data in the
	table and once returned, a Row's contents are guaranteed to be consistent 
	and unchanging.

	Any changes the user makes to a Row are local until commit is called.
	
	@see Table A table holds a collection of rows. 
*/
event Row {
	/** @private*/ import "MemoryStorePlugin" as plugin;
	/** @private*/ wildcard chunk c;

	/** Update the local Row event to reflect the current state of the shared
		MemoryStore table, losing any local modifications.
	
		row.update() has a very similar effect to r := t.get(r.getKey()),
		but is more efficient and doesn't require access to the table.
	*/
	action update() {
		plugin.RowChunk_update(c);
	}

	/** Copy the contents of the specified other Row into this one.
	
		The two rows that these Row events represent must have the same schema 
		but they need not be in the same table.

		r1.copy(r2) is a more efficient equivalent to
		r1.setX("a", r2.getX("a")) for every field. 
		
		You cannot copy a row between a correlator-persistent store and an 
		in-memory, on-disk or distributed store.
	*/
	action copy(Row other) {
		plugin.RowChunk_copy(c, other.c);
	}

	/** Mark the row for deletion when the table is committed.
	
		Fields cannot be accessed after this call, until the removal is
		successfully committed (or reverted using update).
	*/
	action remove() {
		plugin.RowChunk_remove(c);
	}
	
	/** Try to commit changes from this Row back to the table, returning false 
		if the Row is not up to date.
	
		If nothing else has modified the row in the table since this
		Row was created, the changes are committed so other users can
		see them and true is returned.
	
		Otherwise, false is returned and the table is left unchanged. 
		Do not repeatedly call tryCommit() without also calling update(), 
		or use the more efficient Row.tryCommitOrUpdate(). 
		
		Note that a MemoryStore commit operation synchronously writes changes 
		made to the local Row instance back to the table which is shared by all 
		monitors inside the Correlator (or the distributed store), but does not 
		cause a persistent write to disk (see Table#persist). 

		@returns true if the table was modified; false if an error occurred and 
		the table was not changed. 
		
		@see Row#tryCommitOrUpdate()
	*/
	action tryCommit() returns boolean {
		return plugin.RowChunk_tryCommit(c,currentTime);
	}


	/** Try to commit changes from this Row back to the table, which could 
		result in an exception being thrown if the Row is not up to date.
	
		If nothing else has modified the row in the table since this
		Row was created, the changes are committed so other users can
		see them.
	
		Otherwise, an exception is thrown and the table is left unchanged.
		
		If there is any chance that the same row may be written to 
		concurrently - for example by multiple correlator contexts, and/or if 
		using a distributed MemoryStore - use Row.tryCommit() instead of 
		Row.commit() so that it is possible to recover from this situation 
		when it occurs or use Row.forceCommit() to commit the changes 
		forcefully.

		Note that a MemoryStore commit operation synchronously writes changes 
		made to the local Row instance back to the table which is shared by all 
		monitors inside the Correlator (or the distributed store), but does not 
		cause a persistent write to disk (see Table#persist). 

		@see Row#tryCommit()
		@see Row#tryCommitOrUpdate()
	*/
	action commit() {
		plugin.RowChunk_commit(c,currentTime);
	}

	/** Try to commit, or update (losing local modifications) if not. 
	
		This is a more efficient equivalent to calling tryCommit then
		calling update if the commit fails. Typical usage would be to have a 
		loop that makes some modifications to a row, calls tryCommitOrUpdate, 
		and continues to loop (re-instating the local modifications and calling 
		tryCommitOrUpdate again) until it returns true. 
	
		Note that a MemoryStore commit operation synchronously writes changes 
		made to the local Row instance back to the table which is shared by all 
		monitors inside the Correlator (or the distributed store), but does not 
		cause a persistent write to disk (see Table#persist). 
		
		@returns true if the commit succeeded, false if the commit failed but 
		the row has been updated ready for a retry attempt. 
		
	*/
	action tryCommitOrUpdate() returns boolean {
		return plugin.RowChunk_tryCommitOrUpdate(c,currentTime);
	}
	
	/** Commit this Row back to the table even if the Row is not up to date.
		
		If this Row is marked for deletion using Row.remove() then forceCommit 
		will unconditionally remove the Row from the table.
		
		Note that a MemoryStore commit operation synchronously writes changes 
		made to the local Row instance back to the table which is shared by all 
		monitors inside the Correlator (or the distributed store), but does not 
		cause a persistent write to disk (see Table#persist).
	 */
	action forceCommit() {
		plugin.RowChunk_forceCommit(c,currentTime);
	}

	/** Get the key for this Row. 
	
		It cannot be changed.
	*/
	action getKey() returns string {
		return plugin.RowChunk_getKey(c);
	}

	/** Indicate whether this row was in the table when the Row
		was created or updated. 
		
		It is possible to construct a Row that has no corresponding entry in 
		the table, in which case all fields have default values. 
		
		Calling commit on a Row for which inTable()=false will create the row.
	*/
	action inTable() returns boolean {
		return plugin.RowChunk_inTable(c);
	}
	
	/** Get the row as an any using the type the Store was created with
		(using prepareFromAny() or prepareFromTypeName()).
		
		This is equivalent to calling getAll(any.newInstance(getTableName())). 
		This action can be used only if the table name is a valid Apama type. 
		Use getAll() instead if the store was not created from an Apama type.

		@see Store#prepareFromAny()
		@see Store#prepareFromTypeName()
		@see #getAll()
	*/
	action toAny() returns any {
		return getAll(any.newInstance(getTableName()));
	}

	// Get the value
	//
	// The correct variant must be called for the type of the column
	// in the table.

	/** Get the value of the specified field in this row 
		(must only be used on boolean fields).
	*/
	action getBoolean(string name) returns boolean {
		return plugin.RowChunk_getBoolean(c,name);
	}

	/** Get the value of the specified field in this row 
		(must only be used on integer fields).
	*/
	action getInteger(string name) returns integer {
		return plugin.RowChunk_getInteger(c,name);
	}

	/** Get the value of the specified field in this row 
		(must only be used on float fields).
	*/
	action getFloat(string name) returns float {
		return plugin.RowChunk_getFloat(c,name);
	}

	/** Get the value of the specified field in this row 
		(must only be used on string fields).
	*/
	action getString(string name) returns string {
		return plugin.RowChunk_getString(c,name);
	}

	/** Get the value of the specified field in this row 
		(must only be used on decimal fields).
	*/
	action getDecimal(string name) returns decimal {
		return plugin.RowChunk_getDecimal(c,name);
	}
	
	/** Get the value of the specified field in this row 
		(can be used on all types).
		This will return a string for types that cannot be stored. Use getParsed() to parse to a type.
		
		An exception will be thrown if the specified field name is not present in this row. 
		
		If it is not known whether the field name exists or not, use getKeys().indexOf(...) to 
		find out, or use toDictionary.getOr(...). 
		
		@see #getParsed()
		@since 10.1
	*/
	action get(string name) returns any {
		string typeName := plugin.RowChunk_getFieldType(c,name);
		
		if (typeName = "boolean") {
			return getBoolean(name);
		} else if (typeName = "integer") {
			return getInteger(name);
		} else if (typeName = "float") {
			return getFloat(name);
		} else if (typeName = "string") {
			return getString(name);
		} else if (typeName = "decimal") {
			return getDecimal(name);
		}
		
		// Shouldn't get here
		throw com.apama.exceptions.Exception("Unknown type "+typeName+" in get()", "IllegalArgumentException");
	}
	
	/** Get the value of the specified field in this row parsed to the specified typeName.
		@since 10.1
	*/
	action getParsed(string name, string typeName) returns any {
	
		// If stored in the correct type, return it
		any val := get(name);
		if (typeName = plugin.RowChunk_getFieldType(c,name)) {
			return val;
		}
		switch (val) {
			case string: { 
				if val = "" {
					return any.newInstance(typeName);
				}
			}
			default: {}
		}
		return any.parseType(typeName, val.valueToString());
	}

	// Set the value
	//
	// The correct variant must be called for the type of the column
	// in the table.

	/** Set the value of the specified field in this row 
		(must only be used on boolean fields). 
	*/
	action setBoolean(string name, boolean b) {
		plugin.RowChunk_setBoolean(c,name,b);
	}

	/** Set the value of the specified field in this row 
		(must only be used on integer fields). 
	*/
	action setInteger(string name, integer i) {
		plugin.RowChunk_setInteger(c,name,i);
	}

	/** Set the value of the specified field in this row 
		(must only be used on float fields). 
	*/
	action setFloat(string name, float f) {
		plugin.RowChunk_setFloat(c,name,f);
	}

	/** Set the value of the specified field in this row 
		(must only be used on string fields). 
	*/
	action setString(string name, string s) {
		plugin.RowChunk_setString(c,name,s);
	}

	/** Remove a non-schema field from the row.

	   Only functions on non-schema fields with a supported 
	   distributed store. 
		@since 10.3
	*/
	action removeNonSchema(string name) {
		plugin.RowChunk_removeNonSchema(c, name);
	}

	/** Set the value of the specified field in this row 
		(must only be used on decimal fields). 
	*/
	action setDecimal(string name, decimal d) {
		plugin.RowChunk_setDecimal(c,name,d);
	}
	
	/** Set the value of the specified field in this row 
		(can be used with all types).
		Will use the string form if needed.

		If name is a non-schema field and the store is a distributed store which supports them, a new field will be added.
		If any is empty and the above is true, then the field will be removed from the row. Otherwise this method will throw.
		@since 10.1
	*/
	action set(string name, any value) {
		try {
			string type := plugin.RowChunk_getFieldType(c,name);
		
			//  If the schema type is string, we toString the any value ignoring the underlying type (which could be wrong)
			if ("string" = type) {
				setString(name, value.valueToString());
				return;
			}
		} catch(Exception e) {
			// ignore - it may be an extraField entry.
		}
		
		switch (value) {
			case boolean: {
				setBoolean(name, value);
			}
			case integer: {
				setInteger(name, value);
			}
			case float: {
				setFloat(name, value);
			}
			case string: {
				setString(name, value);
			}
			case decimal: {
				setDecimal(name, value);
			}
			default: {
				ifpresent value {
					setString(name, value.valueToString());
				} else {
					removeNonSchema(name);
				}
			}
		}
	}
	
	/** Set all values in this row from all available fields in the supplied any type.
		@param value Any type value (event or dictionary) to take the field values from
		@since 10.1
	*/
	action setAll(any value) {

		sequence<any> keys := value.getKeys();
		sequence<any> entries := value.getEntries();
		sequence<string> stringKeys := new sequence<string>;
		
		integer i := 0;
		while (i < keys.size()) {
			stringKeys.append(keys[i].valueToString());
			i := i+1;
		}
		
		// This throws if schema is invalid
		plugin.RowChunk_validateSchema(c, stringKeys, Schema.normalizeTypes(value.getTypes()));
		
		i := 0;
		while (i < stringKeys.size()) {
			set(stringKeys[i], entries[i]);
			i := i+1;
		}
	}

	/** Fill in value of all keys in the supplied 'any' with values from the row.
	
		@param prototype Any type value (an event or non-empty dictionary) 
		which will be modified in-place with the current values from this row.
		@returns The same instance passed in as prototype, filled in with 
		values from this row.
		
		@since 10.1
	*/
	action getAll(any prototype) returns any {
		
		sequence<any> keys := prototype.getKeys();
		
		any key;
		for key in keys {
			any prototypeEntry := prototype.getEntry(key);
			any rowField := get(key.valueToString());
			
			// If types don't match, and row is a string, attempt to parse it to correct type
			if ((prototypeEntry.getTypeName() != rowField.getTypeName()) and ("string" = rowField.getTypeName())) {
				switch (rowField) {
					case string: { 
						if rowField = "" {
							prototype.setEntry(key, any.newInstance(prototypeEntry.getTypeName()));
						} else {
							prototype.setEntry(key, any.parseType(prototypeEntry.getTypeName(), rowField));
						}
					}
					// will throw on default, the if statement should ensure that it's never anything else
				}
			} else {
				prototype.setEntry(key, rowField);
			}
		}
		
		return prototype;
	}

	/** Get all of the field names held in this Row.
	 * These are all of the valid values that can be passed to get(). Will include all Schema field names followed
	 * by any extra fields if the driver supports them.
	 * @since 10.1
	 */
	action getKeys() returns sequence<string>  {
		sequence<string> keys := [];
		keys.setSize(plugin.RowChunk_getKeys(c, keys));
		integer i := plugin.RowChunk_getKeys(c, keys);
		return keys;
	}

	/** Get a dictionary copy of the Row.
	 * @since 10.1
	 */
	action toDictionary() returns dictionary<string, any> {
		dictionary<string,any> d := {};
		string k;
		for k in getKeys() {
			try {
				d[k] := get(k);
			} catch(Exception e) { // ignore
				log "Ignoring key '"+k+"' in Row.toDictionary(); presumably an unsupported type." at DEBUG;
			}
		}
		return d;
	}

	/** Get the name of the Table that contains this Row. */
	action getTableName() returns string {
		return plugin.RowChunk_getTableName(c);
	}

	/** Get the name of the Store that contains this Row's Table. */
	action getStoreName() returns string {
		return plugin.RowChunk_getStoreName(c);
	}
}


/**
 * Sent to the application on every successful row commit in tables
 * the application has subscribed to.
 *
 * Supported in distributed stores only, and only for fields named in the 
 * schema (extra fields are not supported).
 *
 * Events are sent for every change, whether from the local or a
 * remote node, for tables where the subscribe method has been called.
 *
 * Some distributed MemoryStore drivers support including new and old 
 * values in this event, some just new values, and 
 * others - such as TCStore - leave both sequences empty. 
 *
 * For * example:
 <pre>
<br/>	integer positionRowId := tbl.getFieldIndex("position");
<br/>	RowChanged rowChanged;
<br/>	on all RowChanged(storeName = STORE, 
<br/>	                  tableName = TABLE):rowChanged {
<br/>		// we handle things simply by treating an update as a remove followed by an insert:
<br/>		if (rowChanged.changeType = RowChanged.REMOVE or
<br/>		    rowChanged.changeType = RowChanged.UPDATE) {
<br/>			position := position - float.parse(rowChanged.oldFieldValues[positionRowId]);
<br/>		}
<br/>		if rowChanged.changeType = RowChanged.INSERT or
<br/>		   rowChanged.changeType = RowChanged.UPDATE {
<br/>			position := position + float.parse(rowChanged.newFieldValues[positionRowId]);
<br/>		}
<br/>		log "Position is now "+position.toString();
<br/>	}
 </pre>
 * @see Table#subscribeRowChanged() for subscribing to RowChanged events
 */
event RowChanged {
	/** Value for changeType when a row is added to a table. */
	constant integer INSERT := 1;

	/** Value for changeType when a row is removed from a table. */
	constant integer REMOVE := 2;

	/** Value for changeType when a row is modified in a table. */
	constant integer UPDATE := 3;

	/**
	 * One of INSERT, REMOVE, UPDATE for
	 * rows being added, removed, updated.
	 */
	integer changeType;

	/**
	 * Name of the store that the table is in.
	 */
	string storeName;

	/**
	 * Name of the table that the row is in.
	 */
	string tableName;

	/**
	 * The key value for the changed row.
	 */
	string key;

	/**
	 * Old values of the row, or an empty sequence if not supported 
	 * by this driver.
	 *
	 * This sequence is always blank when using TCStore or BigMemory. 
	 *
 	 * The old values of the row, in toString() format, in the
	 * order defined by the table's Schema.  For UPDATE
	 * changeTypes, this is only populated if the storeFactory
	 * bean property rowChangedOldValueRequired is true (the
	 * default value is provider-specific).
	 *
	 * For INSERT (or UPDATE if rowChangedOldValueRequired is
	 * false), this will be an empty sequence, otherwise it will
	 * have as many entries as there are fields in the schema.
	 *
	 * The field values can be recovered by using the parse method
	 * on the field's type
	 * (e.g. <tt>integer.parse(rc.oldFieldValues[i])</tt>),except
	 * for strings which are inserted without any escaping, so do
	 * not need to be parsed. 
	 *
	 * Use Table.getFieldIndex() to efficiently map a field name
	 * to an index in this sequence (although consider caching the
	 * index in a variable to avoid unnecessary lookups).
	 *
	 * @see Table#getFieldIndex() for mapping from field name to
	 * index.
	 */
	sequence<string> oldFieldValues;

	/**
	 * New values of the row, or an empty sequence if not supported 
	 * by this driver.
  *
	 * This sequence is always blank when using TCStore. 
	 *
 	 * The new values of the row, in toString() format, in the order defined 
	 * by the table's Schema.
	 *
	 * For REMOVE, this will be an empty sequence, otherwise it 
	 * will have as many entries as there are fields in the schema.
	 *
	 * The field values can be recovered by using the parse method
	 * on the field's type (e.g. <tt>integer.parse(rc.newFieldValues[i])</tt>), 
	 * except for strings which are inserted without any escaping, so do not 
	 * need to be parsed. 
	 *
	 * Use Table.getFieldIndex() to efficiently map a field name to an index 
	 * in this sequence (although consider caching the index in a 
	 * variable to avoid unnecessary lookups).
	 *
	 * @see Table#getFieldIndex() for mapping from field name to index. 
	 */
	sequence<string> newFieldValues;
	
	/** 
	 * Get a display string representing this event's change type. 
	 *
	 * @returns "INSERT", "REMOVE" or "UPDATE". 
	 */
	action getChangeTypeString() returns string {
		if changeType = INSERT {
			return "INSERT";
		} else if changeType = REMOVE {
			return "REMOVE";
		} else if changeType = UPDATE {
			return "UPDATE";
		} else {
			return "UNKNOWN:"+changeType.toString();
		}
	}
}

/**
 * Optionally sent to the application if the driver has detected that some of the RowChanged events may have been
 * dropped for a table the application has subscribed to.
 *
 * Supported in distributed stores only.
 *
 * @see Table#subscribeRowChanged() for subscribing to RowChanged and MissedRowChanges events
 */
event MissedRowChanges {
	/**
	 * Name of the store that the table is in.
	 */
	string storeName;

	/**
	 * Name of the table that has received a disconnection.
	 */
	string tableName;
}



/** Represents an iterator that can be used to step through each 
	Row of a Table in turn, making changes or reading data from the row. 
	
	@see Table#begin() Gets an iterator, beginning from the start of the table.
*/
event Iterator {
	/** @private*/ import "MemoryStorePlugin" as plugin;
	/** @private*/ wildcard chunk c;

	/** Checks whether this Iterator has now reached the end of
		the Table. 
	
		You should check done() is not true before you call other Iterator 
		actions (except for appendKeys() and getKeys()).
	*/
	action done() returns boolean {
		return plugin.IteratorChunk_done(c);
	}

	/** Step this Iterator to the next row in the table.
	
		If there are no more rows the Iterator becomes done. 
		
		To avoid an error that will terminate the monitor instance, always 
		use done() to check that the iterator has not reached the end of the 
		table before calling this action. 		
	*/
	action step() {
		plugin.IteratorChunk_step(c);
	}
	
	/** Get the key for the row this Iterator is pointing at.
	
		To avoid an error that will terminate the monitor instance, always 
		use done() to check that the iterator has not reached the end of the 
		table before calling this action. 
	*/
	action getKey() returns string {
		return plugin.IteratorChunk_getKey(c);
	}

	/** Get the Row this Iterator is pointing at.
	
		It is possible that the row the iterator is pointing at is no longer 
		present. This can happen if another monitor deleted the row or table, 
		or cleared the table while the iterator was pointing at that row.

		If the requested row is no longer there, you receive a Row event that 
		represents a row in which all fields have default values and for which 
		Row.inTable() is false. This is the same result as if you call 
		Table.get() on a key that does not exist yet.
	
		To avoid an error that will terminate the monitor instance, always 
		use done() to check that the iterator has not reached the end of the 
		table before calling this action. 
	*/
	action getRow() returns Row {
		return Row(plugin.IteratorChunk_getRow(c));
	}

	/** Append to the specified sequence, keys for up to n consecutive
		rows of the Table, beginning where this Iterator is pointing.
	
		The iterator will be advanced. If it becomes
		done then fewer than n keys will be appended.
		
		@param seq The sequence which is to be updated with the keys from the 
		following n table rows. 
		@param n The number of keys to get and append to the sequence. 
	*/
	action appendKeys(sequence<string> seq, integer n) {
		integer start := seq.size();
		seq.setSize(start+n);
		seq.setSize(plugin.IteratorChunk_appendKeysImpl(c, seq, start));
	}

	/** Get the keys for up to n consecutive rows of the Table beginning
		where this Iterator is pointing.
	
		The iterator will be advanced. If it becomes
		done, a sequence of fewer than n keys will be returned.

		The first key in the returned sequence is the key of the row that the 
		iterator is pointing at when the action is called. When this action is 
		finished, the iterator is pointing at the row immediately beyond that 
		of the last key that was returned. 
		
		@param n The number of keys to get and append to the sequence. 
	*/
	action getKeys(integer n) returns sequence<string> {
		sequence<string> result := new sequence<string>;
		appendKeys(result, n);
		return result;
	}
}

/** Represents a collection of rows in a store, with a defined schema.
	
	A table consists of a series of rows, each identified by a key and
	containing other values with names and types according to the
	table's Schema.
	
	A table typically resides in memory, you can also store it on 
	disk if you want to, or a table can be stored on a distributed cache.
	
	@see Store#open() Tables exist within a named Store, which is used to 
		create and open tables. 
*/
event Table {
	/** @private*/ import "MemoryStorePlugin" as plugin;
	/** @private*/ wildcard chunk c;


	/** Add the table Row with the specified key.
	
		On distributed stores, for performance reasons this action doesn't
		check if there is a Row already present in the the table with the
		specified key. To check if the Row is present in the store, use the
		Table.get() action.
		
		@param key The name/key uniquely identifying the row. 
		@returns An empty Row event.
	*/
	action add(string key) returns Row {
		return Row(plugin.TableChunk_add(c, key));
	}

	/** Get the table Row with the specified key. 
	
		If there is no row with the specified key, this action returns 
		without error, with a Row event that contains default values for the 
		fields in the row. A call to the Row.inTable() action returns false.
		
		@param key The name/key uniquely identifying the row. 
		@returns A Row event representing an atomic snapshot of the committed 
			data in the table when the action was called. 		
	*/
	action get(string key) returns Row {
		return Row(plugin.TableChunk_get(c,key));
	}
	
	/** Remove the specified row from the table. 
	
		If the row does not exist, this action does nothing.

		@param key The name/key uniquely identifying the row. 
	*/
	action remove(string key) {
		plugin.TableChunk_remove(c,key);
	}

	/** Change the row with the specified key by applying an action to it.
	
		It is possible for another context to commit changes to this row 
		between the time mutate() obtains a Row event to represent the row and 
		the time mutate() tries to commit the changes that result from 
		executing the specified action. In this situation, the MemoryStore 
		automatically calls the specified action again on the most recently 
		committed row content; therefore mutation actions must be designed to 
		cope with being called repeatedly without causing unwanted side 
		effects.
	
		@param name The name/key uniquely identifying the row. 
		@param a An action that (idempotently) performs the desired change to 
			the row. 
	*/
	action mutate(string key, action<Row> a) {
		Row row := get(key);
		boolean done := false;
		while not done { a(row); done := row.tryCommitOrUpdate(); }
	}

	/** Mutate all rows in the Table by applying the specified action.
	
		This can temporarily consume a lot of memory when called on a 
		relatively large table because the Correlator does no garbage 
		collection until action execution is complete. A few thousand rows are 
		unlikely to present a problem. Beyond that, it depends on how many 
		fields are in each row, how many rows are in the table, and how much 
		RAM is available.

		@param a An action that performs the desired change to 
			each row in the table. 
	*/
	action mutateAll(action<Row> a) {
		Iterator i := begin();
		while not i.done() {
			Row row := i.getRow();
			boolean done := false;
			while row.inTable() and not done {
				a(row); done := row.tryCommitOrUpdate();
			}
			i.step();
		}
	}

	/** Remove all rows from the table. */
	action clear() {
		plugin.TableChunk_clear(c);
	}

	/** Indicate whether or not a row with the specified key is present
		in the table.
	
		t.hasKey("foo") is a more efficient alternative to
		t.get("foo").inTable()
		
		@param key The name/key uniquely identifying the row. 
	*/
	action hasKey(string key) returns boolean {
		return plugin.TableChunk_hasKey(c,key);
	}

	/** Return an iterator to the beginning of the Table.
	*/
	action begin() returns Iterator {
		return Iterator(plugin.TableChunk_begin(c));
	}

	/** Returns a sequence that contains the keys for all the rows in this 
		table. 
		
		The keys are in an arbitrary order.
 	*/
	action getKeys() returns sequence<string> {
		Iterator i := begin();
		sequence<string> result := i.getKeys(plugin.TableChunk_size(c));
		// Clean up any residue if a race means we didn't get everything
		while not i.done() { i.appendKeys(result, 16); }
		return result;
	}

	/** Persist this table's committed changes back to stable storage, asynchronously.
	
		Note that any local changes to a Row that were not committed will not 
		be written to disk (see Row#commit()). 

		Only on-disk persistent stores can be persisted using this action. 
		It is not possible to call this method on Correlator-persistent tables 
		since all changes committed to such tables will be written to disk 
		automatically in the same transaction as changes to the state of 
		persistent EPL monitors. 
		
		@returns The unique identifier for this operation, which will be 
			included in the Finished event sent after the operation is 
			complete. 
		@see Finished A Finished event will be sent when this asynchronous 
			operation has completed. 
	*/
	action persist() returns integer {
		return plugin.TableChunk_persist(c,currentTime);
	}

	/** Enqueue an event for each row in the table, taken by parsing the string 
		data in the specified table field/column as an event string.
		
		The field must be of string type, and its value for every row should be 
		an Apama event string, in the same form that you would send to the 
		Correlator (e.g. "mypackage.MyEvent(123, [false,true])")

	
		This action is most likely to be useful when you are migrating from the 
		StateStore Correlator plug-in to the MemoryStore. In the StateStore 
		plug-in, persistent data re-entered the Correlator as sent events.
		
		This is only supported for non-distributed stores.
	
		@param fieldName The name of the table field whose values are event 
			strings that should be sent. 
		@returns The unique identifier for this operation, which will be 
			included in the Finished event sent after the column data for 
			the last row has been sent. 
		@see Finished A Finished event will be sent when this asynchronous 
			operation has completed. 
	*/
	action enqueueColumn(string fieldName) returns integer {
		return plugin.TableChunk_enqueueColumn(c, fieldName);
	}

	/** Get the name of this Table. */
	action getTableName() returns string {
		return plugin.TableChunk_getTableName(c);
	}

	/** Get the name of the Store that contains this table. */
	action getStoreName() returns string {
		return plugin.TableChunk_getStoreName(c);
	}

	/**
	 * Subscribe to be notified of all successful commits in
	 * this table.
	 *
 	 * This is only supported for tables in a distributed store, 
	 * and only if the underlying provider supports this feature. 
	 *
	 * The monitor instance will be terminated with an error if this 
	 * action is called on a store that does not support it. 
	 *
	 * It is important to note that (due to the nature of distributed store 
	 * technology) there is no way to atomically subscribe to notifications 
	 * and get an initial snapshot of the table's contents, so 
	 * applications that perform an initial iteration over the table's contents 
	 * to initialize some state before subscribing are at risk of 
	 * double-counting any keys that are mutated after the subscription 
	 * and during the iteration/initialization process. 
	 *
	 * For tables that are relatively small (and fit entirely inside the 
	 * memory of a single Correlator), a common pattern for addressing the need 
	 * for a table snapshot to initialize state before subscribing is to 
	 * maintain a per-key dictionary of last-seen values, updated by both the 
	 * initial iteration and the RowChanged notification events; any RowChanged 
	 * event whose old value does not match the last-seen dictionary must be 
	 * ignored, to avoid double-counting changes. To save memory, entries from 
	 * the last-seen dictionary can be removed after the first RowChanged event 
	 * for that key. 
	 *
	 * For distributed stores and drivers that support it, the application
	 * may also receive MissedRowChanges events to signify that some unknown number
	 * of updates have been missed (typically due to a network disconnection
	 * between the client and the store)
	 *
	 * @returns A unique subscriptionId that can be passed to any instance of 
	 * this Table to unsubscribe.
	 * @see RowChanged The event sent whenever a row is modified.
	 * @see MissedRowChanges The event sent whenever a row is modified.
	 * @see Table#unsubscribe() Unsubscribe using this action. 
	 */
	action subscribeRowChanged() returns integer 
	{
		integer subscriptionId := integer.incrementCounter("apama.MemoryStoreRowChanged");
		plugin.TableChunk_subscribeRowChanged(c, subscriptionId);
		return subscriptionId;
	}
	
	/**
	 * Cancel a previous subscription.
	 *
	 * This is only supported for tables in a distributed store.
	 *
	 * If other monitors in this context have also subscribed,
	 * events will still be delivered until they have all unsubscribed.
	 * subscriptionId must be a value returned from a subscribeRowChanged() on 
	 * this table.
	 *
	 * @param subscriptionId Identifier for the subscription to remove, 
	 * returned by subscribeRowChanged().
	 */
	action unsubscribe(integer subscriptionId) 
	{ 
		plugin.TableChunk_unsubscribe(c, subscriptionId);
	}

	/**
	 * Return the index of a field.
	 *
	 * Returns what position in the Schema the specified field
	 * appears at. If a name that is not in Schema fieldName
	 * is passed in, the monitor instance will be terminated with an error.
	 *
	 * Using this action is more efficient that getting the same information 
	 * by using indexOf on the Schema.fields sequence. 
	 *
	 * @param fieldName A field name that exists in this table's Schema. 
	 */
	action getFieldIndex(string fieldName) returns integer 
	{ 
		return plugin.TableChunk_getFieldIndex(c, fieldName);
	}
}

/** Represents a store, which is a container for a uniquely named collection of 
	tables. 
	
	@see Storage Provides actions to prepare and open a Store. 
	@see Table Represents the tables in a Store. 
*/
event Store {
	/** @private*/ import "MemoryStorePlugin" as plugin;
	/** @private*/ wildcard chunk c;
	

	/** Prepare a table so that subsequent open calls for it will succeed.
	
		If the table already exists, the Schema provided to the prepare
		function must completely match the existing schema. If it does 
		not already exist, the Schema will be used to create the table.
	
		The function returns an id; once preparation is complete a
		Finished event with that id will be sent.
		
		This call is idempotent - if the table was already successfully 
		prepared, it will return success immediately.
		
		@param name A unique name that will be used to identify the new table.
		@param schema The schema identifying the fields of the new table.
		@returns The unique identifier for this operation, which will be 
			included in the Finished event sent after the operation is 
			complete. 
		@see Finished A Finished event will be sent when this asynchronous 
			operation has completed. 
	*/
	action prepare(string name, Schema schema) returns integer {
		return plugin.StoreChunk_prepare3(c, name, schema.fields.toString() + " " + schema.types.toString(), schema.fields, schema.types, schema.exposeMemoryView, schema.exposePersistentView, schema.memoryViewDisplayName, schema.memoryViewDescription, schema.persistentViewDisplayName, schema.persistentViewDescription, currentTime);
	}
	
	/** Prepare a table from a supplied type (a users Event) using the type name
		as the table name and the fields and field types as the schema.
		
		<code>
		integer id := Schema.prepareFromAny(new MyEventType);
		</code>
	 
		@param prototype Any type value to use as the table name and schema
		@returns The unique identifier for this operation, which will be 
			included in the Finished event sent after the operation is 
			complete. 
		@see Finished A Finished event will be sent when this asynchronous 
			operation has completed.
		@see #prepare()
		@since 10.1
	*/
	action prepareFromAny(any prototype) returns integer {
		return prepare(prototype.getTypeName(), Schema.schemaFromAny(prototype));
	}

	/** Prepare a table from a type identified from the supplied type name.
		The type name should identify a users Event.

		<code>
		integer id := Schema.prepareFromTypeName("MyEventType");
		</code>
  	 
  		@param typeName The type name to use as the table name and schema.
  		@returns The unique identifier for this operation, which will be 
  			included in the Finished event sent after the operation is 
  			complete. 
  		@see Finished A Finished event will be sent when this asynchronous 
  			operation has completed.
  		@see #prepareFromAny()
  		@since 10.1
  	*/
	action prepareFromTypeName(string typeName) returns integer {
		return prepareFromAny(any.newInstance(typeName));
	}
	
	/** Indicate whether or not a Table with the specified name is
		present in the Store.
	
		@param name The unique table name to check for. 
		@returns True if it is safe to call open() on the specified table; false 
			if preparation failed or is still in progress. 
	*/
	action hasTable(string name) returns boolean {
		return plugin.StoreChunk_hasTable(c, name);
	}

	/** Open the specified table, once it has been prepared.
	
		It is an error to call this before a prepare call for the table
		has finished without error.
		
		@param name The name of the table to be opened, which must be the same 
			as the name used when the table was first prepared. 
		@see #prepare() This action must not be called until prepare has 
			completed successfully. 
	*/
	action open(string name) returns Table {
		return Table(plugin.StoreChunk_open(c,name));
	}

	/** Persist committed changes back to stable storage, asynchronously.
	
		Only on-disk persistent stores can be persisted using this action. 
		It is not possible to call this method on Correlator-persistent tables 
		since all changes committed to such tables will be 
		written to disk automatically in the same transaction as changes to 
		the state of persistent EPL monitors. 
		
		@returns The unique identifier for this operation, which will be 
			included in the Finished event sent after the operation is 
			complete. 
		@see Finished A Finished event will be sent when this asynchronous 
			operation has completed. 
	*/
	action persist() returns integer {
		return plugin.StoreChunk_persist(c,currentTime);
	}

	/** Create a backup of the Store.
	
		The backup is created in the specified file, which is
		overwritten if it already exists.
	
		Only persistent (on-disk) stores can be backed up. 
		
		@returns The unique identifier for this operation, which will be 
			included in the Finished event sent after the operation is 
			complete. 
		@see Finished A Finished event will be sent when this asynchronous 
			operation has completed. 
	*/
	action backup(string filename) returns integer {
		return plugin.StoreChunk_backup(c, filename);
	}

	/** Get the name of this Store. */
	action getStoreName() returns string {
		return plugin.StoreChunk_getStoreName(c);
	}
}

/** MemoryStore factory interface for creating Store event objects. 

	There are several different types of Store supported by MemoryStore:
	<ul>
	<li>In-memory only (nothing persisted to disk)</li>
	<li>MemoryStore database file (committed changes are persisted to disk when the persist() action is called)</li>
	<li>Correlator-persistent (integrated with the correlator persistence and only 
		supported when the correlator was started with persistence enabled; 
		committed changes go to disk periodically when the Correlator takes a 
		snapshot of persistent monitor state and persists the results). </li>
	<li>Distributed (Using a distributed cache or store technology to share and access
		data across multiple distributed nodes). </li>
	</ul>
	Correlator-persistent stores are only available if Correlator persistence 
	has been enabled. Non-persistent monitors may use any type of store, but 
	a monitor marked as 'persistent' may ONLY access Correlator-persistent 
	stores.

	To use the MemoryStore, create a monitor field (or variable) to hold the 
	Storage factory event, and use one of the prepare* actions to 
	asynchronously get a Store of the desired type ready for use, and give it 
	a unique name. Once the store has been prepared, use the open(name) action 
	to get a Store event that can be used to interact with the store. 
	
	e.g.<pre>
	<br/>using com.apama.memorystore.Storage; 
	<br/>using com.apama.memorystore.Store; 
	<br/>using com.apama.memorystore.Finished; 
	<br/>
	<br/>monitor Test { 
	<br/>	Storage storage; 
	<br/>	Store store; 
	<br/>
	<br/>	action onload() { 
	<br/>		integer id := storage.prepareOrCreate("storename", "/tmp/example.dat"); 
	<br/>		Finished f; 
	<br/>		on Finished(id=id):f
	<br/>		{
	<br/>			if not f.success { log "Store creation failed: "+f.status at ERROR; die; } 
	<br/>			store := storage.open("storename");
	<br/>			...
	<br/>		}
	<br/>	} 
	<br/>}
	</pre>

	@see Store The purpose of the Storage event is to prepare and open stores. 
	@see #prepareOrCreate() The most commonly used action for preparing a 
		persistent Store. 
	@see #open() Once a store has been prepared it can be opened. 
*/
event Storage {
	/** @private*/ import "MemoryStorePlugin" as plugin;

	/** Prepare an in-memory read-write store 
		to be opened and used by the application.
	
		@param name A unique name identifying this Store. 
		@returns The unique identifier for this operation, which will be 
			included in the Finished event sent after the operation is 
			complete and it becomes safe to call open() on this store. 
		@see Finished A Finished event will be sent when this asynchronous 
			operation has completed. 
	*/
	static action prepareInMemory(string name) returns integer {
		return plugin.prepareInMemory(name);
	}

	/** Prepare a distributed store (e.g. distributed cache) 
		to be opened and used by the application.
	
		@param name A unique name identifying this Store, 
			which also specifies the id of its configuration bean in the XML 
			configuration file. This name should not contain spaces.
		@returns The unique identifier for this operation, which will be 
			included in the Finished event sent after the operation is 
			complete and it becomes safe to call open() on this store. 
		@see Finished A Finished event will be sent when this asynchronous 
			operation has completed. 

	*/
	static action prepareDistributed(string name) returns integer {
		return plugin.prepareDistributed(name);
	}

	/** Indicates whether configuration for the given distributed
	 	store name exists. 

		Returning false indicates that a prepareDistributed of
		the store name will definitely fail.  True indicates
		it may succeed, but is not a guarantee of success.
		Does not actually connect to the distributed store.

		@returns false if prepareDistributed for the given
			store name will definitely fail
	*/
	static action hasDistributedStore(string name) returns boolean {
		return plugin.hasDistributedStore(name);
	}


	/** Prepare a Correlator-persistent read-write store 
		to be opened and used by the application.
		
		Only supported when the Correlator was configured with persistence enabled. 
		
		All committed changes made to a Correlator-persistent store are 
		persisted to disk automatically whenever the Correlator takes a 
		snapshot of the Correlator persistent application state. 
		Because the Correlator determines when to persist its state, you 
		cannot explicitly request persistence for a Correlator-persistent 
		store or any tables it contains.

		Attempts to create a Correlator-persistent store in a Correlator that 
		does not have persistence enabled will result in an error that will 
		terminate the monitor instance. 
	
		@param name A unique name identifying this Store. 
		@returns The unique identifier for this operation, which will be 
			included in the Finished event sent after the operation is 
			complete and it becomes safe to call open() on this store. 
		@see Finished A Finished event will be sent when this asynchronous 
			operation has completed. 
	*/
	static action prepareCorrelatorPersistent(string name) returns integer {
		return plugin.prepareCorrelatorPersistent(name);
	}

	/** Prepare a file-based read-write store associated with an existing 
		MemoryStore database file on disk. 
	
		The specified file must exist and must have been created by the 
		MemoryStore. If the specified file does not exist, or cannot be opened 
		for read-write, the Finished event will indicate failure. 
		
		@param name A unique name identifying this Store. 
		@param filename The path of the database file holding the persistent 
			store. If a relative path is specified, it is relative to the 
			directory that contains the associated Apama Studio project
			(i.e. the Correlator working directory). 
		@returns The unique identifier for this operation, which will be 
			included in the Finished event sent after the operation is 
			complete and it becomes safe to call open() on this store. 
		@see Finished A Finished event will be sent when this asynchronous 
			operation has completed. 
	*/			
	static action prepare(string name, string filename) returns integer {
		return plugin.prepare(name, filename);
	}

	/** Prepare a file-based read-write store associated with a 
		MemoryStore database file on disk, which will be created if it does not exist 
		already. 
	
		@param name A unique name identifying this Store. 
		@param filename The path of the database file holding the persistent 
			store. If a relative path is specified, it is relative to the 
			directory that contains the associated Apama Studio project
			(i.e. the Correlator working directory). 
			The parent directory of the specified file must already exist. 
		@returns The unique identifier for this operation, which will be 
			included in the Finished event sent after the operation is 
			complete and it becomes safe to call open() on this store. 
		@see Finished A Finished event will be sent when this asynchronous 
			operation has completed. 
	*/			
	static action prepareOrCreate(string name, string filename) returns integer {
		return plugin.prepareOrCreate(name, filename);
	}

	/** Prepare a file-based read-only store associated with an existing 
		MemoryStore database file on disk. 
	
		@param name A unique name identifying this Store. 
		@param filename The path of the database file holding the persistent 
			store. If a relative path is specified, it is relative to the 
			directory that contains the associated Apama Studio project
			(i.e. the Correlator working directory). 
		@returns The unique identifier for this operation, which will be 
			included in the Finished event sent after the operation is 
			complete and it becomes safe to call open() on this store. 
		@see Finished A Finished event will be sent when this asynchronous 
			operation has completed. 
	*/			
	static action prepareReadOnly(string name, string filename) returns integer {
		return plugin.prepareReadOnly(name, filename);
	}

	/** Indicate whether or not a Store with the specified name has been 
		prepared already. 
	
		@param name A unique name identifying this Store. 
		@returns True if it is safe to call open() on the specified store; 
			false if preparation failed or is still in progress.
	*/
	static action hasStore(string name) returns boolean {
		return plugin.hasStore(name);
	}

	/** Open a named Store that has already been prepared, ready for use by 
		this monitor instance.
	
		Every monitor instance should prepare and open the stores it needs. 
		Multiple monitor instances can have the same table open at the same 
		time.

		It is an error to call open() before a prepare call for the table
		has finished without error.
		
		Note that opening a store will not immediately bring all that store's 
		tables into memory, this only happens when each individual table is 
		itself prepared and opened. 
		
		A persistent monitor can access only Correlator-persistent stores. 
		If a persistent monitor tries to open any other type of store 
		(e.g. in-memory, on-disk or distributed) the monitor instance 
		will terminate with an error.
		
		@param name A unique name identifying this Store. 
	*/
	static action open(string name) returns Store {
		return Store(plugin.open(name));
	}
}
 00000048 C:\dev\apama_win_full_latest\Apama\monitors\data_storage\MemoryStore.mon
TIME 0000000e 1568382756.8,1
MONF 00012475 package com.apama.scenario;

/**
 * This file contains the shared event definitions that are generic across 
 * all Scenarios.  
 *
 * WARNING: 
 *    The event definitions contained in this file form an internal protocol 
 *    and may change between software releases.
 *
 * Notes:
 * 1) The Event definitions contained in this file MUST be considered
 *    as an internal implementation of the communications protocol
 *    between the Apama client API and an Apama server.  As such
 *    these event definitions MUST NOT be considered "stable" and are 
 *    subject to change in any future software release.
 *
 *    The ONLY supported public APIs to the Scenario Service are the 
 *    Java client API (in the com.apama.services.scenario package) and the 
 *    .NET client API (in the Apama.Services.Scenario namespace).  
 *    Customers should not attempt to interface at the event or 
 *    EPL layer. Some events have been changed over time (as 
 *    noted here).
 *
 * 2) Most events now contain an initial field called "scenarioId". This string 
 *    uniquely identifies a scenario inside the correlator, and is used as 
 *    the package name, in several events, and for making up a part of the 
 *    data and control channel names.
 *
 * 3) Events that are intended to be used in a request-response pattern contain
 *    a "messageId" field.  The value of this field must be copied from the 
 *    request event into the response event. The mechanism allows clients to 
 *    match up request-response pairs.
 *
 *
 * $Copyright(c) 2005-2011 Progress Software Corporation (PSC). All rights reserved.$
 * $Copyright (c) 2013-2016 Software AG, Darmstadt, Germany and/or Software AG USA Inc., Reston, VA, USA, and/or its subsidiaries and/or its affiliates and/or their licensors.$
 * Use, reproduction, transfer, publication or disclosure is prohibited except as specifically provided for in your License Agreement with Software AG
 *
 * $Revision: 284562 $
 */

/**
 * Request that a new instance of a specific scenario is created.
 *
 * See also: Created(), Acknowledge()
 *
 * Direction: From the client to the correlator.
 *
 * Response: Acknowledge()
 */
event Create {
	string scenarioId;                   // the unique name of the scenario
	integer messageId;                   // the unique message ID (for request-response matching)
	string owner;                        // the owner (user) of the instance.
	sequence<string> inputFieldValues;   // sequence of INPUT field values in string form
}

/**
 * Notifies all interested clients that a new instance of a specific 
 * scenario has been created. 
 * The event provides the owner (user), initial state, and initial values for 
 * all input fields and all output fields.
 *
 * See also: Create()
 *
 * Direction: From the correlator to the client.
 *
 * Channel: <scenarioId>.Data and <scenarioId>.Data.Raw
 */
event Created { 
	string scenarioId;                   // the unique name of the scenario
	integer messageId;                   // the unique message ID (for request-response matching)
	integer scenarioInstanceId;          // the ID of the scenario instance
	string owner;                        // the owner (user) of the instance.
	string state;                        // the initial state of the instance.
	sequence<string> inputFieldValues;   // sequence of INPUT field values in string form
	sequence<string> outputFieldValues;  // sequence of OUTPUT field values in string form
}


/**
 * Notifies the interested clients of child scenarios created from
 * a parent scenario.
 *
 * Direction: Internal in the correlator
 *
 * Channel: <none>
 */
event ParentChildRelationship {
	string parentScenarioId;
	integer parentScenarioInstanceId;
	string childScenarioId;
	integer childScenarioInstanceId;
}


/**
 * Request that a specific instance of a specific scenario is edited (the input 
 * field values are changed).
 *
 * See also: Edited(), Acknowledge()
 *
 * Direction: From the client to the correlator.
 *
 * Response: Acknowledge()
 */
event Edit { 
	string scenarioId;                   // the unique name of the scenario
	integer messageId;                   // the unique message ID (for request-response matching)
	integer scenarioInstanceId;          // the ID of the scenario instance
	sequence<string> inputFieldValues;   // sequence of INPUT field values in string form
}


/**
 * Notifies all interested clients that a specific instance of a specific 
 * scenario has been edited (the input field values have changed).
 *
 * See also: Edit()
 *
 * Direction: From the correlator to the client.
 *
 * Channel: <scenarioId>.Data and <scenarioId>.Data.Raw
 */
event Edited { 
	string scenarioId;                   // the unique name of the scenario
	integer messageId;                   // the unique message ID (for request-response matching)
	integer scenarioInstanceId;          // the ID of the scenario instance
	sequence<string> inputFieldValues;   // sequence of INPUT field values in string form
	sequence<string> outputFieldValues;  // sequence of OUTPUT field values in string form
}


/**
 * Request that a specific instance of a specific scenario is deleted.
 *
 * See also: Deleted(), Acknowledge()
 *
 * Direction: From the client to the correlator.
 *
 * Response: Acknowledge()
 */
event Delete {
	string scenarioId;                   // the unique name of the scenario
	integer messageId;                   // the unique message ID (for request-response matching)
	integer scenarioInstanceId;          // the ID of the scenario instance
}


/**
 * Notifies all interested clients that a specific instance of a specific 
 * scenario has been deleted.
 *
 * See also: Delete()
 *
 * Direction: From the correlator to the client.
 *
 * Channel: <scenarioId>.Data and <scenarioId>.Data.Raw
 */
event Deleted {
	string scenarioId;                   // the unique name of the scenario
	integer messageId;                   // the unique message ID (for request-response matching)
	integer scenarioInstanceId;          // the ID of the scenario instance
}


/**
 * Indicates that a specific instance of a specific scenario has died.
 * This is sent as a result of a scenario instance use of MonitorScript ondie.
 * This occurs for any of deleting a running scenario, a scenario failing, or 
 * entering the end state.
 *
 * Direction: From the correlator to the client.
 *
 * Channel: <scenarioId>.Data and <scenarioId>.Data.Raw
 */
event InstanceDied {
	string scenarioId;                   // the unique name of the scenario
	integer scenarioInstanceId;          // the ID of the scenario instance
}


/**
 * Contains updated scenario instance output fields.
 * Note that this is the ONLY event type that is sent on the 
 * "<scenarioId>.Data" channel.
 *
 * Direction: From the correlator to the client.
 *
 * Channel: <scenarioId>.Data and <scenarioId>.Data.Raw
 */
event Update { 
	string scenarioId;                   // the unique name of the scenario
	integer scenarioInstanceId;          // the ID of the scenario instance
	float timeStamp;                     // the time of the update (seconds since epoch)
	sequence<string> outputFieldValues;  // sequence of OUTPUT field values in string form
}


/**
 * A general Acknowledgement event that is the "response" to various "request"
 * events such as Create, Edit, Delete.
 *
 * Direction: From the correlator to the client.
 *
 * Channel: <scenarioId>.Control
 */
event Acknowledge { 
	string scenarioId;                   // the unique name of the scenario
	integer messageId;                   // the unique message ID (for request-response matching)
	integer scenarioInstanceId;          // the id of the scenario instance
	boolean success;                     // boolean indication of success
	sequence<string> outputFieldValues;  // sequence of the OUTPUT field values in string form, 
	                                     //   or an empty sequence if success = false
}


/**
 * Indicates that a specific instance of a specific scenario has changed 
 * state, where valid states include "ENDED", "FAILED", "RUNNING".
 *
 * Direction: From the correlator to the client.
 *
 * Channel: <scenarioId>.Data and <scenarioId>.Data.Raw
 */
event StateChange { 
	string scenarioId;                   // the unique name of the scenario.
	integer scenarioInstanceId;          // the ID of the scenario instance.
	string state;                        // the new state.
}


/**
 * Request that each scenario loaded in the correlator send its meta
 * information out on the supplied channel. When all scenarios have
 * sent out this information, a final RequestScenariosDone event will
 * be sent on the same channel.
 *
 * As soon as this event is received, a RequestScenariosAck will be
 * sent on the same channel so client can stop resending the RequestScenarios
 * event.
 *
 * See also: Scenario, RequestScenariosDone, RequestScenariosAck
 *
 * Direction: From the client to the correlator.
 *
 * Response: Scenario() from each loaded scenario.
 */
event RequestScenarios { 
	// renamed for clarity - was Request
	string channel;                      // Name of the private response channel.
}


/**
 * This is a simple marker event that is sent by the correlator to indicate 
 * that it has finished sending all of the Scenario events in response
 * to a RequestScenarios event.
 * 
 * See also: RequestScenarios, Scenario.
 *
 * Direction: From the correlator to the client.
 *
 * Channel: The private channel that was specified in the RequestScenarios event.
 */
event RequestScenariosDone {}

/* This is a simple ack event that is sent by the correlator to indicate the
 * RequestScenarios event is received and the request is being processed
 *
 * See also: RequestScenarios
 *
 * Direction: From the correlator to the client.
 *
 * Channel: The private channel that was specified in the RequestScenarios event.
 */
event RequestScenariosAck {}

/**
 * Request that each instance of the specified scenario send an Instance event 
 * out on the supplied channel. When all instances for the scenario have been 
 * sent out, a final RequestInstancesDone event will be sent on the same channel.
 *
 * See also: Instance, RequestInstancesDone
 *
 * Direction: From the client to the correlator.
 *
 * Response: Instance() from each scenario instance.
 */
event RequestInstancesOnChannel { 
	string scenarioId;                   // Identifier of the scenario for which to return instances. 
	integer messageId;                   // the unique message ID (for request-response matching)
	string channel;                      // Name of the private response channel.
}

/**
 * Request that each instance for the specified user of the specified scenario
 * send an Instance event out on the supplied channel. When all instances for
 * the scenario have been sent out, a final RequestInstancesDone event will be 
 * sent on the same channel.
 *
 * See also: Instance, RequestInstancesDone
 *
 * Direction: From the client to the correlator.
 *
 * Response: Instance() from each scenario instance.
 */
event RequestInstancesOnChannelByUser { 
	string scenarioId;                   // Identifier of the scenario for which to return instances. 
	integer messageId;                   // the unique message ID (for request-response matching)
	string channel;                      // Name of the private response channel.
	string owner;                        // the username to filter by
}


/**
 * This is a simple marker event that is sent by the correlator to indicate 
 * that it has finished sending all of the Instance events in response
 * to a RequestInstancesInternal event.
 * 
 * See also: RequestInstancesInternal, Scenario.
 *
 * Direction: From the correlator to the client.
 *
 * Channel: A unique private channel as specified by the client in a 
 *          RequestScenariosOnChannel event.
 *
 *          Note that previously it would have been on <scenarioId>.Data and 
 *          <scenarioId>.Data.Raw, but that behaviour is now deprecated.
 */
event RequestInstancesDone {
	string scenarioId;                   // Identifier of the scenario for instances were returned. 	
	integer messageId;                   // the unique message ID (for request-response matching)
}


/**
 * Describes the meta-information about a scenario that is loaded in the 
 * correlator.
 * 
 * See also: RequestScenarios, RequestScenariosDone, ScenarioUnloaded
 * 
 * Direction: From correlator to client.
 *
 * Channel:   1) com.apama.scenario to broadcast when loaded.
 *            2) A unique private channel as specified by the client in a 
 *               RequestScenarios event.
 *
 * This event has gained the executionMode field in Apama 4.2
 */
event Scenario {
	string scenarioId;                   // unique identifier for Scenario, e.g. Scenario_statistical$002darbitrage
	string displayName;                  // user-specified name for Scenario, e.g. statistical-arbitrage
	string description;                  // description of the Scenario
	sequence<string> inputNames;         // input parameter names
	sequence<string> inputTypes;         // input parameter types
	sequence<string> inputConstraints;   // input parameter contraints
	sequence<string> inputDefaults;      // input parameter default values
	sequence<string> outputNames;        // output parameter names
	sequence<string> outputTypes;        // output parameter types
	integer executionMode;               // 0 = serial, 1 = parallel, 2 = parallel child. New as of 4.2
	dictionary<string, string> extraParams; // Additional parameters
}



/**
 * Indicates that a specific Scenario definition is being unloaded.
 *
 * Direction: From the correlator to the client.
 *
 * Channel: <scenarioId>.Control
 */
event ScenarioUnloaded { 
	string scenarioId;                   // the unique name of the scenario
}

/**
 * Provides a dump of the current state of a scenario instance.
 * The event definition is identical to the Created event, and includes the 
 * owner (user), initial state, and current values for all input fields and 
 * all output fields.
 *
 * Instance events are sent in response to RequestInstancesOnChannel event 
 * and the deprecated RequestInstancesInternal event; 
 *
 * See also: RequestInstancesOnChannel, RequestInstancesDone, RequestInstancesInternal
 *
 * Direction: From the correlator to the client.
 *
 * Channel: A unique private channel as specified by the client in a 
 *          RequestScenariosOnChannel event.
 *
 *          Note that previously it would have been on <scenarioId>.Data and 
 *          <scenarioId>.Data.Raw, but that behaviour is now deprecated.
 */
event Instance {
	string scenarioId;                   // the unique name of the scenario. 
	integer messageId;                   // the unique message ID (for request-response matching)
	integer scenarioInstanceId;          // the ID of the scenario instance. 
	string owner;                        // the owner (user) of the instance.
	string state;                        // the initial state of the instance.
	sequence<string> inputFieldValues;   // sequence of INPUT field values in string form. 
	sequence<string> outputFieldValues;  // sequence of OUTPUT field values in string form. 
}


/**
 * Indicates this shared MonitorScript has been loaded.
 *
 * Direction: From the correlator to the client.
 *
 * Channel: com.apama.scenario to broadcast when loaded.
 */
event ScenarioServiceLoaded { 
}

/**
 * Indicates this shared MonitorScript is being unloaded.
 *
 * Direction: From the correlator to the client.
 *
 * Channel: com.apama.scenario to broadcast when unloaded.
 */
event ScenarioServiceUnloaded { 
}


/**
 * Set the period over which updates will be queued and coalesced before being
 * sent out on the data channel. Defaults to zero, which means they won't be
 * queued. If it is negative then we won't send any updates on the data channel.
 * This event is deprecated and the ConfigureUpdates event should be used 
 * instead (see below)
 */
event SetThrottlingPeriod {
	float period;   // The period in seconds. Default zero.
}


/**
 * Configures how updates are sent from scenarios.
 * Each scenario is controlled by two configurations - a global default,
 * and an optional per scenario configuration.  The per scenario
 * configuration takes precedence over the global default.
 * The configuration is made up of a number of entries in 
 * the configuration dictionary. The ConfigureUpdate event 
 * is merged into any previous configuration.
 *
 * Global configuration can be modified by specifying an empty string 
 * for scenarioId, and empty values remove values.
 */
event ConfigureUpdates {
	/** Specifies the scenario the configuratio will apply to, or use 
		empty string "" to specify a global default. 
	*/
	string scenarioId;
	/** 
	 * A set of the configurations modified by this event
	 * the key and meaning is one of:
	 * sendThrottled - boolean - whether to send Updates to the 
	 *                           Throttled (.Data) channel (default=true)
	 * throttlePeriod - float - period with which to send Updates. 
	 *                          0.0 means updates are not throttled - 
	 *                          every update is sent on the Throttled 
	 *                          channel. (default=0.0)
	 * sendRaw - boolean - whether to send Updates on the Raw channel 
	 *                     (.Raw) (default=true)
 	 * sendThrottledUser - boolean - whether to send Updates to the 
	 *                     throttled filtered (.Data:username) channel
	 *                     (default=false)
 	 * sendRawUser - boolean - whether to send Updates to the Raw 
	 *                     channel (.Raw:username) (default=false)
	 * routeUpdate - boolean - whether to route Update (and Edited, Deleted) events.
	 * An empty value removes that entry from the configuration
	 */
	dictionary<string,string> configuration;
}

/**
 * Immediately flushes to receivers any scenario Update events that were 
 * waiting for the next throttling period before being sent. 
 * 
 */
event SendQueuedUpdatesNow {
	
}

/* ==========================================================================
 * The following describes INTERNAL event definitions that should not be sent 
 * into the correlator, nor relied upon.
 * ==========================================================================
 */

/**
 * Request that each instance of the specified scenario send an Instance event 
 * out on the scenario Data or Raw channel. When all instances for the scenario
 * have been sent out, a final RequestInstancesDone event will be sent on the 
 * same channel.
 *
 * See also: Instance, RequestInstancesDone, RequestInstancesOnChannel, RequestInstancesOnChannelByUser
 *
 * Direction: From the ScenarioService to the scenario
 *
 * Response: Instance() from each scenario instance, RequestInstancesDone when finished.
 */
event RequestInstancesInternal { 
	string scenarioId;                   // Identifier of the scenario for which to return instances. 
	integer messageId;                   // the unique message ID (for request-response matching)
	string channel;                      // Name of the private response channel.
	boolean internal;                    // if true, events should be routed/ send-to'd the main context
	string owner;                        // owner filter (optional)
	boolean ownerFilter;                 // whether to filter by owner
}

/**
 * A scenario has finished running, but is still discoverable.
 * (i.e. entered end state or failed - but not deleted).
 * Note that this event contains the state as of the last
 * Update/ Edited event - i.e. if an action modified an output variable 
 * and then caused the scenario to fail, the prior modification
 * would not be reflected in this event.
 *
 * This event contains sufficient information for discovery of the
 * scenario instance later
 * 
 * Direction: from scenarios to the ScenarioService sub-monitor (spawned per scenario)
 */
event ScenarioFinished {
	string scenarioId;                   // Identifier of the scenario which has failed. 
	integer scenarioInstanceId;          // the ID of the scenario instance. 
	string owner;                        // the owner (user) of the instance.
	string state;                        // the initial state of the instance.
	sequence<string> inputFieldValues;   // sequence of INPUT field values in string form. 
	sequence<string> outputFieldValues;  // sequence of OUTPUT field values in string form. 
}
/**
 * Only used internally to tell all the scenarios to start routing their
 * meta data (Scenario). It is followed by a sweeper FinishedScenarioRecovery
 * event which indicates that all the scenarios have reported in.
 */
event StartScenarioRecovery {}

/**
 * Sweeper event to indicate that scenario recovery is done. Only used internally.
 */
event FinishedScenarioRecovery {}

/**
 * Trigger discovery of a parallel scenario. Sent from a sub-monitor of
 * ScenarioService to RequestInstancesHandler to create a new sub-monitor.
 */
event RequestInstancesParallel {
	RequestInstancesInternal request;          // the original request event
	dictionary<integer, context> instances;    // all scenario instances and their running context
	integer highestInstanceId;                 // the highest scenarioInstanceId listed in instances (or more accurately, the highest when discovery started)
}

/**
 * Discovery protocol of a parallel scenario. Sent from a scenario instance
 * to RequestInstancesHandler.
 */
event RequestInstancesParallelDone {
	string scenarioId;                   // the unique name of the scenario
	integer messageId;                   // the unique message ID (for request-response matching)
	integer scenarioInstanceId;          // the ID of the scenario instance
}

/**
 * Notification of a new scenario instance
 */
event ParallelStarting {
	string scenarioId;                   // the unique name of the scenario
	integer scenarioInstanceId;          // the ID of the scenario instance
	string owner;                        // the owner of the scenario instance
	context runningCtx;                  // the context the scenario is running in
}

/**
 * Get the current configuration for a given scenario and the default configuration
 */
event GetConfiguration {
	string scenarioId;                   // the unique name of the scenario
}

/**
 * The current configuration for a given scenario and the default configuration
 * @see ConfigureUpdates
 */
event Configuration {
	string scenarioId;                        // the unique name of the scenario
	dictionary<string, string> defaults;      // the global defaults
	dictionary<string, string> configuration; // the scenario configuration (takes precedence)
}


/**
 * An operation has completed. Sent from parallel scenarios to the main context.
 */
event OperationCompleted {
	string scenarioId;
	integer scenarioInstanceId;
	integer messageId;
}

/**
 * Notification that a scenario has loaded a ConfigureUpdates event
 */
event ScenarioProcessedUpdates {
	string scenarioId;
}

/**
 * Request all configuration
 */
event GetAllConfiguration {
	integer requestId;
}

/** 
 * Response all configuration
 */
event AllConfiguration {
	integer requestId;
	dictionary<string, string> defaultConfig;
	dictionary<string, dictionary<string, string> > configurations;
}


/**
 * Library of utility actions
 */
event ScenarioServiceLibrary {

	/**
	 * Get the control channel for a scenario Id. This channel
	 * is always enabled (uses an event set scenario ID)
	 */
	static action getControlChannel(string scenarioId) returns string
	{
		return scenarioId+".Control";
	}
	/**
	 * Get the data channel for a scenario ID. This channel 
	 * is enabled by the sendThrottled configuration key and 
	 * the throttlePeriod key (Update events may be throttled)
	 */
	static action getDataChannel(string scenarioId) returns string
	{
		return scenarioId+".Data";
	}
	/**
	 * Get the raw channel for a scenario ID. This channel
	 * is enabled by the sendRaw configuration key.
	 */
	static action getRawChannel(string scenarioId) returns string
	{
		return scenarioId+".Data.Raw";
	}
	/**
	 * Get the data channel for a scenario Id. This channel 
	 * is enabled by the sendThrottledUser configuration key and 
	 * the throttlePeriod key (Update events may be throttled)
	 */
	static action getDataUserChannel(string channel, string owner) returns string
	{
		return channel+":"+owner;
	}
	/**
	 * Get the raw channel for a scenario Id. This channel
	 * is enabled by the sendRawUser configuration key.
	 */
	static action getRawUserChannel(string channel, string owner) returns string
	{
		return channel+":"+owner;
	}
	
	/**
	 * Merge configuration. Any entries in updates overwrite entries in configuration.
	 * An empty string value removes the value.
	 * @see ConfigureUpdates
	 */
	static action mergeConfiguration(dictionary<string, string> updates, dictionary<string, string> configuration) {
		string k;
		for k in updates.keys() {
			configuration[k]:=updates[k];
			if updates[k]="" {
				configuration.remove(k);
			}
		}
	}
	
	// implementation note: the defaults for sendThrottled, sendRaw, throttlePeriod, etc are in the following actions:
	/**
	 * Get the sendThrottled value from the given configuration
	 * @see ConfigureUpdates
	 */
	static action getSendThrottled(dictionary<string,string> defaults, dictionary<string,string> config) returns boolean {
		string c:=getConfig(defaults, config, "sendThrottled", "true");
		return c = "true";
	}

	/**
	 * Get the sendThrottledUser value from the given configuration
	 * @see ConfigureUpdates
	 */
	static action getSendThrottledUser(dictionary<string,string> defaults, dictionary<string,string> config) returns boolean {
		string c:=getConfig(defaults, config, "sendThrottledUser", "false");
		return c = "true";
	}
	
	/**
	 * Get the sendRaw value from the given configuration
	 * @see ConfigureUpdates
	 */
	static action getSendRaw(dictionary<string,string> defaults, dictionary<string,string> config) returns boolean {
		string c:=getConfig(defaults, config, "sendRaw", "true");
		return c = "true";
	}
	
	/**
	 * Get the sendRawUser value from the given configuration
	 * @see ConfigureUpdates
	 */
	static action getSendRawUser(dictionary<string,string> defaults, dictionary<string,string> config) returns boolean {
		string c:=getConfig(defaults, config, "sendRawUser", "false");
		return c = "true";
	}
	
	/**
	 * Get the throttlePeriod value from the given configuration
	 * @see ConfigureUpdates
	 */
	static action getThrottlePeriod(dictionary<string,string> defaults, dictionary<string,string> config) returns float {
		string c:=getConfig(defaults, config, "throttlePeriod", "0.0");
		return float.parse(c);
	}
	
	/**
	 * Get the routeUpdate value from the given configuration
	 * @see ConfigureUpdates
	 */
	static action getRouteUpdate(dictionary<string,string> defaults, dictionary<string,string> config) returns boolean {
		string c:=getConfig(defaults, config, "routeUpdate", "false");
		return c = "true";
	}
	

	/**
	 * Get the specified key from the configuration dictionaries, reverting to the default 
	 * if none specified.
	 */
	static action getConfig(dictionary<string,string> defaults,
	                 dictionary<string,string> config, 
	                 string key, string _default) returns string {
		if config.hasKey(key) {
			return config[key];
		}
		if defaults.hasKey(key) {
			return defaults[key];
		}
		return _default;
	}

	static action configurationManager(dictionary<string, string> defaultConfig, dictionary<string, dictionary<string, string> > configurations) {
		// the recognised ConfigureUpdates configuration keys, as above:
		dictionary<string,boolean> KNOWN_CONFIG_KEYS := {"sendThrottled":true, "throttlePeriod":false,
		 "sendRaw":true, "sendThrottledUser":true, "sendRawUser":true, "routeUpdate":true};

		dictionary <string,string> EMPTY_DICT:=new dictionary<string,string>;
		ConfigureUpdates cu;
		on all ConfigureUpdates():cu {
			string key;
			for key in cu.configuration.keys() {
				if not KNOWN_CONFIG_KEYS.hasKey(key) {
					log "Unrecognized configuration property "+key+" in event "+cu.toString() at WARN;
				}
			}
			if cu.scenarioId = "" {
				mergeConfiguration(cu.configuration, defaultConfig);
				log "Received "+cu.toString()+" : defaults applicable to all scenarios" at INFO;
			} else {
				if not configurations.hasKey(cu.scenarioId) {
					configurations.add(cu.scenarioId, new dictionary<string,string>);
				}
				mergeConfiguration(cu.configuration, configurations[cu.scenarioId]);
				on ScenarioProcessedUpdates(cu.scenarioId) -> completed ConfigureUpdates(scenarioId=cu.scenarioId) {
					log "Received "+cu.toString()+" : applied to scenario" at INFO;
				}
				on completed ConfigureUpdates(scenarioId=cu.scenarioId) and not ScenarioProcessedUpdates(cu.scenarioId) {
					log "Received "+cu.toString()+" : for scenario that is not yet defined" at INFO;
				}
			}
		}

		GetConfiguration getConfig;
		on all GetConfiguration():getConfig {
			dictionary<string,string> config:=EMPTY_DICT;
			if configurations.hasKey(getConfig.scenarioId) {
				config:=configurations[getConfig.scenarioId];
			}
			route Configuration(getConfig.scenarioId, defaultConfig, config);
		}	
		GetAllConfiguration gac;
		on all GetAllConfiguration():gac {
			route AllConfiguration(gac.requestId, defaultConfig, configurations);
		}
	}
		
}

event CallbackHelper {
	sequence<action<> > callbacks;
	action callback() {
		action<> c;
		for c in callbacks {
			c();
		}
	}
}



/**
 * Base event for tracking configuration for a given scenario
 */
event ScenarioServiceUpdaterBase {
	// these are internal and should not be set by users
	string scenarioId;
	dictionary<string,string> defaultConfig;
	dictionary<string,string> config;
	boolean sendThrottled;
	boolean sendRaw;
	boolean sendAny;
	boolean emitAny;
	boolean sendThrottledUser;
	boolean sendRawUser;
	boolean routeUpdate;
	float throttlePeriod;
	float throttleStart;
	sequence<listener> listeners;
	string controlChannel;
	string rawChannel;
	string dataChannel;

	/**
	 * Called by monitor at onload time
	 * Will maintain configuration for this scenario
	 * @param sId the scenarioId
	 */
	action init(string sId, action<> cb_onUpdate) {
		scenarioId:=sId;
		controlChannel := ScenarioServiceLibrary.getControlChannel(scenarioId);
		rawChannel := ScenarioServiceLibrary.getRawChannel(scenarioId);
		dataChannel := ScenarioServiceLibrary.getDataChannel(scenarioId);
		route GetConfiguration(scenarioId);
		Configuration c;
		listener l:=on Configuration(scenarioId=scenarioId):c {
			config := c.configuration;
			defaultConfig := c.defaults;
			configurationUpdated();
			cb_onUpdate();
		}
		listeners.append(l);
	}

	/**
	 * Listen for further configuration changes.
	 * @param cb_onUpdate callback upon configuration having been updated
	 */	
	action listenToConfigureUpdates(action<> cb_onUpdate) {
		ConfigureUpdates cu;
		listener l:=on all ConfigureUpdates(scenarioId=""):cu or all ConfigureUpdates(scenarioId=scenarioId):cu {
			if(cu.scenarioId != "") {
				route ScenarioProcessedUpdates(cu.scenarioId);
			}
			onConfigureUpdates(cu);
			cb_onUpdate();
		}
		listeners.append(l);
	}

	/**
	 * Called when new ConfigureUpdates event available
	 * @param sId the scenarioId
	 */
	action onConfigureUpdates(ConfigureUpdates cu) {
		if cu.scenarioId = "" {
			ScenarioServiceLibrary.mergeConfiguration(cu.configuration, defaultConfig);
		} else {
			ScenarioServiceLibrary.mergeConfiguration(cu.configuration, config);
		}
		configurationUpdated();
	}
	
	/**
	 * Called when the configuration should be re-parsed.
	 * @param sId the scenarioId
	 */
	action configurationUpdated() {
		sendThrottled:=ScenarioServiceLibrary.getSendThrottled(defaultConfig, config);
		sendThrottledUser:=ScenarioServiceLibrary.getSendThrottledUser(defaultConfig, config);
		if sendThrottled or sendThrottledUser {
			throttlePeriod:=ScenarioServiceLibrary.getThrottlePeriod(defaultConfig, config);
			if(throttlePeriod < 0.0) {
				sendThrottled:=false;
				sendThrottledUser:=false;
			}
			throttleStart:=currentTime;
		}
		sendRaw:=ScenarioServiceLibrary.getSendRaw(defaultConfig, config);
		sendRawUser:=ScenarioServiceLibrary.getSendRawUser(defaultConfig, config);
		routeUpdate:=ScenarioServiceLibrary.getRouteUpdate(defaultConfig, config);
		sendAny:= sendRaw or sendThrottled or routeUpdate or sendRawUser or sendThrottledUser;
		emitAny:= sendRaw or sendThrottled or sendRawUser or sendThrottledUser;
	}

	/** 
	 * Get whether this scenario should send on the throttled (Data) channel
	 */
	action isSendThrottled() returns boolean {
		return sendThrottled or sendThrottledUser;
	}

	/** 
	 * Get whether this scenario should send on the raw channel
	 */
	action isSendRaw() returns boolean {
		return sendRaw or sendRawUser;
	}

	action doEmit(string emitted, string owner) {
		if sendRaw {
			emit emitted to rawChannel;
		}
		if sendThrottled {
			emit emitted to dataChannel;
		}
		if sendRawUser {
			emit emitted to ScenarioServiceLibrary.getRawUserChannel(rawChannel, owner);
		}
		if sendThrottledUser {
			emit emitted to ScenarioServiceLibrary.getDataUserChannel(dataChannel, owner);
		}
	}

	/**
 	 * Kill any listeners this object has started
	 */
	action destroy() {
		listener l;
		for l in listeners {
			l.quit();
		}
	}
}


/**
 * Utility event for tracking configuration for a given scenario.
 * This event is suitable for use by monitors which spawn per instance
 * (e.g. Scenarios)
 * 
 * This event also uses a callback to get the updates (supplied in
 * instanceInit). If the scenario is configured to only send throttled 
 * updates, the callback is only called when the throttling period 
 * determines an update should be sent - thus, the scenario does not
 * need to generate the output sequence<string> except when needed,
 * which can improve performance in such a configuration.
 * 
 * actions starting with an underscore should be considered private 
 * and not called by users of this event.
 */
event ScenarioServiceUpdaterSingleInstance {
	// these are internal and should not be set by users
	string scenarioId;
	integer scenarioInstanceId;
	listener throttlingListener;
	ScenarioServiceUpdaterBase base;
	boolean havePending;
	float latestUpdate;
	action<> returns sequence<string> getUpdate;
	Update update;
	boolean needUpdate;
	context mainContext;
	string owner;
	string controlChannel;
	string rawChannel;
	string dataChannel;

	/**
	 * Called by monitor at onload time
	 * Will maintain configuration for this scenario
	 */
	action init(string sId) {
		init_cb(sId, _noopAction);
	}
	
	/**
	 * Called by monitor at onload time
	 * Will maintain configuration for this scenario.
	 * cb_init is called when initialisation is complete
	 */
	action init_cb(string sId, action<> cb_init) {
		base.init(sId, cb_init);
		scenarioId:=sId;
		controlChannel := ScenarioServiceLibrary.getControlChannel(scenarioId);
		rawChannel := ScenarioServiceLibrary.getRawChannel(scenarioId);
		dataChannel := ScenarioServiceLibrary.getDataChannel(scenarioId);
		base.listenToConfigureUpdates(_noopAction);
		mainContext:=context.current();
	}

	action _noopAction() {
	}
	

	/**
	 * Called by monitor after spawn
	 * Will maintain configuration for this scenario, and update listeners appropriately.
	 * @param getUpdateCallback a callback to get the latest outputFieldValues - may be called at any time, must 
	 *        always return a consistent set of outputs
	 */
	action instanceInit(integer id, action<> returns sequence<string> getUpdateCallback, string _owner) {
		scenarioInstanceId:=id;
		owner:=_owner;
		getUpdate:=getUpdateCallback;
		update.scenarioId:=scenarioId;
		update.scenarioInstanceId:=scenarioInstanceId;
		base.listenToConfigureUpdates(_configurationUpdated);
		_configurationUpdated();
		listener l:=on all SendQueuedUpdatesNow() {
			_sendThrottledUpdate();
		}
		base.listeners.append(l);
	}

	/** 
	 * Get whether this scenario should route updates
	 */
	action isRouteUpdate() returns boolean {
		return base.routeUpdate;
	}

	/**
 	 * Kill any listeners this object has started
	 */
	action destroy() {
		base.destroy();
		throttlingListener.quit();
	}
	  
	/**
	 * called in instances (not factories) when configuration has changed
	 */
	action _configurationUpdated() {
		if base.isSendThrottled() {
			throttlingListener.quit();
			flushPending();
			if(base.throttlePeriod >= 0.0) {
				if havePending {
					_setupThrottleListener();
				}
			}
		}
	}

	/**
	 * set up a throttled listener according to throttlePeriod control
	 */
	action _setupThrottleListener() {
		if base.throttlePeriod > 0.0 {
			float offset:=currentTime-base.throttleStart;
			float t:=((offset/base.throttlePeriod).floor()+1).toFloat();
			throttlingListener:=on wait((t*base.throttlePeriod)-offset) {
				_sendThrottledUpdate();
			}
		} else {
			_sendThrottledUpdate();
		}
	}

	/**
	 * actually send an update on the throttled channel
	 */
	action _sendThrottledUpdate() {
		if not havePending {
			return;
		}
		if needUpdate {
			update.outputFieldValues:=getUpdate();
			update.timeStamp:=latestUpdate;
			needUpdate:=false;
		}
		if base.sendThrottled {
			send update to dataChannel;
		}
		if base.sendThrottledUser {
			send update to ScenarioServiceLibrary.getDataUserChannel(dataChannel, owner);
		}
		havePending:=false;
	}

	/**
	 * flush any pending update on the throttled channel.
	 */
	action flushPending() {
		if havePending {
			_sendThrottledUpdate();
			throttlingListener.quit();
		}
	}	

	/**
 	 * Called when a new update is available.
	 */
	action newUpdateAvailable() {
		needUpdate:=true;
		latestUpdate:=currentTime;
 		if base.sendRaw or base.routeUpdate {
			if needUpdate {
				update.outputFieldValues:=getUpdate();
				update.timeStamp:=currentTime;
				needUpdate:=false;
			}
			if base.sendRaw {
				send update to rawChannel;
			}
			if base.sendRawUser {
				send update to ScenarioServiceLibrary.getRawUserChannel(rawChannel, owner);
			}
			if base.routeUpdate {
				route update;
			}
		}
		if base.isSendThrottled() and not havePending {
			havePending:=true;
			_setupThrottleListener();
		}
	}
	
	/**
 	 * Called to send a new Acknowledgement event.
	 */
	action emitAcknowledgement(integer messageId) {
		Acknowledge ack:=Acknowledge(scenarioId, messageId, scenarioInstanceId, true, getUpdate());
		if base.routeUpdate {
			route ack;
		}
		if base.emitAny {
			send ack to controlChannel;
		}
	}
				
	/**
 	 * Called to send a new Nak event.
	 */
	action emitNack(integer messageId) {
		Acknowledge nack:=Acknowledge(scenarioId, messageId, scenarioInstanceId, false, new sequence<string>);
		if base.routeUpdate {
			route nack;
		}
		if base.emitAny {
			send nack to controlChannel;
		}
	}
	
	/**
 	 * Called to send a new Created event.
	 */
	action emitCreated(integer messageId, string owner, string state, sequence<string> inputVariables, sequence<string> outputVariables) {
		if base.sendAny {
			Created created:=Created(scenarioId, messageId, scenarioInstanceId, owner, state, inputVariables, outputVariables);
			route created;
			if base.emitAny {
				base.doEmit(created.toString(), owner);
			}
		}
	}
	
	/**
 	 * Called to send a new Edited event.
	 */
	action emitEdited(integer messageId, sequence<string> inputVariables) {
		flushPending();
		if base.sendAny {
			Edited edited:=Edited(scenarioId, messageId, scenarioInstanceId, inputVariables, getUpdate());
			if base.routeUpdate {
				route edited;
			}
			if base.emitAny {
				base.doEmit(edited.toString(), owner);
			}
		}
		emitOpCompleted(messageId);
	}

	/**
 	 * Called to say an operation has completed; implied by emitEdited. Must be called before emitInstanceDied.
	 */
	action emitOpCompleted(integer messageId) {
		if(context.current().getId()!=mainContext.getId()) {
			send OperationCompleted(scenarioId, scenarioInstanceId, messageId) to mainContext;
		}
	}

	/**
 	 * Called to send a new Deleted event.
	 */
	action emitDeleted(integer messageId) {
		flushPending();
		if base.sendAny {
			Deleted deleted:=Deleted(scenarioId, messageId, scenarioInstanceId);
			if base.routeUpdate {
				route deleted;
			}
			if base.emitAny {
				base.doEmit(deleted.toString(), owner);
			}
		}
		throttlingListener.quit();
		notifyInstanceDied();
	}

	/**
 	 * Called to send an instance Died event (either of failed, ended)
	 */
	action emitInstanceDied() {
		flushPending();
		if base.sendAny {
			InstanceDied iDied:=InstanceDied(scenarioId, scenarioInstanceId);
			if base.emitAny {
				base.doEmit(iDied.toString(), owner);
			}
			if mainContext.getId()=context.current().getId() {
				route iDied;
			}
		}
		throttlingListener.quit();
	}

	/**
 	 * Called to notify the scenario service monitor that we have gone away - must be called 
 	 * after emitting any events regarding this instance going away. Implied by emitDeleted.
	 */
	action notifyInstanceDied() {
		if mainContext.getId()!=context.current().getId() {
			InstanceDied iDied:=InstanceDied(scenarioId, scenarioInstanceId);
			
			// give a chance for anyone monitoring this from its own context 
			// to handle the InstanceDied before the main context
			if base.routeUpdate {
				route InstanceDied(scenarioId, scenarioInstanceId);
			}

			send iDied to mainContext;
		}
	}
	
	/**
 	 * Called to send a new StateChange event.
	 */
	action emitStateChange(string state) {
		flushPending();
		StateChange stchange:=StateChange(scenarioId, scenarioInstanceId, state);
		if mainContext.getId()!=context.current().getId() {
			send stchange to mainContext;
		} else {
			route stchange;
		}
		if base.emitAny {
			base.doEmit(stchange.toString(), owner);
		}
	}

	/**
 	 * Called to send an instance in response to a RequestInstancesInternal event
	 */
	action emitInstance(RequestInstancesInternal request, string owner, string state, sequence<string> input, sequence<string> output) {
		Instance instance:=Instance(scenarioId, request.messageId, scenarioInstanceId, owner, state, input, output);
		if request.internal {
			if mainContext.getId() != context.current().getId() {
				send instance to mainContext;
			} else {
				route instance;
			}
		} else {
			if(base.emitAny) {
				send instance to request.channel;
			}
		}
		if mainContext.getId() != context.current().getId() {
			send RequestInstancesParallelDone(scenarioId, request.messageId, scenarioInstanceId) to mainContext;
		}
	}

	/**
 	 * Called when the instance has failed.  input and output are the input
 	 * and output variables as at the last Update/ Edited point.
	 */
	action finished(string state, string owner, sequence<string> input, sequence<string> output) {
		ScenarioFinished scenFinished:=ScenarioFinished(scenarioId, scenarioInstanceId, owner, state, input, output);
		if mainContext.getId() != context.current().getId() {
			send scenFinished to mainContext;
		} else {
			route scenFinished;
		}
	}
	
}


/**
 * Utility event for tracking configuration for a given scenario.
 * This event is suitable for use by monitors which spawn per scenario,
 * but not per instance. (e.g. ScenarioService, DataViewService)
 * 
 * actions starting with an underscore should be considered private 
 * and not called by users of this event.
 * 
 * Note that this updater only honours sendThrottledUser changes at the next throttling period
 * (it does not record the owner if sendThrottledUser is not true)
 */
event ScenarioServiceUpdaterMultipleInstances {
	// these are internal and should not be set by users
	string scenarioId;
	listener throttlingListener;
	ScenarioServiceUpdaterBase base;
	boolean currentlySendingThrottledUser;
	dictionary<integer, Update> updates;
	dictionary<integer, string> owners;
	context mainContext;
	string controlChannel;
	string rawChannel;
	string dataChannel;

	/**
	 * Called by monitor for each scenario
	 * Will maintain configuration for this scenario Id
	 */
	action init(string sId, context mainCtx) {
		_init(sId, mainCtx, _configurationUpdated);
	}
	
	/**
	 * Called by monitor for each scenario
	 * Will maintain configuration for this scenario Id
	 */
	action init_cb(string sId, context mainCtx, action<> cb_initComplete) {
		CallbackHelper callbackHelper:=new CallbackHelper;
		callbackHelper.callbacks.append(cb_initComplete);
		callbackHelper.callbacks.append(_configurationUpdated);
		_init(sId, mainCtx, callbackHelper.callback);
	}

	/**
	 * Implementation of init and init_cb
	 */
	action _init(string sId, context mainCtx, action<> cb_initComplete) {
		base.init(sId, cb_initComplete);
		mainContext:=mainCtx;
		scenarioId:=sId;
		controlChannel := ScenarioServiceLibrary.getControlChannel(scenarioId);
		rawChannel := ScenarioServiceLibrary.getRawChannel(scenarioId);
		dataChannel := ScenarioServiceLibrary.getDataChannel(scenarioId);
		listener l:=on all SendQueuedUpdatesNow() {
			_sendThrottledUpdates();
		}
		base.listeners.append(l);
		base.listenToConfigureUpdates(_configurationUpdated);
	}
	
	/** 
	 * Get whether this scenario should route updates
	 */
	action isRouteUpdate() returns boolean {
		return base.routeUpdate;
	}

	/**
 	 * Kill any listeners this object has started
	 */
	action destroy() {
		base.destroy();
		throttlingListener.quit();
	}
	  

	/**
	 * called in instances (not factories) when configuration has changed
	 */
	action _configurationUpdated() {
		if base.isSendThrottled() {
			throttlingListener.quit();
			flushPending();
			if(base.throttlePeriod >= 0.0) {
				_setupThrottleListener();
			}
		}
	}

	/**
	 * set up a throttled listener according to throttlePeriod control
	 */
	action _setupThrottleListener() {
		if base.throttlePeriod > 0.0 {
			throttlingListener:=on all wait(base.throttlePeriod) {
				_sendThrottledUpdates();
			}
		} else {
			_sendThrottledUpdates();
		}
	}

	/**
	 * actually send an update on the throttled channel
	 */
	action _sendThrottledUpdates() {
		integer instance;
		if base.sendThrottled {
			for instance in updates.keys() {
				send updates[instance] to dataChannel;
			}
		}
		if currentlySendingThrottledUser {
			for instance in updates.keys() {
				send updates[instance] to ScenarioServiceLibrary.getDataUserChannel(dataChannel, owners[instance]);
			}
		}
		owners.clear();
		updates.clear();
		currentlySendingThrottledUser := base.sendThrottledUser;
	}

	/**
	 * flush any pending update on the throttled channel.
	 */
	action flushPending() {
		_sendThrottledUpdates();
	}	

	/**
 	 * Flush pending throttled data for one instance
	 */
	action flushPendingInstance(integer scenarioInstanceId) {
		if updates.hasKey(scenarioInstanceId) {
			if base.sendThrottled {
				send updates[scenarioInstanceId] to dataChannel;
			}
			if currentlySendingThrottledUser {
				send updates[scenarioInstanceId] to ScenarioServiceLibrary.getDataUserChannel(dataChannel, owners[scenarioInstanceId]);
			}
			updates.remove(scenarioInstanceId);
			if owners.hasKey(scenarioInstanceId) {
				owners.remove(scenarioInstanceId);
			}
		}
	}	

	/**
 	 * Called when a new update is available. (This variant allows setting of the time parameter)
	 */
	action emitUpdate_time(integer scenarioInstanceId, float time, sequence<string> output, string owner) {
		if base.sendAny {
			Update update:=Update(scenarioId, scenarioInstanceId, time, output);
			if base.sendRaw {
				send update to rawChannel;
			}
			if base.sendRawUser {
				send update to ScenarioServiceLibrary.getRawUserChannel(rawChannel, owner);
			}
			if base.routeUpdate {
				route update;
			}
			if base.isSendThrottled() {
				if base.throttlePeriod > 0.0 {
					updates.add(scenarioInstanceId, update);
					if currentlySendingThrottledUser {
						owners.add(scenarioInstanceId, owner);
					}
				} else {
					send update to dataChannel;
				}
			}
		}
	}
	
	/**
 	 * Called when a new update is available.
	 */
	action emitUpdate(integer scenarioInstanceId, sequence<string> output, string owner) {
		emitUpdate_time(scenarioInstanceId, currentTime, output, owner);
	}

	/**
 	 * Called to send a new Acknowledgement event.
	 */
	action emitAcknowledgement(integer messageId, integer scenarioInstanceId, sequence<string> output) {
		Acknowledge ack:=Acknowledge(scenarioId, messageId, scenarioInstanceId, true, output);
		if base.routeUpdate {
			route ack;
		}
		if base.emitAny {
			send ack to controlChannel;
		}
	}
				
	/**
 	 * Called to send a new Nak event.
	 */
	action emitNack(integer messageId, integer scenarioInstanceId) {
		Acknowledge nack:=Acknowledge(scenarioId, messageId, scenarioInstanceId, false, new sequence<string>);
		if base.routeUpdate {
			route nack;
		}
		if base.emitAny {
			send nack to controlChannel;
		}
	}
	
	/**
 	 * Called to send a new Created event.
	 */
	action emitCreated(integer messageId, integer scenarioInstanceId, string owner, string state, sequence<string> inputVariables, sequence<string> outputVariables) {
		if base.sendAny {
			Created created:=Created(scenarioId, messageId, scenarioInstanceId, owner, state, inputVariables, outputVariables);
			route created;
			if base.emitAny {
				string sCreated:=created.toString();
				base.doEmit(sCreated, owner);
			}
		}
	}

	/**
 	 * Called to send any received events (except for instance) for this scenario.
	 */
	action emitReceivedEvents() {
		dictionary<integer, string> instanceOwners:=new dictionary<integer, string>;
		{
			Update update;
			listener l:=on all Update(scenarioId = scenarioId):update {
				if base.sendRaw {
					send update to rawChannel;
				}
				if base.sendRawUser and instanceOwners.hasKey(update.scenarioInstanceId) {	
					send update to ScenarioServiceLibrary.getRawUserChannel(rawChannel, instanceOwners[update.scenarioInstanceId]);
				}
				if base.isSendThrottled() {
					if base.throttlePeriod > 0.0 {
						updates.add(update.scenarioInstanceId, update);
						string owner:="*";
						if instanceOwners.hasKey(update.scenarioInstanceId) {
							owner:=instanceOwners[update.scenarioInstanceId];
						}
						if currentlySendingThrottledUser {
							owners.add(update.scenarioInstanceId, owner);
						}
					} else {
						send update to dataChannel;
					}
				}
			}
			base.listeners.append(l);
		}
		{
			Created created;
			listener l:=on all Created(scenarioId = scenarioId):created {
				if(created.owner != "*") {
					instanceOwners.add(created.scenarioInstanceId, created.owner);
				}
				base.doEmit(created.toString(), created.owner);				
			}
			base.listeners.append(l);
		}
		{
			Deleted deleted;
			listener l:=on all Deleted(scenarioId = scenarioId):deleted {
				flushPendingInstance(deleted.scenarioInstanceId);
				string owner:="*";
				if instanceOwners.hasKey(deleted.scenarioInstanceId) {
					owner:=instanceOwners[deleted.scenarioInstanceId];
					instanceOwners.remove(deleted.scenarioInstanceId);
				}
				base.doEmit(deleted.toString(), owner);		
			}
			base.listeners.append(l);
		}
		{
			Edited edited;
			listener l:=on all Edited(scenarioId = scenarioId):edited {
				flushPendingInstance(edited.scenarioInstanceId);
				string owner:="*";
				if instanceOwners.hasKey(edited.scenarioInstanceId) {
					owner:=instanceOwners[edited.scenarioInstanceId];
				}
				base.doEmit(edited.toString(), owner);		
			}
			base.listeners.append(l);
		}
		{
			InstanceDied instanceDied;
			listener l:=on all InstanceDied(scenarioId = scenarioId):instanceDied {
				flushPendingInstance(instanceDied.scenarioInstanceId);
				string owner:="*";
				if instanceOwners.hasKey(instanceDied.scenarioInstanceId) {
					owner:=instanceOwners[instanceDied.scenarioInstanceId];
				}
				base.doEmit(instanceDied.toString(), owner);		
			}
			base.listeners.append(l);
		}
	}
	
	/**
 	 * Called to send a new Edited event.
	 */
	action emitEdited(integer messageId, integer scenarioInstanceId, sequence<string> inputVariables, sequence<string> outputVariables, string owner) {
		flushPendingInstance(scenarioInstanceId);
		if base.sendAny {
			Edited edited:=Edited(scenarioId, messageId, scenarioInstanceId, inputVariables, outputVariables);
			if base.routeUpdate {
				route edited;
			}
			if base.emitAny {
				base.doEmit(edited.toString(), owner);
			}
		}
		emitOpCompleted(messageId, scenarioInstanceId);
	}

	/**
 	 * Called to say an operation has completed; implied by emitEdited. Must be called before emitInstanceDied.
	 */
	action emitOpCompleted(integer messageId, integer scenarioInstanceId) {
		if(context.current().getId()!=mainContext.getId()) {
			send OperationCompleted(scenarioId, scenarioInstanceId, messageId) to mainContext;
		}
	}

	/**
 	 * Called to send a new Deleted event.
	 */
	action emitDeleted(integer messageId, integer scenarioInstanceId, string owner) {
		flushPendingInstance(scenarioInstanceId);
		if base.sendAny {
			Deleted deleted:=Deleted(scenarioId, messageId, scenarioInstanceId);
			if base.routeUpdate {
				route deleted;
			}
			if base.emitAny {
				base.doEmit(deleted.toString(), owner);
			}
		}
		notifyInstanceDied(scenarioInstanceId);
	}

	/**
 	 * Called to notify the scenario service monitor that we have gone away - must be called 
 	 * after emitting any events regarding this instance going away. Implied by emitDeleted.
	 */
	action notifyInstanceDied(integer scenarioInstanceId) {
		if mainContext.getId()!=context.current().getId() {
			InstanceDied iDied:=InstanceDied(scenarioId, scenarioInstanceId);
			send iDied to mainContext;
		}
	}
	

	
	/**
 	 * Called to send an instance Died event (either of failed, ended)
	 */
	action emitInstanceDied(integer scenarioInstanceId, string owner) {
		flushPendingInstance(scenarioInstanceId);
		if base.sendAny {
			InstanceDied iDied:=InstanceDied(scenarioId, scenarioInstanceId);
			if base.emitAny {
				base.doEmit(iDied.toString(), owner);
			}
			if mainContext.getId()=context.current().getId() {
				route iDied;
			}
		}
	}
	
	/**
 	 * Called to send a new StateChange event.
	 */
	action emitStateChange(string state, integer scenarioInstanceId, string owner) {
		flushPendingInstance(scenarioInstanceId);
		StateChange stchange:=StateChange(scenarioId, scenarioInstanceId, state);
		if mainContext.getId()!=context.current().getId() {
			send stchange to mainContext;
		} else {
			route stchange;
		}
		if base.emitAny {
			base.doEmit(stchange.toString(), owner);
		}
	}

	/**
 	 * Called to send an instance in response to a RequestInstancesInternal event
	 */
	action emitInstance(RequestInstancesInternal request, integer scenarioInstanceId, string owner, string state, sequence<string> input, sequence<string> output) {
		Instance instance:=Instance(scenarioId, request.messageId, scenarioInstanceId, owner, state, input, output);
		if request.internal {
			if mainContext.getId() != context.current().getId() {
				send instance to mainContext;
			} else {
				route instance;
			}
		} else {
			if(base.emitAny) {
				send instance to request.channel;
			}
		}
		if mainContext.getId() != context.current().getId() {
				send RequestInstancesParallelDone(scenarioId, request.messageId, scenarioInstanceId) to mainContext;
		}
	}
	/**
 	 * Called to send an instance that has already been seen in the current context
	 */
	action emitReceivedInstance(RequestInstancesInternal request, Instance instance) {
		if request.internal {
			if mainContext.getId() != context.current().getId() {
				send instance to mainContext;
			}
		} else {
			if(base.emitAny) {
				send instance to request.channel;
			}
		}
	}
	
}


/*
 * Monitor that performs the following tasks:
 *   - routing/emitting ScenarioServiceLoaded when the service is loaded
 *   - routing/emitting ScenarioServiceUnloaded when the service is unloaded
 *   - routing/emitting a nack if a Create request is ignored
 *   - maintains latest configuration
 *   - tracks state of ended/ failed scenarios
 *   - forwards Edit, Delete events to scenarios in other contexts
 *
 */
monitor ScenarioService {

	event PendingOperation {
		integer messageId;
		integer type; // 0 = delete, 1 = edit
	}

	listener throttledSenderListener;
	RequestScenarios requestScenarios;
	boolean requestingScenarios;
	
	// MetaData relating to the interface
	dictionary<string,string> interfaceMetaData := {
		"interface.package"     :"com.apama.scenario",
		"interface.name"        :"ScenarioService",
		"interface.fileName"    :"ScenarioService.mon",
		"interface.vendor"      :"Apama",
		"interface.version"     :"10.5.0.0.357639",
		"interface.fullVersion" :"rel/10.5.0.x@357639",
		"interface.language"    :"MonitorScript"
	};
	
	// Channel names	
	string scenarioServiceChannel := "com.apama.scenario";
	integer highestInstanceId;


	// the first mThread handles scenario discovery and maps some events to internal events
	action onload() {
		// print version
		log "ScenarioService interface loaded. MetaData: "+interfaceMetaData.toString() at INFO;
		
		// generate the ScenarioServiceLoaded event
		route ScenarioServiceLoaded();
		send ScenarioServiceLoaded() to scenarioServiceChannel;

		dictionary <string,string> defaultConfig:=new dictionary<string,string>;
		dictionary <string, dictionary<string,string> > configurations:=new dictionary<string, dictionary<string,string> >;
		ScenarioServiceLibrary.configurationManager(defaultConfig, configurations);
		RequestInstancesOnChannel requestInstancesOnChannel;
		on all RequestInstancesOnChannel():requestInstancesOnChannel {
			route RequestInstancesInternal(requestInstancesOnChannel.scenarioId, requestInstancesOnChannel.messageId, requestInstancesOnChannel.channel, false, "", false);
			on RequestInstancesDone(scenarioId=requestInstancesOnChannel.scenarioId, messageId=requestInstancesOnChannel.messageId) {
				send RequestInstancesDone(requestInstancesOnChannel.scenarioId, requestInstancesOnChannel.messageId) to requestInstancesOnChannel.channel;
			}
		}

		RequestInstancesOnChannelByUser requestInstancesOnChannelByUser;
		on all RequestInstancesOnChannelByUser():requestInstancesOnChannelByUser {
			route RequestInstancesInternal(requestInstancesOnChannelByUser.scenarioId, requestInstancesOnChannelByUser.messageId, requestInstancesOnChannelByUser.channel, false, requestInstancesOnChannelByUser.owner, true);
			on RequestInstancesDone(scenarioId=requestInstancesOnChannelByUser.scenarioId, messageId=requestInstancesOnChannelByUser.messageId) {
				send RequestInstancesDone(requestInstancesOnChannelByUser.scenarioId, requestInstancesOnChannelByUser.messageId) to requestInstancesOnChannelByUser.channel;
			}
		}
		Scenario scenario;
		on all Scenario():scenario {
			if requestingScenarios {
				send scenario to requestScenarios.channel;
			} else {
				spawn trackScenario(scenario);
			}
		}
		
		ScenarioUnloaded scenarioUnloaded;
		on all ScenarioUnloaded(): scenarioUnloaded {
			send scenarioUnloaded to scenarioServiceChannel;
		}

		
		on all RequestScenarios():requestScenarios {
			send RequestScenariosAck() to requestScenarios.channel;
			route StartScenarioRecovery();
			route FinishedScenarioRecovery();
			requestingScenarios:=true;
			on FinishedScenarioRecovery() {
				requestingScenarios:=false;
				send RequestScenariosDone() to requestScenarios.channel;
			}
		}

		dictionary <string,string> EMPTY_DICT:=new dictionary<string,string>;
		// Pick up any requests for operations on invalid scenarioIds
		Create create;
		on all unmatched Create(): create {
			dictionary<string,string> config:=EMPTY_DICT;
			if configurations.hasKey(create.scenarioId) {
				config:=configurations[create.scenarioId];
			}
			Acknowledge nack := new Acknowledge;
			nack.scenarioId := create.scenarioId;
			nack.messageId := create.messageId;
			nack.success := false;
			log create.scenarioId+": Scenario create ignored - unknown scenarioId." at WARN;
			send nack to ScenarioServiceLibrary.getControlChannel(create.scenarioId);
			if ScenarioServiceLibrary.getRouteUpdate(defaultConfig, config) {
				route nack;
			}
		}

		// The old SetThrottlingPeriod is mapped to a ConfigureUpdates event
		SetThrottlingPeriod setThrottlingPeriod;		
		on all SetThrottlingPeriod():setThrottlingPeriod {
			dictionary<string, string> configChanges:=new dictionary<string,string>;
			if setThrottlingPeriod.period >= 0.0 {
				configChanges["sendThrottled"]:="true";
				configChanges["throttlePeriod"]:=setThrottlingPeriod.period.toString();
			} else {
				configChanges["sendThrottled"]:="false";
			}
			ConfigureUpdates cu:=ConfigureUpdates("", configChanges);
			log "Received deprecated event "+setThrottlingPeriod.toString()+", will re-route as "+cu.toString() at WARN;
			route cu;
		}
	}		
				
	
	action onunload() {
		// generate the ScenarioServiceUnloaded event
		ScenarioServiceUnloaded unloaded := new ScenarioServiceUnloaded;
		route unloaded;
		send unloaded to scenarioServiceChannel;
	}
	
	/**
	 * spawned per scenario, and handles any finished scenario instances.
	 * For parallel scenarios, it also tracks which instance runs in 
	 * which context and forwards Edit and Delete events.
	 */
	action trackScenario(Scenario scenario) {
		on ScenarioUnloaded(scenarioId=scenario.scenarioId) {
			die;
		}
		ScenarioServiceUpdaterMultipleInstances updater:=new ScenarioServiceUpdaterMultipleInstances;
		updater.init(scenario.scenarioId, context.current());
		ScenarioFinished finished;
		on all ScenarioFinished(scenarioId=scenario.scenarioId):finished {
			// Finished scenarios can be deleted (which terminates all listeners for this instance), 
			// discovered, and edits are Nacked 
			Delete delete;
			on Delete(scenarioId=scenario.scenarioId, scenarioInstanceId = finished.scenarioInstanceId):delete {
				updater.emitAcknowledgement(delete.messageId, finished.scenarioInstanceId, finished.outputFieldValues);
				updater.emitDeleted(delete.messageId, finished.scenarioInstanceId, finished.owner);
			}
			Edit edit;
			on all Edit(scenarioId=scenario.scenarioId, scenarioInstanceId=finished.scenarioInstanceId):edit and not 
			            Delete(scenarioId=scenario.scenarioId, scenarioInstanceId = finished.scenarioInstanceId) {
				updater.emitNack(edit.messageId, finished.scenarioInstanceId);
				log scenario.displayName+"("+finished.scenarioInstanceId.toString()+ "): Scenario edit ignored - Scenario is in "+finished.state+" state." at WARN;
			}
			RequestInstancesInternal requestInstances;
			if finished.owner = "*" {
				on all RequestInstancesInternal(scenarioId=scenario.scenarioId):requestInstances and not
						Delete(scenarioId=scenario.scenarioId, scenarioInstanceId = finished.scenarioInstanceId) {
					updater.emitInstance(requestInstances, finished.scenarioInstanceId,
						finished.owner, finished.state, finished.inputFieldValues, finished.outputFieldValues);
				}
			} else {
				on all (RequestInstancesInternal(scenarioId=scenario.scenarioId, ownerFilter=false):requestInstances or
					RequestInstancesInternal(scenarioId=scenario.scenarioId, owner=finished.owner, ownerFilter=true):requestInstances) and not
						Delete(scenarioId=scenario.scenarioId, scenarioInstanceId = finished.scenarioInstanceId) {
					updater.emitInstance(requestInstances, finished.scenarioInstanceId,
						finished.owner, finished.state, finished.inputFieldValues, finished.outputFieldValues);
				}
			}
		}
		if scenario.executionMode > 0 {
			// for parallel scenarios, we keep track of instance to context mapping:
			dictionary<integer, context> runningCtxs := new dictionary<integer, context>;
			// and to owner mapping:
			dictionary<integer, string> ownerCtxs := new dictionary<integer, string>;
			// and by user:
			dictionary<string, dictionary<integer, context> > runningCtxsByOwner := new dictionary<string, dictionary<integer, context> >;
			// maps from instanceId to sequence<messageId>
			dictionary<integer, sequence<PendingOperation> > pendingOperations := new dictionary<integer, sequence<PendingOperation> >;
			ParallelStarting starting;
			on all ParallelStarting(scenarioId = scenario.scenarioId):starting {
				runningCtxs.add(starting.scenarioInstanceId, starting.runningCtx);
				ownerCtxs.add(starting.scenarioInstanceId, starting.owner);
				if not runningCtxsByOwner.hasKey(starting.owner) {
					runningCtxsByOwner.add(starting.owner, new dictionary<integer, context>);
				}
				runningCtxsByOwner[starting.owner].add(starting.scenarioInstanceId, starting.runningCtx);
				highestInstanceId := starting.scenarioInstanceId;
			}
			
			InstanceDied died;
			on all InstanceDied(scenarioId = scenario.scenarioId):died {
				if runningCtxs.hasKey(died.scenarioInstanceId) {
					runningCtxs.remove(died.scenarioInstanceId);
				}
				if ownerCtxs.hasKey(died.scenarioInstanceId) {
					string owner:=ownerCtxs[died.scenarioInstanceId];
					ownerCtxs.remove(died.scenarioInstanceId);
					if runningCtxsByOwner.hasKey(owner) {
						if runningCtxsByOwner[owner].hasKey(died.scenarioInstanceId) {
							runningCtxsByOwner[owner].remove(died.scenarioInstanceId);
						}
						if runningCtxsByOwner[owner].size()=0 {
							runningCtxsByOwner.remove(owner);
						}
					}
				}
				if pendingOperations.hasKey(died.scenarioInstanceId) {
					PendingOperation pending;
					for pending in pendingOperations[died.scenarioInstanceId] {
						if pending.type = 0 {
							route Delete(scenario.scenarioId, pending.messageId, died.scenarioInstanceId);
						} else {
							if pending.type = 1 {
								route Edit(scenario.scenarioId, pending.messageId, died.scenarioInstanceId, new sequence<string>);
							} else {
								log "error: unknown pending operation type "+pending.toString() at ERROR;
							}
						}
					}
					pendingOperations.remove(died.scenarioInstanceId);
				}
			}
			
			// and forward edits, deletes:
			Edit edit;
			on all unmatched Edit(scenarioId = scenario.scenarioId):edit {
				if runningCtxs.hasKey(edit.scenarioInstanceId) {
					send edit to runningCtxs[edit.scenarioInstanceId];
					addPendingOperation(pendingOperations, edit.scenarioInstanceId, edit.messageId, 1);
					on OperationCompleted(scenarioId = scenario.scenarioId, scenarioInstanceId = edit.scenarioInstanceId, messageId = edit.messageId) and not
					   ScenarioFinished(scenarioId = scenario.scenarioId, scenarioInstanceId = edit.scenarioInstanceId){
						removePendingOperation(pendingOperations, edit.scenarioInstanceId, edit.messageId);
					}
				} else {
					log scenario.displayName+"("+edit.scenarioInstanceId.toString()+"): Scenario edit ignored - unknown scenarioInstanceId." at WARN;
					updater.emitNack(edit.messageId, edit.scenarioInstanceId);
				}
			}
			Delete delete;
			on all unmatched Delete(scenarioId = scenario.scenarioId):delete {
				if runningCtxs.hasKey(delete.scenarioInstanceId) {
					send delete to runningCtxs[delete.scenarioInstanceId];
					addPendingOperation(pendingOperations, delete.scenarioInstanceId, delete.messageId, 0);
					on OperationCompleted(scenarioId = scenario.scenarioId, scenarioInstanceId = delete.scenarioInstanceId, messageId = delete.messageId) and not
					   ScenarioFinished(scenarioId = scenario.scenarioId, scenarioInstanceId = delete.scenarioInstanceId){
						removePendingOperation(pendingOperations, delete.scenarioInstanceId, delete.messageId);
					}
				} else {
					log scenario.displayName+"("+delete.scenarioInstanceId.toString()+"): Scenario delete ignored - unknown scenarioInstanceId." at WARN;
					updater.emitNack(delete.messageId, delete.scenarioInstanceId);
				}
			}
			
			// and request instances is handled by a separate monitor. Note that 
			// Finished scenarios are not in the dictionary, but are handled by the finished
			// listener above.
			RequestInstancesInternal reqInstances;
			on all RequestInstancesInternal(scenarioId=scenario.scenarioId):reqInstances {
				if reqInstances.ownerFilter {
					if runningCtxsByOwner.hasKey(reqInstances.owner) {
						dictionary<integer, context> rCtxs:=runningCtxsByOwner[reqInstances.owner];
						if runningCtxsByOwner.hasKey("*") {
							rCtxs:=rCtxs.clone();
							integer i;
							dictionary<integer, context> wildcards:=runningCtxsByOwner["*"];
							for i in wildcards.keys() {
								rCtxs.add(i, wildcards[i]);
							}
						}
						route RequestInstancesParallel(reqInstances, rCtxs, highestInstanceId);
					} else {
						if runningCtxsByOwner.hasKey("*") {
							route RequestInstancesParallel(reqInstances, runningCtxsByOwner["*"], highestInstanceId);
						} else {
							route RequestInstancesParallel(reqInstances, new dictionary<integer,context>, highestInstanceId);
						}
					}
				} else {
					route RequestInstancesParallel(reqInstances, runningCtxs, highestInstanceId);
				}
			}
			ConfigureUpdates cu;
			on all ConfigureUpdates(scenarioId=""):cu or all ConfigureUpdates(scenarioId=scenario.scenarioId):cu {
				integer inst;
				for inst in runningCtxs.keys() {
					send cu to runningCtxs[inst];
				}
			}
			on all SendQueuedUpdatesNow() {
				SendQueuedUpdatesNow snow:=SendQueuedUpdatesNow();
				integer inst;
				for inst in runningCtxs.keys() {
					send snow to runningCtxs[inst];
				}
			}
		}
	}
	
	action addPendingOperation(dictionary<integer,  sequence<PendingOperation> > pendingOperations, integer scenarioInstanceId, integer messageId, integer type) {
		if not pendingOperations.hasKey(scenarioInstanceId) {
			pendingOperations.add(scenarioInstanceId, new sequence<PendingOperation>);
		}
		pendingOperations[scenarioInstanceId].append(PendingOperation(messageId, type));
	}
	
	action removePendingOperation(dictionary<integer, sequence<PendingOperation> > pendingOperations, integer scenarioInstanceId, integer messageId) {
		if not pendingOperations.hasKey(scenarioInstanceId) {
			return;
		}
		integer idx:=-1, i:=0;
		while(i < pendingOperations[scenarioInstanceId].size()) {
			if pendingOperations[scenarioInstanceId][i].messageId = messageId {
				idx:=i;
				break;
			}
			i:=i+1;
		}
		if(idx>=0) {
			pendingOperations[scenarioInstanceId].remove(idx);
		}
		if pendingOperations[scenarioInstanceId].size() = 0 {
			pendingOperations.remove(scenarioInstanceId);
		}
	}	
}

/*
 * Monitor that handles request instances for parallel scenarios:
 * - on a RequestInstancesOnChannel for a parallel scenario, the ScenarioService 
 *   routes a RequestInstancesParallel which triggers this monitor to spawn.
 * - this waits for a response (be it to say the request instances has been 
 *   handled or that the scenario has finished) before sending the 
 *   RequestInstancesDone event 
 *
 * Note that this monitor assumes scenarioInstancesIds always increase over time.
 */
monitor RequestInstancesHandler {
	RequestInstancesParallel req;
	action onload() {
		on all RequestInstancesParallel():req {
			spawn handleRequest();
		}
	}
	
	/**
	 * Forward the request to every context and await responses. We remove 
	 * instances from the dictionary upon receiving an update for them. 
	 */
	action handleRequest() {
		ScenarioServiceUpdaterMultipleInstances updater:=new ScenarioServiceUpdaterMultipleInstances;
		updater.init(req.request.scenarioId, context.current());
		integer k;
		for k in req.instances.keys() {
			send req.request to req.instances[k];
		}
		// if a scenario dies, it will send events in the order ScenarioFinished, InstanceDied:
		ScenarioFinished finished;
		on all ScenarioFinished(scenarioId=req.request.scenarioId, scenarioInstanceId <= req.highestInstanceId):finished {
			// if a scenario dies after it has sent the Instance, do not send another 
			// (the StateChange/ InstanceDied events are sufficient)
			if(req.instances.hasKey(finished.scenarioInstanceId)) {
				updater.emitInstance(req.request, finished.scenarioInstanceId,
					finished.owner, finished.state, finished.inputFieldValues, finished.outputFieldValues);
			}
		}
		// A finished scenario should not be counted
		InstanceDied died;
		on all InstanceDied(scenarioId = req.request.scenarioId, scenarioInstanceId <= req.highestInstanceId):died {
			if(req.instances.hasKey(died.scenarioInstanceId)) {
				req.instances.remove(died.scenarioInstanceId);
				checkFinished();
			}
		}
		RequestInstancesParallelDone pdone;
		on all RequestInstancesParallelDone(scenarioId = req.request.scenarioId, messageId = req.request.messageId):pdone {
			if(req.instances.hasKey(pdone.scenarioInstanceId)) {
				req.instances.remove(pdone.scenarioInstanceId);
				checkFinished();
			}
		}
		checkFinished();
	}
	
	/**
	 * Check whether we are finished.
	 * We are finished if we have no instances left in our dictionary, in which 
	 * case we route a RequestInstancesDone (handled by the ScenarioService monitor)
	 * and terminate.
	 */
	action checkFinished() {
		if req.instances.size()=0 {
			route RequestInstancesDone(req.request.scenarioId, req.request.messageId);
			die;
		}
	}
}

 0000003f C:\dev\apama_win_full_latest\Apama\monitors\ScenarioService.mon
TIME 0000000e 1568382757.1,1
MONF 0000299b // 
// Bridges between the MemoryStore and ScenarioService event APIs. 
//
// Requires: ScenarioService.mon. 
//
// $Copyright(c) 2009-2012 Progress Software Corporation (PSC). All rights reserved.$
// $Copyright (c) 2013-2016 Software AG, Darmstadt, Germany and/or Software AG USA Inc., Reston, VA, USA, and/or its subsidiaries and/or its affiliates and/or their licensors.$
// Use, reproduction, transfer, publication or disclosure is prohibited except as specifically provided for in your License Agreement with Software AG

package com.apama.memorystore;

using com.apama.scenario.Update;
using com.apama.scenario.Create;
using com.apama.scenario.Delete;
using com.apama.scenario.Edit;
using com.apama.scenario.Created;
using com.apama.scenario.Deleted;
using com.apama.scenario.Edited;
using com.apama.scenario.InstanceDied;
using com.apama.scenario.Instance;
using com.apama.scenario.RequestInstancesDone;
using com.apama.scenario.RequestInstancesInternal;
using com.apama.scenario.Scenario;
using com.apama.scenario.ScenarioServiceUpdaterMultipleInstances;
using com.apama.scenario.ScenarioServiceLibrary;
using com.apama.scenario.StartScenarioRecovery;
using com.apama.scenario.ConfigureUpdates;
using com.apama.scenario.GetAllConfiguration;
using com.apama.scenario.AllConfiguration;

/**
	Requests Scenario Service updates for an exposed MemoryStore to be 
	forwarded to the specified Correlator context. 
	
	Note that this is inefficient and does not implement proper flow
	control. Only use for testing or debugging. 
	
	@see Schema#exposeMemoryView Only tables that are configured to expose 
		their contents will be affected by this event. 
*/
event ForwardMemoryStoreUpdatesTo {
	/** The context to which events should be forwarded. */
	context ctx;
}

/** Makes data in MemoryStore available for viewing by 
	any dashboard client that uses the Scenario Service, or as a 
	DataView. 
	
	@private
*/
monitor MemoryStoreScenarioImpl
{
	import "MemoryStorePlugin" as plugin;

	string MEMORYSTORE_SCENARIO_PREFIX := "DV_MEMST_";
	string PREFIX_UPPER := "DV_MEMST`";
	Scenario recoveryResponse;
	boolean doingRecovery;
	// a private context that sends events out.  Should never block on something 
	// that may be blocking on the memory store plugin. That means no 
	// calling into the plugin and no direct send-to to any other 
	// context that may call the plugin.
	// Deadlocks can be avoided using the asyncEnqueuTo method on the
	// plugin, but must only do so if there can only be a bounded 
	// number of such events queued; we use it for scenario discovery only.
	context emitterContext := context("MemoryStore_emitter");
	context asyncForwarding := context("MemoryStore_forwarder");
	context mainContext := context.current();

	action onload()
	{
		spawn asyncForwarder() to asyncForwarding;
		integer id:=integer.getUnique();
		route GetAllConfiguration(id);
		AllConfiguration allConfig;
		on AllConfiguration(requestId = id):allConfig {
			startup(allConfig.defaultConfig, allConfig.configurations);
		}
	}

	event RequestInstancesHandler {
		import "MemoryStorePlugin" as plugin;
		RequestInstancesInternal scenRequestInstances;
		ScenarioServiceUpdaterMultipleInstances updater;
		action<string, RequestInstancesInternal, ScenarioServiceUpdaterMultipleInstances> handleRequestInstances;
		context emitterContext;

		action onConfig() {
			sequence<string> names := ["", ""];
			plugin.decodeScenarioName(scenRequestInstances.scenarioId, names);
			string storeName := names[0], tableName := names[1];

			Storage storage := new Storage;
			if storage.hasStore(storeName)
			{
				Store store := storage.open(storeName);
				if store.hasTable(tableName)
				{
					if updater.base.sendAny
					{
						if plugin.exposingViews(tableName,storeName,isMemory(scenRequestInstances.scenarioId)) {
							spawn spawnTarget() to emitterContext;
							plugin.sendScenarioInstancesFor(tableName,storeName,isMemory(scenRequestInstances.scenarioId),scenRequestInstances.messageId);
						} else {
							route com.apama.scenario.RequestInstancesDone(scenRequestInstances.scenarioId, scenRequestInstances.messageId);
						}
					} else {
						route com.apama.scenario.RequestInstancesDone(scenRequestInstances.scenarioId, scenRequestInstances.messageId);
					}
				}
			}
			updater.destroy();
		}
		action spawnTarget() {
			handleRequestInstances(scenRequestInstances.scenarioId, scenRequestInstances, updater);
		}

		action isMemory(string name) returns boolean
		{
			string MEMORYSTORE_SCENARIO_MEMORY_SUFFIX := "_memory";
			integer index := name.find(MEMORYSTORE_SCENARIO_MEMORY_SUFFIX);
			return index > 0;
		}
	}

	event InvalidRequestHandler {
		ScenarioServiceUpdaterMultipleInstances updater;
		integer messageId;
		integer scenarioInstanceId;

		action handle(string scenarioId, integer messageId, integer scenarioInstanceId) {
			self.messageId := messageId;
			self.scenarioInstanceId := scenarioInstanceId;
			updater.init_cb(scenarioId, context.current(), onConfig);
		}

		action onConfig() {
			updater.emitNack(messageId, scenarioInstanceId);
			updater.destroy();
		}
	}
	
	action startup(dictionary<string, string> defaultConfig, dictionary<string, dictionary<string, string> > configurations) {
		spawn handleNewScenarios(defaultConfig, configurations) to emitterContext;

		//setup listener to listen for discovery
		on all StartScenarioRecovery()
		{
			doingRecovery := true;
			chunk c := plugin.prepareScenariosSnapshot2();
			integer count := plugin.ScenarioChunk_count(c);
			integer i := 0;		
			while i < count
			{
				recoveryResponse.scenarioId := plugin.ScenarioChunk_getId(c,i);
				recoveryResponse.displayName := plugin.ScenarioChunk_getName(c,i);
				recoveryResponse.description := plugin.ScenarioChunk_getDescription(c,i);
				recoveryResponse.outputNames := [];
				integer numFields := plugin.ScenarioChunk_getFieldsLength(c,i);
				integer j := 0;
				while j < numFields
				{
					recoveryResponse.outputNames.append(plugin.ScenarioChunk_getField(c,i,j));
					j := j + 1;
				}
				recoveryResponse.outputTypes := [];
				integer numTypes := plugin.ScenarioChunk_getTypesLength(c,i);
				j := 0;
				while j < numTypes
				{
					recoveryResponse.outputTypes.append(plugin.ScenarioChunk_getType(c,i,j));
					j := j + 1;
				}
				i := i + 1;
				recoveryResponse.extraParams := {"isReadOnly":"true", "type":"dataview"};
				route recoveryResponse;
			}

		}
		on all completed StartScenarioRecovery() {
			doingRecovery := false;
		}

		// initialisation - send all scenarios to the emitter context, spawn for each scenario

		plugin.setEmitContext(emitterContext.getId());

		{
			chunk c := plugin.prepareScenariosSnapshot2();
			integer count := plugin.ScenarioChunk_count(c);
			integer i := 0;		

			while i < count
			{
				spawn handleScenario(plugin.ScenarioChunk_getId(c,i)) to emitterContext;
				i := i + 1;
			}
		}

		// forward scenario service requests:
		ConfigureUpdates configUpdate;
		on all ConfigureUpdates():configUpdate {
			send configUpdate to emitterContext;
		}
		RequestInstancesInternal scenRequestInstances;
		on all RequestInstancesInternal(scenarioId in (MEMORYSTORE_SCENARIO_PREFIX : PREFIX_UPPER)):scenRequestInstances
		{
			ScenarioServiceUpdaterMultipleInstances updater := new ScenarioServiceUpdaterMultipleInstances;
			RequestInstancesHandler handler := RequestInstancesHandler(scenRequestInstances, updater, handleRequestInstances, emitterContext);
			updater.init_cb(scenRequestInstances.scenarioId, context.current(), handler.onConfig);
		}
		Create scenCreate;
		on all Create(scenarioId in (MEMORYSTORE_SCENARIO_PREFIX : PREFIX_UPPER)):scenCreate
		{
			InvalidRequestHandler handler:=new InvalidRequestHandler;
			handler.handle(scenCreate.scenarioId, scenCreate.messageId, -1);
		}

		Delete scenDel;
		on all Delete(scenarioId  in (MEMORYSTORE_SCENARIO_PREFIX : PREFIX_UPPER)):scenDel
		{
			InvalidRequestHandler handler:=new InvalidRequestHandler;
			handler.handle(scenDel.scenarioId, scenDel.messageId, scenDel.scenarioInstanceId);
		}

		Edit scenEdit;
		on all Edit(scenarioId in (MEMORYSTORE_SCENARIO_PREFIX : PREFIX_UPPER)):scenEdit
		{
			InvalidRequestHandler handler:=new InvalidRequestHandler;
			handler.handle(scenEdit.scenarioId, scenEdit.messageId, scenEdit.scenarioInstanceId);
		}
		ForwardMemoryStoreUpdatesTo f;
		on all ForwardMemoryStoreUpdatesTo():f {
			spawn forwardUpdatesTo(f.ctx) to emitterContext;
		}
	}

	action handleNewScenarios(dictionary <string,string> defaultConfig, dictionary <string, dictionary<string,string> > configurations) {

		Scenario scenario;
		on all unmatched Scenario(scenarioId in (MEMORYSTORE_SCENARIO_PREFIX : PREFIX_UPPER)):scenario
		{
			send scenario to "com.apama.scenario";
			spawn handleScenario(scenario.scenarioId);
		}
		ScenarioServiceLibrary.configurationManager(defaultConfig, configurations);
	}
	


	action handleScenario(string scenarioId) {
		on all Scenario(scenarioId = scenarioId) {}

		ScenarioServiceUpdaterMultipleInstances updater := new ScenarioServiceUpdaterMultipleInstances;
		updater.init(scenarioId, asyncForwarding);
		updater.emitReceivedEvents();
	}

	action handleRequestInstances(string scenarioId, RequestInstancesInternal scenRequestInstances, ScenarioServiceUpdaterMultipleInstances updater) {
		Instance scenInstance;
		on all Instance(scenarioId = scenarioId, messageId = scenRequestInstances.messageId):scenInstance and 
			not RequestInstancesDone(scenarioId = scenarioId, messageId = scenRequestInstances.messageId) {
			updater.emitReceivedInstance(scenRequestInstances, scenInstance);
		}
		RequestInstancesDone rid;
		on all RequestInstancesDone(scenarioId = scenarioId, messageId = scenRequestInstances.messageId):rid {
			integer _ := plugin.asyncEnqueueTo(rid.toString(), mainContext.getId()); // doesn't matter when it completes
			die;
		}
	}

	action asyncForwarder() {
		Instance i;
		on all Instance():i {
			integer _:=plugin.asyncEnqueueTo(i.toString(), mainContext.getId());
		}
		RequestInstancesDone rid;
		on all RequestInstancesDone():rid {
			integer _:=plugin.asyncEnqueueTo(rid.toString(), mainContext.getId());
		}
	}

	action forwardUpdatesTo(context ctx) {
		Update u;
		on all Update(scenarioId in (MEMORYSTORE_SCENARIO_PREFIX : PREFIX_UPPER)):u {
			integer _:=plugin.asyncEnqueueTo(u.toString(), ctx.getId());
		}
	}
}

 00000054 C:\dev\apama_win_full_latest\Apama\monitors\data_storage\MemoryStoreScenarioImpl.mon
MONF 00004fa4 package com.apama.dataview;

/*
 * $Copyright(c) 2007, 2008 Progress Software Corporation (PSC). All rights reserved.$
 * $Copyright (c) 2013-2016 Software AG, Darmstadt, Germany and/or Software AG USA Inc., Reston, VA, USA, and/or its subsidiaries and/or its affiliates and/or their licensors.$
 * Use, reproduction, transfer, publication or disclosure is prohibited except as specifically provided for in your License Agreement with Software AG
 */


/* Apama DataViewService API.
 *
 * This service enables MonitorScript or JMon applications to expose a simple 
 * read-only "DataView" interface. DataViews may be viewed using Apama Dashboard 
 * Studio in a similar way to Scenarios.
 *
 * Several implementations of this interface will exist. 
 * Each implementation is in a separate file - inject the one you wish to use.
 *   e.g. DataViewService_Impl_Dict.mon
 *
 * Route vs. Emit
 * The standard implementations of the DataViewService will always ROUTE 
 * any com.apama.dataview.* events, with the expectation that applications
 * using the service are co-located in the same correlator as the service.
 * If your architecture requires the client application to be in a separate 
 * correlator to the DataView service, then two "emitter" monitors are 
 * available.
 * DataViewService_ServiceEmitter.mon  would be injected into the same 
 * correlator as the DataView service after injecting the DataViewService 
 * interface but before injecting the implementation.
 * DataViewService_ApplicationEmitter.mon  would be injected into the same 
 * correlator as the client application after injecting the DataViewService 
 * interface but before injecting the client application.
 * 
 *
 * Notes:
 * 
 * 1) Every event has an initial field called msgId. Clients may choose to put 
 *    some identifier in this field when sending messages to the service. Any 
 *    event routed by the service in response will contain the same identifier.
 *
 * 2) Most events contain a field called "dvName". This string 
 *    uniquely identifies a DataView inside the correlator. 
 *
 * 3) Every event has a final field called extraParams that is a string:string
 *    dictionary. Some implementations may choose to use this field. It provides
 *    a way of future-proofing the interface to a certain extent.
 *
 * $Revision: 279443 $
 */





/* ==========================================================================
 * ==========================================================================
 * Events to send to the DataViewService to manage the DataView schemas
 * ==========================================================================
 * ========================================================================== */


/** Define a new DataView type.
 *
 * Expect either a DataViewDefinition or a DataViewException in response.
 *
 * @see DataViewDefinition, DataViewException, DataViewAddItem
 *
 * Direction: From the application monitor to the DataViewService.
 */
event DataViewAddDefinition {
	/** Optional application-defined message identifier used to correlate 
		requests and responses. */
	string msgId;
	/** The name that uniquely identifies this DataView (e.g. DataView_XXX). */
	string dvName;
	/** The display name of the DataView (e.g. "XXX manager"). */
	string dvDisplayName;
	/** Optional field containing a description of this DataView 
		(e.g. "This DataView exposes XXX objects"). */
	string dvDescription;
	/** Specifies the names of each field exposed by the DataView. */
	sequence<string> fieldNames;
	/** Specifies the types corresponding to each field in the fieldNames sequence. 
		Supported types are: string, float, integer, boolean, decimal. */
	sequence<string> fieldTypes;
	/** Optional set of field names whose values in an Item are to be combined 
		to make a unique key that can be used instead of the dvItemId field of 
		DataViewDeleteItem, DataViewUpdateItem, and DataViewUpdateDelta events.
 	*/
	sequence<string> keyFields;
	
	/** Optional dictionary of extra information about this definition, 
		some of which may be available for display in dashboards and clients. 
		
		DataView implementation-specific parameters may also be stored here. 
		
		To avoid collisions with keys that may be added to the product in 
		future, all user-defined extraParams should start with a prefix 
		identifying the application or organisation they were added for. 
	*/
	dictionary<string, string> extraParams;
}


/** Remove an existing DataView type.
 *
 * Direction: From the customer Monitor to the DataViewService.
 *
 * Response: DataViewUnloaded()
 *
 * @see DataViewUnloaded
 */
event DataViewDeleteDefinition {
	/** [OPTIONAL] A messageId that applications may choose to use to identify "responses". */
	string msgId;
	/** The DataView Name (e.g. conventionally DataView_XXX). */
	string dvName;
	/** [OPTIONAL] Some implementations may choose to make use of this field. 
	
		To avoid collisions with keys that may be added to the product in 
		future, all user-defined extraParams should start with a prefix 
		identifying the application or organisation they were added for. 
	*/
	dictionary<string, string> extraParams;
}


/** Request helper dictionary to facilitate sequence position lookup
 *    by field name.
 *
 * @see DataViewFieldLookup
 *
 * Direction: From the customer Monitor to the DataViewService.
 *
 * Response: DataViewFieldLookup()
 */
event DataViewGetFieldLookup {
	/** [OPTIONAL] A messageId that applications may choose to use to identify "responses". */
	string msgId;
	/** The DataView Name (e.g. conventionally DataView_XXX). */
	string dvName;
	/** [OPTIONAL] Some implementations may choose to make use of this field.
	
		To avoid collisions with keys that may be added to the product in 
		future, all user-defined extraParams should start with a prefix 
		identifying the application or organisation they were added for. 
	 */
	dictionary<string, string> extraParams;
}



/* ==========================================================================
 * ==========================================================================
 * Events to send to the DataViewService to manage individual DataView Items
 * ==========================================================================
 * ========================================================================== */


/** Request that a new Item is added to a specific DataView. Must not already 
* exist. 
*
* @see DataViewItem
*
* Direction: From the customer Monitor to the DataViewService.
*/
event DataViewAddItem {
	/** [OPTIONAL] A messageId that applications may choose to use to identify "responses". */
	string msgId;
	/** The unique name of the DataView. */
	string dvName;
	/** The owner (user) of the Item. */
	string owner;
	/** The timestamp of the initial update (seconds since epoch). If the value given is -1.0 then the service will populate it using correlator currentTime. */
	float timeStamp;
	/** Complete sequence of field values in string form. */
	sequence<string> fieldValues;
	/** [OPTIONAL] Some implementations may choose to make use of this field.
	
		To avoid collisions with keys that may be added to the product in 
		future, all user-defined extraParams should start with a prefix 
		identifying the application or organisation they were added for. 
	 */
	dictionary<string, string> extraParams;
}


/** Request that a new Item is added to a specific DataView if it does not already exist, 
* or is updated when it does exist. 
* 
* This will ONLY work when keyFields are used.
* Attempts to change the owner of an existing item will be rejected with a DataViewItemException.
*
* @see DataViewItem
*
* Direction: From the customer Monitor to the DataViewService.
*/
event DataViewAddOrUpdateItem {
	/** [OPTIONAL] A messageId that applications may choose to use to identify "responses". */
	string msgId;
	/** The unique name of the DataView. */
	string dvName;
	/** The owner (user) of the Item - ONLY used for new items. */
	string owner;
	/** The timestamp of the initial update (seconds since epoch). If the value given is -1.0 then the service will populate it using correlator currentTime. */
	float timeStamp;
	/** Complete sequence of field values in string form. */
	sequence<string> fieldValues;
	/** [OPTIONAL] Some implementations may choose to make use of this field. 
	
		To avoid collisions with keys that may be added to the product in 
		future, all user-defined extraParams should start with a prefix 
		identifying the application or organisation they were added for. 
	*/
	dictionary<string, string> extraParams;
}


/** Contains updated DataView Item fields.
 * Use this to update the fields.
 *
 * Direction: From the customer Monitor to the DataViewService.
 *
 */
event DataViewUpdateItem { 
	/** [OPTIONAL] A messageId that applications may choose to use to identify "responses". */
	string msgId;
	/** The unique name of the DataView. */
	string dvName;
	/** The ID of the Item within the DataView (may be -1 if using keyFields instead). */
	integer dvItemId;
	/** The timestamp of the update (seconds since epoch). If the value given is -1.0 then the service will populate it using correlator currentTime. */
	float timeStamp;
	/** Sequence of field values in string form. */
	sequence<string> fieldValues;
	/** [OPTIONAL] Some implementations may choose to make use of this field. 
	
		To avoid collisions with keys that may be added to the product in 
		future, all user-defined extraParams should start with a prefix 
		identifying the application or organisation they were added for. 
	*/
	dictionary<string, string> extraParams;
}


/** Contains updated DataView Item fields.
 * Use this to update the fields.
 *
 * Direction: From the customer Monitor to the DataViewService.
 *
 */
event DataViewUpdateItemDelta { 
	/** [OPTIONAL] A messageId that applications may choose to use to identify "responses". */
	string msgId;
	/** The unique name of the DataView. */
	string dvName;
	/** The ID of the Item within the DataView (may be -1 if using keyFields instead). */
	integer dvItemId;
	/** The timestamp of the update (seconds since epoch). If the value given is -1.0 then the service will populate it using correlator currentTime. */
	float timeStamp;
	/** Values to be updated. Dictionary Key is index into fields sequence, Value is new field value in sequence. 
	 If not using dvItemId, then the dictionary MUST contain the key values (even though they have not changed). */
	dictionary<integer,string> fieldValues;
	/** [OPTIONAL] Some implementations may choose to make use of this field. 
	
		To avoid collisions with keys that may be added to the product in 
		future, all user-defined extraParams should start with a prefix 
		identifying the application or organisation they were added for. 
	*/
	dictionary<string, string> extraParams;
}


/** Request that a specific Item within a specific DataView is deleted.
 *
 * @see DataViewItemDeleted
 *
 * Direction: From the customer Monitor to the DataViewService.
 */
event DataViewDeleteItem {
	/** [OPTIONAL] A messageId that applications may choose to use to identify "responses". */
	string msgId;
	/** The unique name of the DataView. */
	string dvName;
	/** The ID of the Item within the DataView (may be -1 if using keyFields instead). */
	integer dvItemId;
	/** [OPTIONAL] Sequence of ONLY key field values (if not using the dvItemId). */
	sequence<string> keyFields;
	/** [OPTIONAL] Some implementations may choose to make use of this field. 
	
		To avoid collisions with keys that may be added to the product in 
		future, all user-defined extraParams should start with a prefix 
		identifying the application or organisation they were added for. 
	*/
	dictionary<string, string> extraParams;
}


/** Request that all Items within a specific DataView are deleted.
 *
 * @see DataViewAllItemsDeleted
 *
 * Direction: From the customer Monitor to the DataViewService.
 */
event DataViewDeleteAllItems {
	/** [OPTIONAL] A messageId that applications may choose to use to identify "responses". */
	string msgId;
	/** The unique name of the DataView. */
	string dvName;
	/** [OPTIONAL] Some implementations may choose to make use of this field. 
	
		To avoid collisions with keys that may be added to the product in 
		future, all user-defined extraParams should start with a prefix 
		identifying the application or organisation they were added for. 
	*/
	dictionary<string, string> extraParams;
}


/* ==========================================================================
 * ==========================================================================
 * Events to that are callbacks from DatavViewService
 * ==========================================================================
 * ========================================================================== */


/** Confirmation that a specific DataView definition has been added.
 *
 * Direction: From the DataViewService to the customer Monitor.
 */
event DataViewDefinition {
	/** Optional application-defined message identifier used to correlate 
		requests and responses. */
	string msgId;
	/** The name that uniquely identifies this DataView (e.g. DataView_XXX). */
	string dvName;
	/** The display name of the DataView (e.g. "XXX manager"). */
	string dvDisplayName;
	/** Optional field containing a description of this DataView 
		(e.g. "This DataView exposes XXX objects"). */
	string dvDescription;
	/** Specifies the names of each field exposed by the DataView. */
	sequence<string> fieldNames;
	/** Specifies the types corresponding to each field in the fieldNames sequence. 
		Supported types are: string, float, integer, boolean, decimal. */
	sequence<string> fieldTypes;
	/** Optional set of field names whose values in an Item are to be combined 
		to make a unique key that can be used instead of the dvItemId field of 
		DataViewDeleteItem, DataViewUpdateItem, and DataViewUpdateDelta events.
 	*/
	sequence<string> keyFields;
	/** Optional dictionary of extra parameters.
		DataView implementation-specific parameters may also be stored here. */
	dictionary<string, string> extraParams;
	/** Prefix for identifying metadata entries in the extraParams dictionary.
		Entries with key names prefixed by the EXTRA_PARAMS_METADATA_PREFIX 
		string are considered metadata entries. */
	constant string EXTRA_PARAMS_METADATA_PREFIX := "Metadata:";
}


/** Indicates that a specific DataView definition is being unloaded.
 *
 * Direction: From the DataViewService to the customer Monitor.
 */
event DataViewDefinitionDeleted { 
	/** [OPTIONAL] A messageId that applications may choose to use to identify "responses". */
	string msgId;
	/** The unique name of the DataView. */
	string dvName;
	/** [OPTIONAL] Some implementations may choose to make use of this field. */
	dictionary<string, string> extraParams;
}


/** Notifies all interested clients that a new Item has been added to a specific 
 * DataView. 
 * The event provides the unique itemID, owner (user), and initial values for 
 * all fields.
 *
 * @see DataViewAddItem
 *
 * Direction: From the DataViewService to the customer Monitor.
 *
 */
event DataViewItem { 
	/** [OPTIONAL] A messageId that applications may choose to use to identify "responses". */
	string msgId;
	/** The unique name of the DataView. */
	string dvName;
	/** The ID of the Item within the DataView. */
	integer dvItemId;
	/** The owner (user) of the Item. */
	string owner;
	/** Sequence of field values in string form. */
	sequence<string> fieldValues;
	/** [OPTIONAL] Some implementations may choose to make use of this field. */
	dictionary<string, string> extraParams;
}


/** Notifies all interested clients that a specific Item within a specific 
 * DataView has been deleted.
 *
 * @see DataViewDeleteItem
 *
 * Direction: From the DataViewService to the customer Monitor.
 *
 */
event DataViewItemDeleted {
	/** [OPTIONAL] A messageId that applications may choose to use to identify "responses". */
	string msgId;
	/** The unique name of the DataView. */
	string dvName;
	/** The ID of the Item within the DataView. */
	integer dvItemId;
	/** Sequence of ONLY key field values (for those not using the dvItemId). */
	sequence<string> keyFields;
	/** [OPTIONAL] Some implementations may choose to make use of this field. */
	dictionary<string, string> extraParams;
}


/** Notifies all interested clients that all Items within a specific 
 * DataView have been deleted.
 *
 * @see DataViewDeleteAllItems
 *
 * Direction: From the DataViewService to the customer Monitor.
 *
 */
event DataViewAllItemsDeleted {
	/** [OPTIONAL] A messageId that applications may choose to use to identify "responses". */
	string msgId;
	/** The unique name of the DataView. */
	string dvName;
	/** [OPTIONAL] Some implementations may choose to make use of this field. */
	dictionary<string, string> extraParams;
}


/** The helper dictionary to facilitate sequence position lookup
 *    by field name.
 *
 * @see DataViewGetFieldLookup
 *
 * Direction: From the DataViewService to the customer Monitor.
 */
event DataViewFieldLookup {
	/** [OPTIONAL] A messageId that applications may choose to use to identify "responses". */
	string msgId;
	/** The DataView Name (e.g. conventionally DataView_XXX). */
	string dvName;
	/** A map of fieldName:fieldIndex. */
	dictionary <string, integer> fields;
	/** [OPTIONAL] Some implementations may choose to make use of this field. */
	dictionary<string, string> extraParams;
}


/** Indicates that an exception occurred within the DataViewService, and indicates 
* the name of the specific DataView.
*
* Direction: From the DataViewService to the customer Monitor.
*/
event DataViewException {
	/** [OPTIONAL] A messageId that applications may choose to use to identify "responses". */
	string msgId;
	/** The unique name of the DataView. */
	string dvName;
	/** The message in the exception. This is designed to be human readable, and may change between implementations/versions, hence the wildcard. */
	wildcard string message;
	/** [OPTIONAL] Some implementations may choose to make use of this field. */
	dictionary<string, string> extraParams;
}

/** Indicates that an exception occurred within the DataViewService, and indicates 
* the name of the specific DataView, and the Id of the specific Item.
*
* Direction: From the DataViewService to the customer Monitor.
*/
event DataViewItemException {
	/** [OPTIONAL] A messageId that applications may choose to use to identify "responses". */
	string msgId;
	/** The unique name of the DataView. */
	string dvName;
	/** The ID of the Item within the DataView. */
	integer dvItemId;
	/** The message in the exception. This is designed to be human readable, and may change between implementations/versions, hence the wildcard. */
	wildcard string message;
	/** [OPTIONAL] Some implementations may choose to make use of this field. */
	dictionary<string, string> extraParams;
}


/** Indicates that the DataView service is being unloaded.
 *
 * Direction: From the DataViewService to the customer Monitor.
 */
event DataViewServiceUnloaded { 
	/** [OPTIONAL] Some implementations may choose to make use of this field. */
	dictionary<string, string> extraParams;
}

/** Just logs the DataViewService details upon injection
  @private
*/
monitor DataViewService_Interface {
	// MetaData relating to the interface
	dictionary<string,string> interfaceMetaData := {
		"interface.package"     :"com.apama.dataview",
		"interface.name"        :"DataViewService_Interface",
		"interface.fileName"    :"DataViewService_Interface.mon",
		"interface.vendor"      :"Apama",
		"interface.version"     :"10.5.0.0.357639",
		"interface.fullVersion" :"rel/10.5.0.x@357639",
		"interface.language"    :"MonitorScript"
	};

	action onload() {
		log "DataViewService interface loaded. MetaData: "+interfaceMetaData.toString() at INFO;
	}
}

 00000049 C:\dev\apama_win_full_latest\Apama\monitors\DataViewService_Interface.mon
MONF 0000ec8f package com.apama.dataview;

/*
 * $Copyright(c) 2007-2011 Progress Software Corporation (PSC). All rights reserved.$
 * $Copyright (c) 2013-2017, 2019 Software AG, Darmstadt, Germany and/or Software AG USA Inc., Reston, VA, USA, and/or its subsidiaries and/or its affiliates and/or their licensors.$
 * Use, reproduction, transfer, publication or disclosure is prohibited except as specifically provided for in your License Agreement with Software AG
 */


/* This is an implementation of the Apama DataViewService API.
 *
 * You must first inject the "interface" - DataViewService_Interface.mon
 * Several implementations of the interface may exist. 
 * You may also need to inject optional "emitter" (see below).
 * Each implementation is in a separate file - inject the one you wish to use.
 *   e.g. this implementation is DataViewService_Impl_Dict.mon
 * 
 *
 * This service enables Apama applications to expose a simple 
 * read-only "DataView" interface that is accessible externally to 
 * dashboards and other clients using the Scenario Service.
*
 * Route vs. Send
 * The standard implementations of the DataViewService will always ROUTE 
 * any com.apama.dataview.* events, with the expectation that applications
 * using the service are co-located in the same context as the service.
 * If your architecture requires the client application to be in a separate 
 * context to the DataView service, then two "emitter" monitors are 
 * available.
 * DataViewService_ServiceEmitter.mon would be injected into the same 
 * correlator as the DataView service after injecting the DataViewService 
 * interface but before injecting the implementation.
 * DataViewService_ApplicationEmitter.mon  would be injected into the same 
 * correlator as the client application after injecting the DataViewService 
 * interface but before injecting the client application.
 *
 * Notes:
 * 
 * 1) Every event has an initial field called msgId. Clients may choose to put 
 *    some identifier in this field when sending messages to the service. Any 
 *    event routed by the service in response will contain the same identifier.
 *
 * 2) Most events contain a field called "dvName". This string 
 *    uniquely identifies a DataView inside the correlator. 
 *
 * 3) Every event has a final field called extraParams that is a string:string
 *    dictionary. Some implementations may choose to use this field. It provides
 *    a way of future-proofing the interface to a certain extent.
 *
 * $Revision: 357639 $
 */

using com.apama.scenario.Create;
using com.apama.scenario.Delete;
using com.apama.scenario.Edit;
using com.apama.scenario.RequestInstancesDone;
using com.apama.scenario.RequestInstancesInternal;
using com.apama.scenario.Scenario;
using com.apama.scenario.ScenarioServiceUpdaterMultipleInstances;
using com.apama.scenario.ScenarioUnloaded;
using com.apama.scenario.StartScenarioRecovery;

// INTERNAL API CODE; not included in public API documentation

monitor DataViewService_Impl_Dict {

	/** Internal event used to store instances/items in a DataView. */
	event _Item {
		wildcard integer scenarioInstanceId;
		wildcard string owner;
		sequence<string> outputFields;
	}
	

	// MetaData relating to this specific implementation
	dictionary<string,string> implementationMetaData := {
		"implementation.package"       :"com.apama.dataview",
		"implementation.name"          :"DataViewService_Impl_Dict",
		"implementation.fileName"      :"DataViewService_Impl_Dict.mon",
		"implementation.vendor"        :"Apama",
		"implementation.version"       :"10.5.0.0.357639",
		"implementation.fullVersion"   :"rel/10.5.0.x@357639",
		"implementation.language"      :"MonitorScript"
	};

	
	// Variables needed in the parent monitor
	dictionary <string, string> dataViewNamesDictionary;  // scenarioId : dvName
	DataViewAddDefinition dvAddDefinition;

	// Variables required in the per-DataView spawned sub-monitor 
	string dvName;  // this is without the PREFIX (which is defined in the onload)
	string scenarioId; // this is with the PREFIX (which is defined in the onload)
	integer NUM_FIELDS;
	sequence<integer> compoundKeyIndexes; // the indexes of the fields which form the compound unique key of a _Item
	sequence<string> compoundKeyNames;    // the names of the fields which form the compound unique key of a _Item
	dictionary <string, integer> compoundKeyInstanceDictionary; // scenarioInstanceCompoundKey : scenarioInstanceId
	dictionary <integer, _Item> instancesDictionary; // scenarioInstanceId : _Item
	integer scenarioInstanceId := 0;
	
	// Defect 9762.  Space, semi-colon and tab in dvName must be escaped 
	dictionary<string, string> escapeCharMap := {" ":"_",		// space
	                                             ";":"$003b",	// semi-colon
	                                             "\t":"$0009"	// tab
	                                            };
	dictionary <string, string> escapedDvNamesDictionary; // unescaped dvname : escaped dvname
	dictionary <string, string> escapedScenarioIdDictionary; // unescaped scenarioId : escaped scenarioId

	ScenarioServiceUpdaterMultipleInstances updater;
	
	
	//===================================================================================
	
	/** A default no-arg constructor for an internal _Item. */
	action createDefaultItem() returns _Item {
		return _Item( -1, "", new sequence<string> );
	}

	/** action to take a string and escape all characters appeared in the escapeCharMap dictionary
	 *
	 * @param s - the string to be escaped
	 * 
	 * @return escaped string.  The original string is returned if there is nothing to be escaped
	**/
	action escapeDvName(string s) returns string {
		integer i;
		string retString := s;
		string unEscapeChar;
		for unEscapeChar in escapeCharMap.keys() {
			retString := _escapeIt(retString, unEscapeChar, escapeCharMap[unEscapeChar]);
		}
		
		return retString;
	}
	
	/** internal recursive method to escape the passed in string s.  s will be scanned for the the 
	    unEscapeChar and if found, replaced that with the escapeChar param.  This process will continue
	    until all characters in s is scanned.
	**/
	action _escapeIt( string s, string unEscapeChar, string escapeChar ) returns string {
		
		if (s.find(unEscapeChar) = -1) {
			return s;
		}
		
		integer index := s.find(unEscapeChar);

		string rest := s.substring(index+1, s.length());
		string retString := s.substring(0, index) + escapeChar + _escapeIt(rest, unEscapeChar, escapeChar);
		
		return retString;
	}
	
	action getEscapedDvName( string rawDvName ) returns string {
		string s;

		// given the raw dvName, return the cached value
		if (escapedDvNamesDictionary.hasKey(rawDvName)) {
			return escapedDvNamesDictionary[rawDvName];
		}
		
		// not found, just return original string
		return rawDvName;
	}
	
	action getUnescapedDvName( string escapedDvName ) returns string {
		
		string s;
		for s in escapedDvNamesDictionary.keys() {
			if (escapedDvNamesDictionary[s] = escapedDvName) {
				return s;
			}
		}
		
		// not found, just return original string
		return escapedDvName;
	}
	
	action getEscapedScenarioId( string rawScenarioId ) returns string {
		string s;

		// given the raw scenarioId, return the cached value
		if (escapedScenarioIdDictionary.hasKey(rawScenarioId)) {
			return escapedScenarioIdDictionary[rawScenarioId];
		}
		
		// not found, just return original string
		return rawScenarioId;
	}
	
	action getUnescapedScenarioId( string escapedScenarioId ) returns string {
		
		string s;
		for s in escapedScenarioIdDictionary.keys() {
			if (escapedScenarioIdDictionary[s] = escapedScenarioId) {
				return s;
			}
		}
		
		// not found, just return original string
		return escapedScenarioId;
	}
	
	action convertToScenarioId( string in_dvName ) returns string {
		string PREFIX := "DV_";
		string out_scenarioId;
		
		// for now just prepend the prefix, but in future do more checks and escaping of the name
		out_scenarioId:=PREFIX+in_dvName;
		
		return out_scenarioId;
	}
	
	
	action onload() {
		log "DataViewService implementation loaded. MetaData: "+implementationMetaData.toString() at INFO;
		
		log "onload() - entered." at DEBUG;

		// Look for the event to define a new DataView
		on all DataViewAddDefinition():dvAddDefinition {
			string escapedDvName := escapeDvName(dvAddDefinition.dvName);
			
			// name must not be ""
			if (dvAddDefinition.dvName.length()=0) {
				string msg := "Invalid name for new DataView - length must be greater than zero.";
				log "onload().on_all_DataViewAddDefinition() - "+msg at WARN;
				route DataViewException(dvAddDefinition.msgId, escapedDvName, msg, new dictionary<string,string> );
				return;
			}
			
			//name can not start with MEMST (clashes with memorystore plugin)
			string MEMORY_STORE_PREFIX := "MEMST_";
			if (dvAddDefinition.dvName.find(MEMORY_STORE_PREFIX)=0) {
				string msg := "Invalid name for new DataView - Must not start with " + MEMORY_STORE_PREFIX;
				log "onload().on_all_DataViewAddDefinition() - "+msg at WARN;
				route DataViewException(dvAddDefinition.msgId, dvAddDefinition.dvName, msg, new dictionary<string,string> );
				return;
			}
			
			
			// displayName must not be ""
			if (dvAddDefinition.dvDisplayName.length()=0) {
				string msg := "Invalid displayName for new DataView - length must be greater than zero.";
				log "onload().on_all_DataViewAddDefinition() - "+msg at WARN;
				route DataViewException(dvAddDefinition.msgId, escapedDvName, msg, new dictionary<string,string> );
				return;
			}
			
			// use the escaped dvName here.  Will save to the escapedDvNamesDictionary
			// when validation is passed

			// both dvName and scenarioId are escaped
			dvName:=escapedDvName;
			scenarioId:=convertToScenarioId(dvName);
			string rawScenarioId:=convertToScenarioId(dvAddDefinition.dvName);
			
			// Validate the params we were given...
			
			// Make sure this is not already present as a DataView or Scenario
			if dataViewNamesDictionary.hasKey(scenarioId) {
				string msg := "DataView name already exists";
				log "onload().on_all_DataViewAddDefinition() - \""+escapedDvName+"\" - "+msg at WARN;
				route DataViewException(dvAddDefinition.msgId, escapedDvName, msg, new dictionary<string,string>);
				return;
			}
			
				
			// Make sure we were given more than zero field names and types
			if (0=dvAddDefinition.fieldNames.size() or 0=dvAddDefinition.fieldTypes.size()) {
				string msg := "There must be 1 or more fields. DataViewAddDefinition event supplied "+dvAddDefinition.fieldNames.size().toString() +" names, and "+dvAddDefinition.fieldTypes.size().toString()+" types.";
				log "onload().on_all_DataViewAddDefinition() - \""+escapedDvName+"\" - "+msg at WARN;
				route DataViewException(dvAddDefinition.msgId, escapedDvName, msg, new dictionary<string,string>);
				return;
			}
			
			// Make sure we were not given any duplicate field names or emptystring field names
			dictionary<string,boolean> validNames := new dictionary<string,boolean>;
			string fName;
			for fName in dvAddDefinition.fieldNames {
				// check for name=""
				if (0=fName.length()) {
					string msg := "One of the supplied field names in a DataViewAddDefinition event is invalid. Field names must have a length greater than zero. The field names supplied were: "+dvAddDefinition.fieldNames.toString();
					log "onload().on_all_DataViewAddDefinition() - \""+escapedDvName+"\" - "+msg at WARN;
					route DataViewException(dvAddDefinition.msgId, escapedDvName, msg, new dictionary<string,string>);
					return;					
				}
				// check for duplicates
				if (validNames.hasKey(fName)) {
					string msg := "One of the supplied field names in a DataViewAddDefinition event is a duplicate. Duplicate field name: \""+fName+"\". The field names supplied were: "+dvAddDefinition.fieldNames.toString();
					log "onload().on_all_DataViewAddDefinition() - \""+escapedDvName+"\" - "+msg at WARN;
					route DataViewException(dvAddDefinition.msgId, escapedDvName, msg, new dictionary<string,string>);
					return;
				}
				validNames[fName] := true;
			}
			
			// Make sure we were given enough types for the field names
			if (dvAddDefinition.fieldNames.size() != dvAddDefinition.fieldTypes.size()) {
				string msg := "Each field name must have a corresponding type. DataViewAddDefinition event supplied "+dvAddDefinition.fieldNames.size().toString() +" names, and "+dvAddDefinition.fieldTypes.size().toString()+" types.";
				log "onload().on_all_DataViewAddDefinition() - \""+escapedDvName+"\" - "+msg at WARN;
				route DataViewException(dvAddDefinition.msgId, escapedDvName, msg, new dictionary<string,string>);
				return;
			}
			
			// Make sure the type strings we were given represent valid scenario variable types
			dictionary<string,boolean> validTypes := {"string":true, "float":true, "integer":true, "boolean":true, "enumeration":true, "decimal":true};
			integer i := 0;
			string t;
			for t in dvAddDefinition.fieldTypes {
				if not validTypes.hasKey(t) {
					string msg := "One of the supplied field types in a DataViewAddDefinition event is invalid. The type supplied at index "+i.toString()+" was: \""+t+"\"";
					log "onload().on_all_DataViewAddDefinition() - \""+escapedDvName+"\" - "+msg at WARN;
					route DataViewException(dvAddDefinition.msgId, escapedDvName, msg, new dictionary<string,string>);
					return;
				}
				i:=i+1;
			}

			compoundKeyIndexes := new sequence<integer>; // ensure it is ALWAYS reset
			compoundKeyNames := new sequence<string>; // ensure it is ALWAYS reset
			// if we've been given some optional key fields, then validate these
			if (dvAddDefinition.keyFields.size() > 0) {
				string k;
				for k in dvAddDefinition.keyFields {
					integer idx := dvAddDefinition.fieldNames.indexOf(k);
					if (-1 = idx) {
						string msg := "One of the supplied keyField field names in a DataViewAddDefinition event is invalid. The invalid keyField name supplied was: \""+k+"\". The keyField names supplied were: "+dvAddDefinition.keyFields.toString();
						log "onload().on_all_DataViewAddDefinition() - \""+escapedDvName+"\" - "+msg at WARN;
						route DataViewException(dvAddDefinition.msgId, escapedDvName, msg, new dictionary<string,string>);
						return;						
					}
					if (-1 < compoundKeyIndexes.indexOf(idx)) {
						string msg := "A duplicate keyField field name was given in a DataViewAddDefinition event. Duplicate keyField name: \""+k+"\". The keyField names supplied were: "+dvAddDefinition.keyFields.toString();
						log "onload().on_all_DataViewAddDefinition() - \""+escapedDvName+"\" - "+msg at WARN;
						route DataViewException(dvAddDefinition.msgId, escapedDvName, msg, new dictionary<string,string>);
						return;												
					}
					compoundKeyIndexes.append(idx); // since it is valid, add the index to the set.
				}
				compoundKeyNames := dvAddDefinition.keyFields;
			}

			// all fields are validated, save the escapedDvName and associate the scenarioId with the escapedName (dvName is escaped already)
			escapedDvNamesDictionary.add(dvAddDefinition.dvName, dvName);
			escapedScenarioIdDictionary.add(rawScenarioId, scenarioId);
			
			dataViewNamesDictionary.add(scenarioId, dvName);
			log "onload().on_all_DataViewAddDefinition() - \""+dvAddDefinition.dvName+"\" - adding new DataView definition with name: \""+dvAddDefinition.dvName+"\", and exposed externally with scenarioId: \""+scenarioId+"\"" at INFO;
			log "onload().on_all_DataViewAddDefinition() - \""+dvAddDefinition.dvName+"\" - spawning initializeScenario()..." at DEBUG;
			spawn initializeScenario();

		}

		// look for requests to unload definitions and tidy up our records.
		// The actual (spawned) DataView *also* looks for this event and kills itself
		on all DataViewDeleteDefinition() as dvDeleteDefinition {
			string rawScenarioId := convertToScenarioId(dvDeleteDefinition.dvName);
			string escapedScenarioId := getEscapedScenarioId(rawScenarioId);
			if dataViewNamesDictionary.hasKey(escapedScenarioId) {
				log "onload().on_all_DataViewDeleteDefinition() - \""+dvDeleteDefinition.dvName+"\" - removing DataView from dictionary with DataView name: \""+dvDeleteDefinition.dvName+"\", and exposed externally with scenarioId: \""+rawScenarioId+"\"" at INFO;
				dataViewNamesDictionary.remove(escapedScenarioId);
				escapedDvNamesDictionary.remove(dvDeleteDefinition.dvName);  // key is unescapedDvName
				escapedScenarioIdDictionary.remove(rawScenarioId);  // key is unescapedScenarioId
			}
		}

		
		// Look for external (i.e. com.apama.scenario API events) to remove
		// existing scenarios from our list to ensure we're up to date.
		on all ScenarioUnloaded() as scenScenarioUnloaded {
			// the following if statement should never now eval to true, as the entry in the dictionary 
			// should always have been previously deleted by the DataViewDeleteDefinition (see above). Done for completeness.
			if dataViewNamesDictionary.hasKey(scenScenarioUnloaded.scenarioId) {
				string dvName := dataViewNamesDictionary[scenScenarioUnloaded.scenarioId];
				log "onload().on_all_ScenarioUnloaded() - \""+scenScenarioUnloaded.scenarioId+"\" - removing DataView from dictionary with DataView name: \""+dvName+"\", and exposed externally with scenarioId: \""+scenScenarioUnloaded.scenarioId+"\"" at INFO;
				dataViewNamesDictionary.remove(scenScenarioUnloaded.scenarioId);
				escapedDvNamesDictionary.remove(getUnescapedDvName(dvName));  // key is unescapedDvName
				escapedScenarioIdDictionary.remove(getUnescapedScenarioId(scenScenarioUnloaded.scenarioId));  // key is unescapedScenarioId
			}			
		}

		
		// Look for DataViewItem* events for DataView names that do not exist and route exception events
		on all unmatched DataViewAddItem() as unmatchedAddItem {
			string msg := "Unknown DataView name in a DataViewAddItem event";
			log "unmatched DataViewAddItem() - "+msg at WARN;
			route DataViewException(unmatchedAddItem.msgId, escapeDvName(unmatchedAddItem.dvName), msg, new dictionary<string,string>);
		}
		on all unmatched DataViewAddOrUpdateItem() as unmatchedAddOrUpdateItem {
			string msg := "Unknown DataView name in a DataViewAddOrUpdateItem event";
			log "unmatched DataViewAddOrUpdateItem() - "+msg at WARN;
			route DataViewException(unmatchedAddOrUpdateItem.msgId, escapeDvName(unmatchedAddOrUpdateItem.dvName), msg, new dictionary<string,string>);
		}
		on all unmatched DataViewUpdateItem() as unmatchedUpdateItem {
			string msg := "Unknown DataView name in a DataViewUpdateItem event";
			log "unmatched DataViewUpdateItem() - "+msg at WARN;
			route DataViewItemException(unmatchedUpdateItem.msgId, escapeDvName(unmatchedUpdateItem.dvName), unmatchedUpdateItem.dvItemId, msg, new dictionary<string,string>);
		}
		on all unmatched DataViewUpdateItemDelta() as unmatchedUpdateItemDelta {
			string msg := "Unknown DataView name in a DataViewUpdateItemDelta event";
			log "unmatched DataViewUpdateItemDelta() - "+msg at WARN;
			route DataViewItemException(unmatchedUpdateItemDelta.msgId, escapeDvName(unmatchedUpdateItemDelta.dvName), unmatchedUpdateItemDelta.dvItemId, msg, new dictionary<string,string>);
		}
		on all unmatched DataViewDeleteItem() as unmatchedDeleteItem {
			string msg := "Unknown DataView name in a DataViewDeleteItem event";
			log "unmatched DataViewDeleteItem() - "+msg at WARN;
			route DataViewItemException(unmatchedDeleteItem.msgId, escapeDvName(unmatchedDeleteItem.dvName), unmatchedDeleteItem.dvItemId, msg, new dictionary<string,string>);
		}
		on all unmatched DataViewDeleteAllItems() as unmatchedDeleteAllItems {
			string msg := "Unknown DataView name in a DataViewDeleteAllItems event";
			log "unmatched DataViewDeleteAllItems() - "+msg at WARN;
			route DataViewException(unmatchedDeleteAllItems.msgId, escapeDvName(unmatchedDeleteAllItems.dvName), msg, new dictionary<string,string>);
		}
		on all unmatched DataViewGetFieldLookup() as unmatchedLookup {
			string msg := "Unknown DataView name in a DataViewGetFieldLookup event";
			log "unmatched DataViewGetFieldLookup() - "+msg at WARN;
			route DataViewException(unmatchedLookup.msgId, escapeDvName(unmatchedLookup.dvName), msg, new dictionary<string,string>);
		}
		
		log "onload() - complete." at DEBUG;
	}


	//===================================================================================

	
	// This defines the behaviour for each DataView bridge scenario type
	action initializeScenario() {
		log "initializeScenario() - \""+dvName+"\" - entered (spawned with this action)." at DEBUG;
		updater.init(scenarioId, context.current());

		string SCENARIO_SERVICE_CHANNEL := "com.apama.scenario";
		Scenario scenario := new Scenario; // store the schema of the DataView

		// Build up the scenario definition event
		scenario.scenarioId := scenarioId;
		scenario.displayName := dvAddDefinition.dvDisplayName;
		scenario.description := dvAddDefinition.dvDescription;
		scenario.inputNames := [];
		scenario.inputTypes := [];
		scenario.inputConstraints := [];
		scenario.inputDefaults := [];
		scenario.outputNames := dvAddDefinition.fieldNames;
		scenario.outputTypes := dvAddDefinition.fieldTypes;
		scenario.executionMode := 0;
		scenario.extraParams := dvAddDefinition.extraParams;
		scenario.extraParams.add("isReadOnly", "true");
		scenario.extraParams.add("type", "dataview");
		NUM_FIELDS := scenario.outputTypes.size();
	
		// If we have dont have enough constraints then set default constraints for ALL inputs (ignore any we were given)
		// - no - don't need to do that - always ZERO INPUTS
		
		// If we have dont have enough default initial inputs set basic defaults for ALL inputs (ignore any we were given)
		// - no - don't need to do that - always ZERO INPUTS

		
		// Notify any client listeners when scenario loads
		route scenario;
		send scenario to SCENARIO_SERVICE_CHANNEL;
		route DataViewDefinition(dvAddDefinition.msgId, dvName, dvAddDefinition.dvDisplayName, dvAddDefinition.dvDescription, dvAddDefinition.fieldNames, dvAddDefinition.fieldTypes, dvAddDefinition.keyFields, new dictionary<string,string>);

		// Build the helper dictionaries
		initialiseFieldLookup(scenario, dvName);
		
		// Look for the request to delete this bridge type
		on DataViewDeleteDefinition(dvName = getUnescapedDvName(dvName)) as delDef {
			//Remove this bridge type
			// the "on unload" listener will generate the response.
			log "initializeScenario().on_DataViewDeleteDefinition() - \""+dvName+"\" - routing DataViewDefinitionDeleted/ScenarioUnloaded events..." at INFO;
			route DataViewDefinitionDeleted(delDef.msgId, dvName, new dictionary<string,string>);
			route ScenarioUnloaded(scenarioId);
			log "initializeScenario().on_DataViewDeleteDefinition() - \""+dvName+"\" - Killing the mthread for this DataView." at INFO;
			die;
		}

		// RequestInstances handling (dumps current state of all instances by sending Instance events)
		on all RequestInstancesInternal(scenarioId = scenarioId) as scenRequestInstances {
			log "initializeScenario().on_all_RequestInstances() - \""+scenarioId+"\" - received request for instances. Initiating recovery on for request messageId: "+scenRequestInstances.messageId.toString() at DEBUG;
			
			integer k;
			_Item item;
			for k in instancesDictionary.keys() {
				item := instancesDictionary[k];

				log "dvItemMThread().on_all_RequestInstances() - \""+scenarioId+":"+k.toString()+"\" - routing an Instance event for this DataView Item..." at DEBUG;

				if(scenRequestInstances.ownerFilter = false or 
				   scenRequestInstances.owner = item.owner or 
				   item.owner = "*") {
					updater.emitInstance(scenRequestInstances, item.scenarioInstanceId, item.owner, "RUNNING", new sequence<string>, item.outputFields);
				}
			}
			route RequestInstancesDone(scenarioId, scenRequestInstances.messageId);
		}
		
		// Look for the scenario recovery event and send out the definition of this Scenario/DataView. (remember we have spawned per Scenario)
		on all StartScenarioRecovery() {
			route scenario;
		}

		
		
		
		// ========= Listeners for Create/Delete/Edit/Update ==================
		
		
		// ####################################################################
		// ####################################################################	
		// CREATE
		// First if an instance is created via the scenario API (e.g. a dashboard)...
		on all Create(scenarioId = scenarioId) as scenCreate {
			log "initializeScenario().on_all_Create() - \""+scenarioId+"\" - Scenario instance create ignored - DataViewService does not handle incoming CREATE events from the ScenarioService." at WARN;
			emitNack(scenCreate.messageId, -1);
			return;
		}
		// ... secondly if it is created from the MonitorScript side of things
		on all DataViewAddItem(dvName = getUnescapedDvName(dvName)) as dvAddItem {
			log "initializeScenario().on_all_DataViewAddItem() - \""+dvName+"\" - " at DEBUG;
			addDataViewItem(dvAddItem);
		}
		
		
		// #########################################################
		// #########################################################
		// DELETE
		// From Scenario API - Ignore/Nack
		on all Delete(scenarioId=scenarioId) as scenDelete {
			log "initializeScenario().on_all_Delete() - \""+scenarioId+":"+scenDelete.scenarioInstanceId.toString()+"\" - Scenario instance delete ignored - DataViewService does not handle incoming DELETE events from the ScenarioService." at WARN;
			emitNack(scenDelete.messageId, scenDelete.scenarioInstanceId);
			return;
		}
		// From DataViewService API
		on all DataViewDeleteItem(dvName=getUnescapedDvName(dvName)) as dvDeleteItem {
			log "initializeScenario().on_all_DataViewDeleteItem() - \""+dvName+":"+dvDeleteItem.dvItemId.toString()+"\" - " at DEBUG;
			deleteDataViewItem(dvDeleteItem);
		}
		// From DataViewService API
		on all DataViewDeleteAllItems(dvName=getUnescapedDvName(dvName)) as dvDeleteAllItems {
			log "initializeScenario().on_all_DataViewDeleteAllItems() - \""+dvName+"\" - " at DEBUG;
			deleteAllDataViewItems(dvDeleteAllItems);
		}
		
		
		// #########################################################
		// #########################################################
		// EDIT
		// From Scenario API - Ignore/Nack
		on all Edit(scenarioId = scenarioId) as scenEdit {
			log "initializeScenario().on_all_Edit() - \""+scenarioId+":"+scenEdit.scenarioInstanceId.toString()+"\" - Scenario instance edit ignored - DataViewService does not handle incoming EDIT events from the ScenarioService." at WARN;
			emitNack(scenEdit.messageId, scenEdit.scenarioInstanceId);
			return;
		}

		
		// #########################################################
		// #########################################################
		// ADD OR UPDATE (full)
		// Forward the AddOrUpdates from the Monitor via this DataViewService to the Scenario API
		on all DataViewAddOrUpdateItem(dvName = getUnescapedDvName(dvName)) as dvAddOrUpdateItem {
			addOrUpdateDataViewItem(dvAddOrUpdateItem);
		}

		// #########################################################
		// #########################################################
		// UPDATE (full)
		// Forward the Updates from the Monitor via this DataViewService to the Scenario API
		on all DataViewUpdateItem(dvName = getUnescapedDvName(dvName)) as dvUpdateItem {
			updateFullDataViewItem(dvUpdateItem);
		}

		// #########################################################
		// #########################################################
		// UPDATE (delta) - an update containing only deltas
		// Forward the Updates from the Monitor via this DataViewService to the Scenario API
		on all DataViewUpdateItemDelta(dvName = getUnescapedDvName(dvName)) as dvUpdateItemDelta {
			updateDeltaDataViewItem(dvUpdateItemDelta);
		}
		
		// ####################################################################
		// ####################################################################
		log "initializeScenario() - \""+dvName+"\" - complete." at DEBUG;
	}
	
	
	//===================================================================================

	
	// Management Actions

	/** Build the fieldname-index lookup dictionary, and add a the DataViewGetFieldLookup listener. */
	action initialiseFieldLookup(Scenario theScenario, string dataViewName) {
		log "initialiseFieldLookup() - building the dictionary, and adding a the DataViewGetFieldLookup listener" at DEBUG;
		string s;
		integer count := 0;
		dictionary <string, integer> fieldLookupDictionary := new dictionary<string, integer>; // fieldName : index in sequence
		for s in theScenario.outputNames {
			fieldLookupDictionary.add(s, count);
			count := count + 1;
		}		


		// Look for requests for the helper lookup dictionaries and reply
		on all DataViewGetFieldLookup(dvName = getUnescapedDvName(dataViewName)) as lookupReq {
			log "initialiseFieldLookup().on_all_DataViewGetFieldLookup() - \""+dataViewName+"\" - routing DataViewFieldLookup event..." at DEBUG;
			route DataViewFieldLookup(lookupReq.msgId, dataViewName, fieldLookupDictionary, new dictionary<string,string>);
		}		
	}
	

	action generateInstanceDied(_Item item) {
		// this should only ever be called once, from deleteDataViewItem() or deleteAllDataViewItems(), so we no longer need a flag to says its been called.
		log "generateInstanceDied() - \""+scenarioId+":"+item.scenarioInstanceId.toString()+"\" - routing Died events." at DEBUG;
		updater.emitInstanceDied(item.scenarioInstanceId, item.owner);
	}
	
	
	//===================================================================================

	
	// Management Actions
	action onunload() {
		route DataViewServiceUnloaded( new dictionary<string,string> );
		log "DataViewService implementation unloaded." at INFO;
	}
	
	
	//===================================================================================

	/* Build the compound key from a COMPLETE sequence of values (i.e. not just the keyFields).
	 * The key will ALWAYS be > "".  "" indicates an error.
	 * For a single-field (non-compound) key, whose value is "", just return the prefix.
	*/
	action buildCompoundKeyFromSeq(sequence<string> fieldValues) returns string {
		string key := "#";
		integer keyIndex;
		integer i:=0;
		if not (fieldValues.size() = NUM_FIELDS) {
			log "buildCompoundKeyfromSeq() - the given sequence of fields is the wrong size. Required: "+NUM_FIELDS.toString()+", Found: "+fieldValues.size().toString() at WARN;
			return "";
		}
		for keyIndex in compoundKeyIndexes {
			if (fieldValues.size() <= keyIndex) {
				log "buildCompoundKeyfromSeq() - the given sequence of fields does not contain a required keyField: "+compoundKeyNames[i]+", index: "+keyIndex.toString() at WARN;
				return "";
			}
			key := key + fieldValues[keyIndex]; 
			i:=i+1;
			if (compoundKeyIndexes.size() > i) {
				key := key +":";
			}
		}
		return key;
	}

	/* Build the compound key from a sequence of keyField values ONLY (i.e. just the keyFields).
	 * The key will ALWAYS be > "".  "" indicates an error.
	 * For a single-field (non-compound) key, whose value is "", just return the prefix.
	*/
	action buildCompoundKeyFromKeySeq(sequence<string> keyFieldValues) returns string {
		string key := "#";
		string keyValue;
		integer i:=0;
		if not (keyFieldValues.size() = compoundKeyIndexes.size()) {
			log "buildCompoundKeyfromKeySeq() - the given sequence of keyFields is the wrong size. Required: "+compoundKeyIndexes.size().toString()+", Found: "+keyFieldValues.size().toString() at WARN;
			return "";
		}
		for keyValue in keyFieldValues {
			key := key + keyValue; 
			i:=i+1;
			if (compoundKeyIndexes.size() > i) {
				key := key +":";
			}
		}
		return key;
	}

	/* Build the compound key from a dictionary of fieldNAME<->fieldvalue. 
	 * The dictionary does not need to contain a complete set of fields, but must contain at least the keyFields.
	 * The key will ALWAYS be > "".  "" indicates an error.
	 * For a single-field (non-compound) key, whose value is "", just return the prefix.
	*/
	action buildCompoundKeyFromDict(dictionary<string,string> fields) returns string {
		string key := "#"; // all keys will have this prefix
		string keyName;
		integer i:=0;
		for keyName in compoundKeyNames {
			if not (fields.hasKey(keyName)) {
				log "buildCompoundKeyfromDict() - the given dictionary does not contain a required keyField: "+keyName at WARN;
				return "";
			}
			key := key + fields[keyName];
			i:=i+1;
			if (compoundKeyIndexes.size() > i) {
				key := key +":";
			}
		}
		return key;
	}

	/* Build the compound key from a dictionary of fieldINDEX<->fieldvalue. 
	 * The dictionary does not need to contain a complete set of fields, but must contain at least the keyFields.
	 * The key will ALWAYS be > "".  "" indicates an error.
	 * For a single-field (non-compound) key, whose value is "", just return the prefix.
	*/
	action buildCompoundKeyFromIndexDict(dictionary<integer,string> fields) returns string {
		string key := "#"; // all keys will have this prefix
		integer keyIndex;
		integer i:=0;
		for keyIndex in compoundKeyIndexes {
			if not (fields.hasKey(keyIndex)) {
				log "buildCompoundKeyfromIndexDict() - the given dictionary does not contain a required keyField: "+compoundKeyNames[i]+", index: "+keyIndex.toString() at WARN;
				return "";
			}
			key := key + fields[keyIndex];
			i:=i+1;
			if (compoundKeyIndexes.size() > i) {
				key := key +":";
			}
		}
		return key;
	}
	
	
	/** Add a new DataViewItem to the current (spawned) DataView.
	 * This action is called as a result of matching a DataViewAddItem.
	 * 
	 * @exception Routes a DataViewException event if the new Item cannot be added.
	 */
	action addDataViewItem(DataViewAddItem dvAddItem) {
		log "addDataViewItem() - \""+dvName+"\" - entered." at DEBUG;
		
		if (dvAddItem.fieldValues.size() != NUM_FIELDS) {
			string msg := "DataView addItem ignored - " + NUM_FIELDS.toString() + " output field(s) required but " + dvAddItem.fieldValues.size().toString() + " provided.";
			
			// dvName is escaped already
			log "addDataViewItem() - \""+dvName+"\" - " + msg at WARN;
			route DataViewException(dvAddItem.msgId, dvName, msg, new dictionary<string,string>);
			return;
		}

		_Item newItem := createDefaultItem();
		newItem.owner := dvAddItem.owner;
		newItem.outputFields := dvAddItem.fieldValues;
		
		// are we using the automatic compound key feature? If so we must generate the key and store it in a dictionary
		if (compoundKeyIndexes.size()>0) {
			// build the key
			string compoundKey := buildCompoundKeyFromSeq(newItem.outputFields);
			
			// dvName is escaped already
			log "addDataViewItem() - \""+dvName+"\" - compoundKey is: "+compoundKey at DEBUG;
			
			// do we already have an item with that key?
			if (compoundKeyInstanceDictionary.hasKey(compoundKey)) {
				// reject the new item - duplicate key
				string msg := "DataView addItem ignored - the DataView uses the keyFields feature and the new item clashes with an existing item.  The supplied values were: "+dvAddItem.fieldValues.toString();
				log "addDataViewItem() - \""+dvName+"\" - " + msg at WARN;
				route DataViewException(dvAddItem.msgId, dvName, msg, new dictionary<string,string>);
				return;
			}
			
			// add the new key to the dictionary to map it to the scenarioInstanceId(=dvItemId)
			compoundKeyInstanceDictionary.add(compoundKey, scenarioInstanceId);
		}
		
		//copy then increment the main instanceId counter
		newItem.scenarioInstanceId := scenarioInstanceId;
		scenarioInstanceId := scenarioInstanceId + 1;

		// store the newly created Item
		log "addDataViewItem() - \""+dvName+":"+newItem.scenarioInstanceId.toString()+"\" - storing Item..." at INFO;
		instancesDictionary.add(newItem.scenarioInstanceId, newItem);
	
		// Send Created/Added events to both the Scenario and DataViewService APIs
		// This ensures that the Application MonitorScript and the Components such as Dashboards see the new instance
		log "addDataViewItem() - \""+dvName+":"+newItem.scenarioInstanceId.toString()+"\" - routing Created/Added events..." at DEBUG;
		updater.emitCreated(-1, newItem.scenarioInstanceId, newItem.owner, "RUNNING", new sequence<string>, newItem.outputFields);
		
		log "addDataViewItem() - \""+dvName+":"+newItem.scenarioInstanceId.toString()+"\" - routing initial Update event for this Item..." at DEBUG;
		float timeStamp := dvAddItem.timeStamp;
		if (-1.0=timeStamp) {
			timeStamp:=currentTime;
		}
		updater.emitUpdate_time(newItem.scenarioInstanceId, timeStamp, newItem.outputFields, newItem.owner);
		
		route DataViewItem(dvAddItem.msgId, dvName, newItem.scenarioInstanceId, newItem.owner, newItem.outputFields, new dictionary<string,string>);

		log "addDataViewItem() - \""+dvName+":"+newItem.scenarioInstanceId.toString()+"\" - complete." at DEBUG;
	}
	
	
	/* Add a new DataViewItem to the current (spawned) DataView if it does not already exist, 
	 * or update it when it does exist. This will ONLY work when keyFields are used.
	 * Attempts to change the owner of an existing item will be rejected with a DataViewItemException.
	 *
	 * This action is called as a result of matching a DataViewAddOrUpdateItem.
	 * 
	 * @exception Routes a DataViewException event if the new Item cannot be added.
	 * @exception Routes a DataViewItemException event if the new Item attempts to change the owner of an existing item.
	 */
	action addOrUpdateDataViewItem(DataViewAddOrUpdateItem dvAddOrUpdateItem) {
		log "addOrUpdateDataViewItem() - \""+dvName+"\" - entered." at DEBUG;
		
		if (0=compoundKeyIndexes.size()) { 
			// this DataView does not use keyFields - error - The DataViewAddOrUpdateItem event is only valid for DataViews which use keyFields
			string msg := "DataViewAddOrUpdateItem event is only valid for DataViews which use keyFields";
			log "addOrUpdateDataViewItem() - \""+dvName+"\" - routing DataViewException event - "+msg at WARN;
			route DataViewException(dvAddOrUpdateItem.msgId, dvName, msg, new dictionary<string,string>);
			return;
		}

		if (dvAddOrUpdateItem.fieldValues.size() != NUM_FIELDS) {
			string msg := "DataView addOrUpdateItem ignored - " + NUM_FIELDS.toString() + " output field(s) required but " + dvAddOrUpdateItem.fieldValues.size().toString() + " provided.";
			log "addOrUpdateDataViewItem() - \""+dvName+"\" - " + msg at WARN;
			route DataViewException(dvAddOrUpdateItem.msgId, dvName, msg, new dictionary<string,string>);
			return;
		}

		_Item newItem := createDefaultItem();
		newItem.owner := dvAddOrUpdateItem.owner;
		newItem.outputFields := dvAddOrUpdateItem.fieldValues;
		
		// build the key
	
		string compoundKey := buildCompoundKeyFromSeq(newItem.outputFields);
		log "addOrUpdateDataViewItem() - \""+dvName+"\" - compoundKey is: "+compoundKey at DEBUG;
		
		// do we already have an item with that key?
		boolean alreadyExists := compoundKeyInstanceDictionary.hasKey(compoundKey);
		if (alreadyExists) {
			// Yes we found the key - so we're going to get the existing item and update it (after a couple of checks)
			integer itemId := compoundKeyInstanceDictionary[compoundKey];
			newItem.scenarioInstanceId := itemId; // copy the ID for use when we send out the update
			log "addOrUpdateDataViewItem() - \""+dvName+":"+itemId.toString()+"\" - found dvItemId for keyFields" at DEBUG;
			
			// Get the existing item
			_Item item := instancesDictionary[itemId];
			
			// Check the owner is not changed
			if (item.owner != newItem.owner) {
				// reject the new item - attempted to change OWNER
				string msg := "DataView addOrUpdateItem ignored - detected attempt to change the owner of an existing item.  Current owner: \""+item.owner+"\", attempted owner: \""+newItem.owner+"\"";
				log "addOrUpdateDataViewItem() - \""+dvName+":"+itemId.toString()+"\" - " + msg at WARN;
				route DataViewItemException(dvAddOrUpdateItem.msgId, dvName, itemId, msg, new dictionary<string,string>);
				return;
			}
			
			// Now we can make the change to the actual stored values
			item.outputFields := newItem.outputFields;
		}
		else {
			// No didn't find the key, so it must be new - add the new key to the dictionary to map it to the scenarioInstanceId(=dvItemId)
			compoundKeyInstanceDictionary.add(compoundKey, scenarioInstanceId);
			
			//copy then increment the main instanceId counter
			newItem.scenarioInstanceId := scenarioInstanceId;
			scenarioInstanceId := scenarioInstanceId + 1;

			// store the newly created Item
			log "addOrUpdateDataViewItem() - \""+dvName+":"+newItem.scenarioInstanceId.toString()+"\" - storing Item..." at INFO;
			instancesDictionary.add(newItem.scenarioInstanceId, newItem);
		
			// Send Created/Added events to both the Scenario and DataViewService APIs
			// This ensures that the Application MonitorScript and the Components such as Dashboards see the new instance
			log "addOrUpdateDataViewItem() - \""+dvName+":"+newItem.scenarioInstanceId.toString()+"\" - routing Created/Added events..." at DEBUG;
			updater.emitCreated(-1, newItem.scenarioInstanceId, newItem.owner, "RUNNING", new sequence<string>, newItem.outputFields);
		}

		// In either case (add or update), we now need to route the Update event
		log "addOrUpdateDataViewItem() - \""+dvName+":"+newItem.scenarioInstanceId.toString()+"\" - routing an Update event with the following field values:"+newItem.outputFields.toString() at DEBUG;
		float timeStamp := dvAddOrUpdateItem.timeStamp;
		if (-1.0=timeStamp) {
			timeStamp:=currentTime;
		}
		updater.emitUpdate_time(newItem.scenarioInstanceId, timeStamp, newItem.outputFields, newItem.owner);
		
		if (not alreadyExists) {
		
			route DataViewItem(dvAddOrUpdateItem.msgId, dvName, newItem.scenarioInstanceId, newItem.owner, newItem.outputFields, new dictionary<string,string>);
		}

		// All done
		log "addOrUpdateDataViewItem() - \""+dvName+":"+newItem.scenarioInstanceId.toString()+"\" - complete." at DEBUG;
	}


	/** Delete an existing DataViewItem from the current (spawned) DataView.
	 * This action is called as a result of matching a DataViewDeleteItem.
	 * 
	 * @exception Routes a DataViewItemException event if the Item cannot be deleted (not found, etc).
	 */
	action deleteDataViewItem(DataViewDeleteItem dvDeleteItem) {
		integer itemId := dvDeleteItem.dvItemId;
		string compoundKey := buildCompoundKeyFromKeySeq(dvDeleteItem.keyFields);// build the key
		
		if (0<=itemId) { // an itemId was supplied
			if (not instancesDictionary.hasKey(itemId)) {
				string msg := "Unknown dvItemId: "+itemId.toString();
				log "deleteDataViewItem() - \""+dvName+":"+itemId.toString()+"\" - routing DataViewItemException event - "+msg at WARN;
				route DataViewItemException(dvDeleteItem.msgId, dvName, itemId, msg, new dictionary<string,string>);
				return;
			}
		}
		else { // no itemId supplied
			if (0=compoundKeyIndexes.size()) { 
				// this DataView does not use keyFields - error - must supply a dvItemId
				string msg := "A valid dvItemId must be supplied (this DataView does not use keyFields)";
				log "deleteDataViewItem() - \""+dvName+"\" - routing DataViewItemException event - "+msg at WARN;
				route DataViewItemException(dvDeleteItem.msgId, dvName, itemId, msg, new dictionary<string,string>);
				return;				
			}
			if (dvDeleteItem.keyFields.size() != compoundKeyIndexes.size()) {
				// invalid number of keys supplied
				string msg := "Incorrect number of key fields supplied. Found "+dvDeleteItem.keyFields.size().toString()+", require "+compoundKeyIndexes.size().toString();
				log "deleteDataViewItem() - \""+dvName+"\" - routing DataViewItemException event - "+msg at WARN;
				route DataViewItemException(dvDeleteItem.msgId, dvName, itemId, msg, new dictionary<string,string>);
				return;				
			}
			
			if (0=compoundKey.length()) {
				// we get an error back from buildCompoundKey - most likely the key fields were not supplied
				string msg := "Invalid set of key fields supplied: "+dvDeleteItem.keyFields.toString();
				log "deleteDataViewItem() - \""+dvName+"\" - routing DataViewItemException event - "+msg at WARN;
				route DataViewItemException(dvDeleteItem.msgId, dvName, itemId, msg, new dictionary<string,string>);
				return;								
			}
			
			
			// all valid - get the itemId from the dictionary
			if (not compoundKeyInstanceDictionary.hasKey(compoundKey)) {
				// we built a valid key, but no dvItem is currently known with that key
				string msg := "No DataViewItem could be found for the keyFields supplied: "+dvDeleteItem.keyFields.toString();
				log "deleteDataViewItem() - \""+dvName+"\" - routing DataViewItemException event - "+msg at WARN;
				route DataViewItemException(dvDeleteItem.msgId, dvName, itemId, msg, new dictionary<string,string>);
				return;
			}
		}
		// Clear the dictionary for the keyFields 
		if (compoundKeyIndexes.size()>0) {
			if (compoundKeyInstanceDictionary.hasKey(compoundKey)) {
				itemId := compoundKeyInstanceDictionary[compoundKey];
				log "deleteDataViewItem() - \""+dvName+":"+itemId.toString()+"\" - found dvItemId for keyFields" at DEBUG;
				// remove that compound key
				compoundKeyInstanceDictionary.remove(compoundKey);
			}
		}
		
		if (instancesDictionary.size()>0){
			_Item item := instancesDictionary[itemId];

			// Tell everyone about Deletion
			generateInstanceDied(item);
			log "deleteDataViewItem() - \""+dvName+":"+itemId.toString()+"\" - routing Deleted events..." at DEBUG;
			updater.emitDeleted(-1, itemId, item.owner);
			if (dvDeleteItem.keyFields.size() != compoundKeyIndexes.size()) {
				// deleted using dvItemId, but this DataView is using keyFields, so we need to build the key to pass out in the Deleted event
				integer i := 0;
				while i < compoundKeyIndexes.size() {
					dvDeleteItem.keyFields.append( item.outputFields[compoundKeyIndexes[i]] );
					i := i + 1;
				}
				// Rebuild and remove that compound key when deleted using only dvItemId
				if (dvDeleteItem.keyFields.size()>0){
					compoundKey := buildCompoundKeyFromKeySeq(dvDeleteItem.keyFields);
					log "compound key after rebuild whne deleted using only dvItemId" + compoundKey at DEBUG;
					compoundKeyInstanceDictionary.remove(compoundKey);
				}
			}
			log "dvDeleteItem.keyFields" +dvDeleteItem.keyFields.toString() at DEBUG;
			route DataViewItemDeleted(dvDeleteItem.msgId, dvName, itemId, dvDeleteItem.keyFields, new dictionary<string,string>);
			log "deleteDataViewItem() - \""+dvName+":"+itemId.toString()+"\" - removing Item..." at INFO;
			instancesDictionary.remove(itemId);
			log "compoundKeyInstanceDictionary content: " + compoundKeyInstanceDictionary.toString()  at DEBUG;
			log "deleteDataViewItem() - instancesDictionary content after removal: "+instancesDictionary.toString() at DEBUG;
		}
		
	}


	
	/** Delete all existing DataViewItems from the current (spawned) DataView.
	 * This action is called as a result of matching a DataViewDeleteAllItems.
	 * 
	 * @exception Routes a DataViewItemException event if the Item cannot be deleted (not found, etc).
	 */
	action deleteAllDataViewItems(DataViewDeleteAllItems dvDeleteAllItems) {
		
		// Iterate all the items an delete each one
		integer itemId;
		_Item item;
		for itemId in instancesDictionary.keys() {
			item := instancesDictionary[itemId];
			// Tell everyone about Deletion
			generateInstanceDied(item);
			log "deleteAllDataViewItems() - \""+dvName+":"+itemId.toString()+"\" - routing Deleted events..." at DEBUG;
			updater.emitDeleted(-1, itemId, item.owner);
		}
		
		// Clear the dictionaries
		log "deleteAllDataViewItems() - \""+dvName+"\" - removing ALL Items..." at INFO;
		compoundKeyInstanceDictionary.clear();
		instancesDictionary.clear();

		route DataViewAllItemsDeleted(dvDeleteAllItems.msgId, dvName, new dictionary<string,string>);
		
		log "deleteAllDataViewItems() - instancesDictionary content after removal: "+instancesDictionary.toString() at DEBUG;
		log "deleteAllDataViewItems() - compoundKeyInstanceDictionary content after removal: "+compoundKeyInstanceDictionary.toString() at DEBUG;

	}


	/** Update ALL the field values of an existing DataViewItem in the current (spawned) DataView.
	 * This action is called as a result of matching a DataViewUpdateItem.
	 * 
	 * @exception Routes a DataViewItemException event if the Item cannot be updated (not found, keyField clash, etc).
	 */
	action updateFullDataViewItem(DataViewUpdateItem dvupdate) {
		integer itemId := dvupdate.dvItemId;
		
		// first check the number of fields (this is required before some of the other checks)
		if (dvupdate.fieldValues.size()!= NUM_FIELDS) {
			string msg := "DataView updateItem ignored - " + NUM_FIELDS.toString() + " output field(s) required but " + dvupdate.fieldValues.size().toString() + " provided.";
			log "updateFullDataViewItem() - \""+dvName+":"+itemId.toString()+"\" - " + msg at WARN;
			route DataViewItemException(dvupdate.msgId, dvName, itemId, msg, new dictionary<string,string>);
			return;
		}

		string compoundKey := "";
		if (0>itemId) { // no itemId supplied
			if (0=compoundKeyIndexes.size()) { 
				// this DataView does not use keyFields - error - must supply a dvItemId
				string msg := "A valid dvItemId must be supplied (this DataView does not use keyFields)";
				log "updateFullDataViewItem() - \""+dvName+"\" - routing DataViewItemException event - "+msg at WARN;
				route DataViewItemException(dvupdate.msgId, dvName, itemId, msg, new dictionary<string,string>);
				return;				
			}
			// build the key
			compoundKey := buildCompoundKeyFromSeq(dvupdate.fieldValues);
			log "updateFullDataViewItem() - \""+dvName+"\" - compoundKey: "+compoundKey at DEBUG;
			if (0=compoundKey.length()) {
				// we get an error back from buildCompoundKey - most likely the key fields were not supplied?
				string msg := "Unable to construct compound key from field values: "+dvupdate.fieldValues.toString();
				log "updateFullDataViewItem() - \""+dvName+"\" - routing DataViewItemException event - "+msg at WARN;
				route DataViewItemException(dvupdate.msgId, dvName, itemId, msg, new dictionary<string,string>);
				return;								
			}
			
			// all valid - get the itemId from the dictionary
			if (not compoundKeyInstanceDictionary.hasKey(compoundKey)) {
				// we built a valid key, but no dvItem is currently known with that key
				string msg := "No DataViewItem could be found using the keyFields from the field values supplied: "+dvupdate.fieldValues.toString();
				log "updateFullDataViewItem() - \""+dvName+"\" - routing DataViewItemException event - "+msg at WARN;
				route DataViewItemException(dvupdate.msgId, dvName, itemId, msg, new dictionary<string,string>);
				return;
			}
			itemId := compoundKeyInstanceDictionary[compoundKey];
			log "updateFullDataViewItem() - \""+dvName+":"+itemId.toString()+"\" - found dvItemId for keyFields" at DEBUG;
		}
		
		// check if we have an Item with the (supplied or calculated) itemId
		if (not instancesDictionary.hasKey(itemId)) {
			string msg := "Unknown dvItemId: "+itemId.toString();
			log "updateFullDataViewItem() - \""+dvName+":"+itemId.toString()+"\" - routing DataViewItemException event - "+msg at WARN;
			route DataViewItemException(dvupdate.msgId, dvName, itemId, msg, new dictionary<string,string>);
			return;
		}
				
		_Item item := instancesDictionary[itemId];
		
		// IMPORTANT
		// check we have not altered a keyField value if this DataView is configured for their use!!
		if (0<compoundKeyIndexes.size()) {
			string existingCompoundKey := buildCompoundKeyFromSeq(item.outputFields);
			if (0=compoundKey.length()) {
				compoundKey := buildCompoundKeyFromSeq(dvupdate.fieldValues);
			}
			if not (compoundKey=existingCompoundKey) {
				string msg := "DataView updateItem ignored - It is not permitted to change the value of a keyField. The supplied values were: "+dvupdate.fieldValues.toString();
				log "updateFullDataViewItem() - \""+dvName+":"+itemId.toString()+"\" - routing DataViewItemException event - "+msg at WARN;
				route DataViewItemException(dvupdate.msgId, dvName, itemId, msg, new dictionary<string,string>);

				log "updateFullDataViewItem() - \""+dvName+":"+itemId.toString()+"\" - existing compoundKey: \""+existingCompoundKey+"\", new compoundKey: \""+compoundKey+"\"" at DEBUG;
				
				return;				
			}
		}

		// Now we can make the change to the actual stored values
		integer i:=0;
		while(i<NUM_FIELDS) {
			item.outputFields[i] := dvupdate.fieldValues[i].clone();
			i:=i+1;
		}

		log "updateFullDataViewItem() - \""+dvName+":"+itemId.toString()+"\" - routing an Update event with the following field values:"+item.outputFields.toString() at DEBUG;
		float timeStamp := dvupdate.timeStamp;
		if (-1.0=timeStamp) {
			timeStamp:=currentTime;
		}
		updater.emitUpdate_time(item.scenarioInstanceId, timeStamp, item.outputFields, item.owner);
	}
	
	
	/** Update a SUBSET of the field values of an existing DataViewItem in the current (spawned) DataView.
	 * This action is called as a result of matching a DataViewUpdateItemDelta.
	 * 
	 * @exception Routes a DataViewItemException event if the Item cannot be updated (not found, keyField clash, etc).
	 */
	action updateDeltaDataViewItem(DataViewUpdateItemDelta dvdelta) {

		integer numberOfUpdatedFields := dvdelta.fieldValues.size() - compoundKeyIndexes.size();
		if (numberOfUpdatedFields=0) or (dvdelta.fieldValues.size()=0) {
			// empty delta
			log "updateDeltaDataViewItem() - \""+dvName+":"+dvdelta.dvItemId.toString()+"\" - empty delta - ignored. Delta field values: "+dvdelta.fieldValues.toString() at DEBUG;
			//route DataViewItemException(dvName, dvdelta.dvItemId, "Empty delta - ignored. Delta field values: "+dvdelta.fieldValues.toString(), new dictionary<string,string>);
			return;
		}
		
		integer itemId := dvdelta.dvItemId;
		string compoundKey := "";
		
		if (0>itemId) { // no itemId supplied
			if (0=compoundKeyIndexes.size()) { 
				// this DataView does not use keyFields - error - must supply a dvItemId
				string msg := "A valid dvItemId must be supplied (this DataView does not use keyFields)";
				log "updateDeltaDataViewItem() - \""+dvName+"\" - routing DataViewItemException event - "+msg at WARN;
				route DataViewItemException(dvdelta.msgId, dvName, itemId, msg, new dictionary<string,string>);
				return;				
			}
			if (numberOfUpdatedFields<0) {
				// not enough dictionary items provided - must be at least the number of keyFields+1
				string msg := "Not enough delta field values provided. Must be at least number of keyFields +1 (="+ (compoundKeyIndexes.size()+1).toString() +"). Supplied delta field values: "+dvdelta.fieldValues.toString();
				log "updateDeltaDataViewItem() - \""+dvName+"\" - routing DataViewItemException event - "+msg at WARN;
				route DataViewItemException(dvdelta.msgId, dvName, itemId, msg, new dictionary<string,string>);
				return;				
			}
			// build the key
			compoundKey := buildCompoundKeyFromIndexDict(dvdelta.fieldValues);
			log "updateDeltaDataViewItem() - \""+dvName+"\" - compoundKey: "+compoundKey at DEBUG;
			
			if (0=compoundKey.length()) {
				// we get an error back from buildCompoundKey - most likely the key fields were not supplied?
				string msg := "Unable to construct compound key from delta field values: "+dvdelta.fieldValues.toString();
				log "updateDeltaDataViewItem() - \""+dvName+"\" - routing DataViewItemException event - "+msg at WARN;
				route DataViewItemException(dvdelta.msgId, dvName, itemId, msg, new dictionary<string,string>);
				return;								
			}
			
			// all valid - get the itemId from the dictionary
			if (not compoundKeyInstanceDictionary.hasKey(compoundKey)) {
				// we built a valid key, but no dvItem is currently known with that key
				string msg := "No DataViewItem could be found for the keyFields supplied: "+dvdelta.fieldValues.toString();
				log "updateDeltaDataViewItem() - \""+dvName+"\" - routing DataViewItemException event - "+msg at WARN;
				route DataViewItemException(dvdelta.msgId, dvName, itemId, msg, new dictionary<string,string>);
				return;
			}
			itemId := compoundKeyInstanceDictionary[compoundKey];
			log "updateDeltaDataViewItem() - \""+dvName+":"+itemId.toString()+"\" - found dvItemId for keyFields" at DEBUG;
		}

		// check if we have an Item with the (supplied or calculated) itemId
		if (not instancesDictionary.hasKey(itemId)) {
			string msg := "Unknown dvItemId: "+itemId.toString();
			log "updateDeltaDataViewItem() - \""+dvName+":"+itemId.toString()+"\" - routing DataViewItemException event - "+msg at WARN;
			route DataViewItemException(dvdelta.msgId, dvName, itemId, msg, new dictionary<string,string>);
			return;
		}
		
		//log "updateDeltaDataViewItem() - \""+dvName+":"+itemId.toString()+"\" - content of delta: "+dvdelta.fieldValues.toString() at DEBUG;
		_Item item := instancesDictionary[itemId];
		integer k;
		sequence<string> tmpFields := item.outputFields.clone(); // take a copy of the current values
		for k in dvdelta.fieldValues.keys() {
			if (k<0 or k>=NUM_FIELDS) {
				string msg := "DataView updateItemDelta ignored - Invalid field index provided ("+k.toString()+") in the delta field values: "+dvdelta.fieldValues.toString();
				log "updateDeltaDataViewItem() - \""+dvName+"\" - " + msg at WARN;					
				route DataViewItemException(dvdelta.msgId, dvName, itemId, msg, new dictionary<string,string>);
				return;
			}
			// no need to check for duplicate indexs, as we're getting them out of a dictionary - by definition there can't be duplicate keys!

			tmpFields[k] := dvdelta.fieldValues[k]; // overwrite a specific value with a new value
		}
		
		// IMPORTANT
		// check we have not altered a keyField value if this DataView is configured for their use!!
		if (0<compoundKeyIndexes.size()) {
			string existingCompoundKey := buildCompoundKeyFromSeq(item.outputFields);
			if (0=compoundKey.length()) {
				compoundKey := buildCompoundKeyFromSeq(tmpFields);
			}
			if not (compoundKey=existingCompoundKey) {
				string msg := "DataView updateItemDelta ignored - It is not permitted to change the value of a keyField. The supplied values were: "+dvdelta.fieldValues.toString();
				log "updateDeltaDataViewItem() - \""+dvName+":"+itemId.toString()+"\" - routing DataViewItemException event - "+msg at WARN;
				route DataViewItemException(dvdelta.msgId, dvName, itemId, msg, new dictionary<string,string>);

				log "updateDeltaDataViewItem() - \""+dvName+":"+itemId.toString()+"\" - existing compoundKey: \""+existingCompoundKey+"\", new compoundKey: \""+compoundKey+"\"" at DEBUG;

				return;				
			}
		}

		// Now we can make the change to the actual stored values
		item.outputFields := tmpFields; // replace with the new updated set
		
		log "updateDeltaDataViewItem() - \""+dvName+":"+itemId.toString()+"\" - routing an Update event with the following field values: "+item.outputFields.toString() at DEBUG;
		float timeStamp := dvdelta.timeStamp;
		if (-1.0=timeStamp) {
			timeStamp:=currentTime;
		}
		updater.emitUpdate_time(item.scenarioInstanceId, timeStamp, item.outputFields, item.owner);
	}

	
	//===================================================================================

	
	
	// The ACKs and NACKs for the Scenario API and the Scenario Bridge API.	
	action emitAcknowledgement(integer messageId, _Item item) {
		updater.emitAcknowledgement(messageId, item.scenarioInstanceId, item.outputFields);
	}

	action emitNack(integer messageId, integer scenarioInstanceId) {
		updater.emitNack(messageId, scenarioInstanceId);
	}

}
 00000049 C:\dev\apama_win_full_latest\Apama\monitors\DataViewService_Impl_Dict.mon
TIME 0000000e 1568382757.2,1
MONF 0000057f /**
 * $Copyright (c) 2016 Software AG, Darmstadt, Germany and/or Software AG USA Inc., Reston, VA, USA, and/or its subsidiaries and/or its affiliates and/or their licensors.$
 * Use, reproduction, transfer, publication or disclosure is prohibited except as specifically provided for in your License Agreement with Software AG
 */

package com.apama.eventscheduler;

/**
 * An event object providing function to schedule sending of an event to a channel 
 * in future. It is useful for externally-clocked correlator where correlator time 
 * travels differently than real time and timer based on real time is required. 
 * The "on wait()" listener is the standard way for creating a timer and should
 * be used in most cases.
 */
event EventScheduler {
	/** @private */
	import "EventSchedulerPlugin" as _plugin;

	/** Schedule an event to be sent in future after the specified time. The event is
	 * sent to the specified channel.
	 *
	 * @param eventString String that specifies the event to be sent.
	 * @param channel String that specifies the channel to be which event should be sent.
	 * @param duration Float that specifies time duration after which event should be sent. 
	 * The duration is specified in seconds.
	 *
	 */
	static action scheduleEvent(string eventString, string channel, float duration) {
		_plugin.scheduleEvent(eventString, channel, duration);
	}
}
 0000003e C:\dev\apama_win_full_latest\Apama\monitors\EventScheduler.mon
DISC 0000003c 6736152632449878368:6735871166063102304 from 127.0.0.1:58877
DISC 0000003c 6736152632449878368:6736715595288201568 from 127.0.0.1:15903
